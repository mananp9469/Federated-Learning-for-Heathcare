{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9LLLfSEhU_e9"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WW1w7Q5HLcO9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Activation\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from keras.regularizers import l2\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import sklearn\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers.legacy import SGD\n",
        "from numpy.random import seed\n",
        "from tensorflow.random import set_seed\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed(0)\n",
        "set_seed(0)"
      ],
      "metadata": {
        "id": "gpXstZGMpKqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/stroke_dataset.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Y0vZqnCqL48Q",
        "outputId": "52cb4cec-2899-4308-8600-bd90a4218a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
              "0   9046    Male  67.0             0              1          Yes   \n",
              "1  51676  Female  61.0             0              0          Yes   \n",
              "2  31112    Male  80.0             0              1          Yes   \n",
              "3  60182  Female  49.0             0              0          Yes   \n",
              "4   1665  Female  79.0             1              0          Yes   \n",
              "\n",
              "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
              "0        Private          Urban             228.69  36.6  formerly smoked   \n",
              "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
              "2        Private          Rural             105.92  32.5     never smoked   \n",
              "3        Private          Urban             171.23  34.4           smokes   \n",
              "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
              "\n",
              "   stroke  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e11bc02f-6417-47ef-95b5-41e91a236643\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>work_type</th>\n",
              "      <th>Residence_type</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>bmi</th>\n",
              "      <th>smoking_status</th>\n",
              "      <th>stroke</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9046</td>\n",
              "      <td>Male</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>228.69</td>\n",
              "      <td>36.6</td>\n",
              "      <td>formerly smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>51676</td>\n",
              "      <td>Female</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>202.21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31112</td>\n",
              "      <td>Male</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Rural</td>\n",
              "      <td>105.92</td>\n",
              "      <td>32.5</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60182</td>\n",
              "      <td>Female</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>171.23</td>\n",
              "      <td>34.4</td>\n",
              "      <td>smokes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1665</td>\n",
              "      <td>Female</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>174.12</td>\n",
              "      <td>24.0</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e11bc02f-6417-47ef-95b5-41e91a236643')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e11bc02f-6417-47ef-95b5-41e91a236643 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e11bc02f-6417-47ef-95b5-41e91a236643');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(['id'], axis = 1, inplace = True)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "Y3rFk1QFMiC7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "dc4ca060-a33b-401e-bde7-f92d93950492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   gender   age  hypertension  heart_disease ever_married      work_type  \\\n",
              "0    Male  67.0             0              1          Yes        Private   \n",
              "1  Female  61.0             0              0          Yes  Self-employed   \n",
              "2    Male  80.0             0              1          Yes        Private   \n",
              "3  Female  49.0             0              0          Yes        Private   \n",
              "4  Female  79.0             1              0          Yes  Self-employed   \n",
              "\n",
              "  Residence_type  avg_glucose_level   bmi   smoking_status  stroke  \n",
              "0          Urban             228.69  36.6  formerly smoked       1  \n",
              "1          Rural             202.21   NaN     never smoked       1  \n",
              "2          Rural             105.92  32.5     never smoked       1  \n",
              "3          Urban             171.23  34.4           smokes       1  \n",
              "4          Rural             174.12  24.0     never smoked       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-08370810-2ae4-4787-91c5-b28f82b82e14\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>work_type</th>\n",
              "      <th>Residence_type</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>bmi</th>\n",
              "      <th>smoking_status</th>\n",
              "      <th>stroke</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Male</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>228.69</td>\n",
              "      <td>36.6</td>\n",
              "      <td>formerly smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Female</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>202.21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Male</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Rural</td>\n",
              "      <td>105.92</td>\n",
              "      <td>32.5</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Female</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>171.23</td>\n",
              "      <td>34.4</td>\n",
              "      <td>smokes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Female</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>174.12</td>\n",
              "      <td>24.0</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08370810-2ae4-4787-91c5-b28f82b82e14')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-08370810-2ae4-4787-91c5-b28f82b82e14 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-08370810-2ae4-4787-91c5-b28f82b82e14');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing"
      ],
      "metadata": {
        "id": "75B8OEfkVpSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6pHWf1GWRQq",
        "outputId": "d04220c4-76f7-42a7-b569-5fe84c8893a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gender                 0\n",
              "age                    0\n",
              "hypertension           0\n",
              "heart_disease          0\n",
              "ever_married           0\n",
              "work_type              0\n",
              "Residence_type         0\n",
              "avg_glucose_level      0\n",
              "bmi                  201\n",
              "smoking_status         0\n",
              "stroke                 0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.bmi.replace(to_replace=np.nan, value=data.bmi.mean(), inplace=True)"
      ],
      "metadata": {
        "id": "O_p7pNAnWNGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = data.iloc[:, :-1]\n",
        "y = data.iloc[:,-1]"
      ],
      "metadata": {
        "id": "rgHdfkGMNCWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ct = ColumnTransformer(transformers= [('encoder', OneHotEncoder(), [0,5,9])], remainder= 'passthrough')\n",
        "x = np.array(ct.fit_transform(x))"
      ],
      "metadata": {
        "id": "aZhzw0jVVowE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "x[:, 15] = le.fit_transform(x[:, 15])\n",
        "x[:, 16] = le.fit_transform(x[:, 16])"
      ],
      "metadata": {
        "id": "3lhnm8xxV27y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5GsnmHXWCIS",
        "outputId": "52366e4b-296c-4c41-a5cf-7d6e290b6bcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0, 1.0, 0.0, ..., 1, 228.69, 36.6],\n",
              "       [1.0, 0.0, 0.0, ..., 0, 202.21, 28.893236911794666],\n",
              "       [0.0, 1.0, 0.0, ..., 0, 105.92, 32.5],\n",
              "       ...,\n",
              "       [1.0, 0.0, 0.0, ..., 0, 82.99, 30.6],\n",
              "       [0.0, 1.0, 0.0, ..., 0, 166.29, 25.6],\n",
              "       [1.0, 0.0, 0.0, ..., 1, 85.28, 26.2]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "bOxHyTT3NVZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "scaler.fit(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntWi9SO_N7GL",
        "outputId": "fd5d477a-7f65-43c1-edd3-9eb27210c8f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler()"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_scaled = scaler.transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "mxFGSCeNN_Sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_scaled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO38d5lqPzSq",
        "outputId": "ac87c44f-a3fd-4bcc-e877-bc8ad76d99b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4088, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_scaled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVGEQ0JuYD9a",
        "outputId": "524091dc-520b-4f3b-dedb-b795a544ed7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1022, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SMOTE"
      ],
      "metadata": {
        "id": "D22AenpjXWMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "Bo1Vl6HaXXYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
        "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
        "\n",
        "sm = SMOTE(random_state=None)\n",
        "x_train_res, y_train_res = sm.fit_resample(x_train_scaled, y_train.ravel())\n",
        "\n",
        "print('After OverSampling, the shape of train_X: {}'.format(x_train_res.shape))\n",
        "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
        "\n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
        "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvRCynRJXZFS",
        "outputId": "dafd407e-f5ea-47e4-a8bf-eaa4bf4c3ab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before OverSampling, counts of label '1': 195\n",
            "Before OverSampling, counts of label '0': 3893 \n",
            "\n",
            "After OverSampling, the shape of train_X: (7786, 19)\n",
            "After OverSampling, the shape of train_y: (7786,) \n",
            "\n",
            "After OverSampling, counts of label '1': 3893\n",
            "After OverSampling, counts of label '0': 3893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Device data split"
      ],
      "metadata": {
        "id": "3NxL6gmxRaX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train1, x_train2, y_train1, y_train2 = train_test_split(x_train_res, y_train_res, test_size = 0.33, random_state = 0)\n",
        "x_train1, x_train3, y_train1, y_train3 = train_test_split(x_train1, y_train1, test_size = 0.5, random_state = 0)"
      ],
      "metadata": {
        "id": "VVLcPHJoRm5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train1.shape, y_train1.shape, x_train2.shape, y_train2.shape, x_train3.shape, y_train3.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Om4qd-EPJ1Z",
        "outputId": "447a52a0-1072-48f3-a38f-b871f27ca534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2608, 19), (2608,), (2570, 19), (2570,), (2608, 19), (2608,))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Models"
      ],
      "metadata": {
        "id": "fDQ6zHsyRhRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  input = Input(shape = x_train_scaled.shape[-1])\n",
        "  dense_1 = Dense(units = 8, activation = 'relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(input)\n",
        "  dense_2 = Dense(units = 8, activation = 'relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(dense_1)\n",
        "  classifier = Dense(units = 1, activation = 'sigmoid')(dense_2)\n",
        "\n",
        "  model = Model(input, classifier)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "q7JOnd49S-fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clear_session()\n",
        "model1 = build_model()\n",
        "model2 = build_model()\n",
        "model3 = build_model()"
      ],
      "metadata": {
        "id": "Tu-xedXpOLl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = SGD()"
      ],
      "metadata": {
        "id": "gxhlaJ-Imxdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics = 'accuracy')\n",
        "model2.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics = 'accuracy')\n",
        "model3.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics = 'accuracy')"
      ],
      "metadata": {
        "id": "5_Nr3A95OUaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model1,\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True,\n",
        "    show_layer_activations=True,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "JAT_B7kkQUtR",
        "outputId": "63ceb19a-91fa-46bf-afa3-b8fed16aa51a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history1 = model1.fit(x_train1, y_train1, epochs = 50, validation_split = 0.2, workers = -1, use_multiprocessing = True, verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FK2nCXcMPWMG",
        "outputId": "5c20a136-eda7-4e4b-cbab-ce0f0cacd48a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "66/66 [==============================] - 1s 6ms/step - loss: 0.3777 - accuracy: 0.8495 - val_loss: 0.3970 - val_accuracy: 0.8410\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3776 - accuracy: 0.8543 - val_loss: 0.3927 - val_accuracy: 0.8563\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3783 - accuracy: 0.8519 - val_loss: 0.3948 - val_accuracy: 0.8314\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3766 - accuracy: 0.8514 - val_loss: 0.4753 - val_accuracy: 0.7874\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3793 - accuracy: 0.8567 - val_loss: 0.3903 - val_accuracy: 0.8467\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3774 - accuracy: 0.8523 - val_loss: 0.4028 - val_accuracy: 0.8448\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8591 - val_loss: 0.3995 - val_accuracy: 0.8467\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3766 - accuracy: 0.8533 - val_loss: 0.4034 - val_accuracy: 0.8467\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3779 - accuracy: 0.8547 - val_loss: 0.3930 - val_accuracy: 0.8602\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.8552 - val_loss: 0.3860 - val_accuracy: 0.8544\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3774 - accuracy: 0.8519 - val_loss: 0.4258 - val_accuracy: 0.8238\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3768 - accuracy: 0.8538 - val_loss: 0.3922 - val_accuracy: 0.8506\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3764 - accuracy: 0.8538 - val_loss: 0.4139 - val_accuracy: 0.8391\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3765 - accuracy: 0.8514 - val_loss: 0.4039 - val_accuracy: 0.8487\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3759 - accuracy: 0.8509 - val_loss: 0.3887 - val_accuracy: 0.8506\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3746 - accuracy: 0.8557 - val_loss: 0.3936 - val_accuracy: 0.8563\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.8567 - val_loss: 0.3901 - val_accuracy: 0.8544\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3764 - accuracy: 0.8519 - val_loss: 0.3932 - val_accuracy: 0.8467\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3746 - accuracy: 0.8523 - val_loss: 0.4033 - val_accuracy: 0.8525\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3767 - accuracy: 0.8557 - val_loss: 0.3897 - val_accuracy: 0.8582\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.8567 - val_loss: 0.3956 - val_accuracy: 0.8544\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3754 - accuracy: 0.8514 - val_loss: 0.4322 - val_accuracy: 0.8257\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3770 - accuracy: 0.8543 - val_loss: 0.3932 - val_accuracy: 0.8506\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3771 - accuracy: 0.8567 - val_loss: 0.3883 - val_accuracy: 0.8582\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3771 - accuracy: 0.8557 - val_loss: 0.4115 - val_accuracy: 0.8391\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3772 - accuracy: 0.8509 - val_loss: 0.3920 - val_accuracy: 0.8487\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3754 - accuracy: 0.8557 - val_loss: 0.4080 - val_accuracy: 0.8544\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3765 - accuracy: 0.8533 - val_loss: 0.3951 - val_accuracy: 0.8391\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3757 - accuracy: 0.8547 - val_loss: 0.3889 - val_accuracy: 0.8487\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3734 - accuracy: 0.8543 - val_loss: 0.3919 - val_accuracy: 0.8487\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3747 - accuracy: 0.8519 - val_loss: 0.3901 - val_accuracy: 0.8621\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3761 - accuracy: 0.8528 - val_loss: 0.4013 - val_accuracy: 0.8506\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.8552 - val_loss: 0.3961 - val_accuracy: 0.8448\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3752 - accuracy: 0.8514 - val_loss: 0.3977 - val_accuracy: 0.8525\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3766 - accuracy: 0.8528 - val_loss: 0.3885 - val_accuracy: 0.8582\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3752 - accuracy: 0.8581 - val_loss: 0.3937 - val_accuracy: 0.8467\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3771 - accuracy: 0.8552 - val_loss: 0.3902 - val_accuracy: 0.8429\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3762 - accuracy: 0.8480 - val_loss: 0.3908 - val_accuracy: 0.8602\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3751 - accuracy: 0.8567 - val_loss: 0.3850 - val_accuracy: 0.8640\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3746 - accuracy: 0.8547 - val_loss: 0.3898 - val_accuracy: 0.8448\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3760 - accuracy: 0.8500 - val_loss: 0.3917 - val_accuracy: 0.8467\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3755 - accuracy: 0.8523 - val_loss: 0.4065 - val_accuracy: 0.8314\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3769 - accuracy: 0.8552 - val_loss: 0.3974 - val_accuracy: 0.8448\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3760 - accuracy: 0.8547 - val_loss: 0.3927 - val_accuracy: 0.8487\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3740 - accuracy: 0.8557 - val_loss: 0.3965 - val_accuracy: 0.8582\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3749 - accuracy: 0.8552 - val_loss: 0.3921 - val_accuracy: 0.8506\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3743 - accuracy: 0.8581 - val_loss: 0.4009 - val_accuracy: 0.8506\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3764 - accuracy: 0.8562 - val_loss: 0.4196 - val_accuracy: 0.8199\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3760 - accuracy: 0.8523 - val_loss: 0.4295 - val_accuracy: 0.8199\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.8533 - val_loss: 0.4042 - val_accuracy: 0.8276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.plot(history1.history['accuracy'])\n",
        "# plt.plot(history1.history['val_accuracy'])\n",
        "# plt.title('model1 accuracy')\n",
        "# plt.ylabel('accuracy')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'test'], loc='upper left')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "SIpR-Ys-05iV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(x_train2, y_train2, epochs = 50, validation_split = 0.2, workers = -1, use_multiprocessing = True, verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDWm21gCPsHz",
        "outputId": "cf9be7f9-7aa9-4fcf-fb09-6f904ba63eb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.3749 - accuracy: 0.8497 - val_loss: 0.4176 - val_accuracy: 0.8210\n",
            "Epoch 2/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3721 - accuracy: 0.8555 - val_loss: 0.4360 - val_accuracy: 0.8054\n",
            "Epoch 3/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3733 - accuracy: 0.8517 - val_loss: 0.4258 - val_accuracy: 0.8152\n",
            "Epoch 4/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3728 - accuracy: 0.8551 - val_loss: 0.4240 - val_accuracy: 0.8152\n",
            "Epoch 5/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3740 - accuracy: 0.8512 - val_loss: 0.4127 - val_accuracy: 0.8327\n",
            "Epoch 6/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3718 - accuracy: 0.8575 - val_loss: 0.4218 - val_accuracy: 0.8268\n",
            "Epoch 7/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3727 - accuracy: 0.8560 - val_loss: 0.4166 - val_accuracy: 0.8307\n",
            "Epoch 8/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3726 - accuracy: 0.8531 - val_loss: 0.4150 - val_accuracy: 0.8268\n",
            "Epoch 9/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3743 - accuracy: 0.8531 - val_loss: 0.4279 - val_accuracy: 0.8268\n",
            "Epoch 10/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3733 - accuracy: 0.8531 - val_loss: 0.4271 - val_accuracy: 0.8152\n",
            "Epoch 11/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3732 - accuracy: 0.8541 - val_loss: 0.4267 - val_accuracy: 0.8288\n",
            "Epoch 12/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3738 - accuracy: 0.8536 - val_loss: 0.4172 - val_accuracy: 0.8230\n",
            "Epoch 13/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3720 - accuracy: 0.8575 - val_loss: 0.4176 - val_accuracy: 0.8210\n",
            "Epoch 14/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3712 - accuracy: 0.8521 - val_loss: 0.4307 - val_accuracy: 0.8210\n",
            "Epoch 15/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3723 - accuracy: 0.8546 - val_loss: 0.4214 - val_accuracy: 0.8171\n",
            "Epoch 16/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3723 - accuracy: 0.8517 - val_loss: 0.4196 - val_accuracy: 0.8249\n",
            "Epoch 17/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3703 - accuracy: 0.8526 - val_loss: 0.4189 - val_accuracy: 0.8288\n",
            "Epoch 18/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3711 - accuracy: 0.8609 - val_loss: 0.4179 - val_accuracy: 0.8191\n",
            "Epoch 19/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3730 - accuracy: 0.8546 - val_loss: 0.4185 - val_accuracy: 0.8288\n",
            "Epoch 20/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3701 - accuracy: 0.8580 - val_loss: 0.4217 - val_accuracy: 0.8327\n",
            "Epoch 21/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3715 - accuracy: 0.8517 - val_loss: 0.4195 - val_accuracy: 0.8327\n",
            "Epoch 22/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3735 - accuracy: 0.8589 - val_loss: 0.4188 - val_accuracy: 0.8366\n",
            "Epoch 23/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3701 - accuracy: 0.8560 - val_loss: 0.4237 - val_accuracy: 0.8210\n",
            "Epoch 24/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3694 - accuracy: 0.8546 - val_loss: 0.4332 - val_accuracy: 0.8191\n",
            "Epoch 25/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3717 - accuracy: 0.8536 - val_loss: 0.4262 - val_accuracy: 0.8307\n",
            "Epoch 26/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3728 - accuracy: 0.8531 - val_loss: 0.4193 - val_accuracy: 0.8191\n",
            "Epoch 27/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3700 - accuracy: 0.8609 - val_loss: 0.4201 - val_accuracy: 0.8307\n",
            "Epoch 28/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3703 - accuracy: 0.8551 - val_loss: 0.4386 - val_accuracy: 0.8035\n",
            "Epoch 29/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3696 - accuracy: 0.8580 - val_loss: 0.4349 - val_accuracy: 0.8152\n",
            "Epoch 30/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3701 - accuracy: 0.8585 - val_loss: 0.4285 - val_accuracy: 0.8366\n",
            "Epoch 31/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3701 - accuracy: 0.8536 - val_loss: 0.4141 - val_accuracy: 0.8346\n",
            "Epoch 32/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3708 - accuracy: 0.8536 - val_loss: 0.4163 - val_accuracy: 0.8346\n",
            "Epoch 33/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3693 - accuracy: 0.8585 - val_loss: 0.4224 - val_accuracy: 0.8346\n",
            "Epoch 34/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3699 - accuracy: 0.8541 - val_loss: 0.4185 - val_accuracy: 0.8366\n",
            "Epoch 35/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3684 - accuracy: 0.8575 - val_loss: 0.4298 - val_accuracy: 0.8191\n",
            "Epoch 36/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3704 - accuracy: 0.8560 - val_loss: 0.4164 - val_accuracy: 0.8424\n",
            "Epoch 37/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3701 - accuracy: 0.8541 - val_loss: 0.4348 - val_accuracy: 0.8093\n",
            "Epoch 38/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3699 - accuracy: 0.8536 - val_loss: 0.4265 - val_accuracy: 0.8230\n",
            "Epoch 39/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3680 - accuracy: 0.8565 - val_loss: 0.4136 - val_accuracy: 0.8327\n",
            "Epoch 40/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3698 - accuracy: 0.8580 - val_loss: 0.4306 - val_accuracy: 0.8210\n",
            "Epoch 41/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8546 - val_loss: 0.4195 - val_accuracy: 0.8346\n",
            "Epoch 42/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3676 - accuracy: 0.8609 - val_loss: 0.4318 - val_accuracy: 0.8171\n",
            "Epoch 43/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3691 - accuracy: 0.8560 - val_loss: 0.4245 - val_accuracy: 0.8230\n",
            "Epoch 44/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3705 - accuracy: 0.8526 - val_loss: 0.4166 - val_accuracy: 0.8405\n",
            "Epoch 45/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3700 - accuracy: 0.8526 - val_loss: 0.4268 - val_accuracy: 0.8288\n",
            "Epoch 46/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3677 - accuracy: 0.8570 - val_loss: 0.4382 - val_accuracy: 0.8074\n",
            "Epoch 47/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3683 - accuracy: 0.8594 - val_loss: 0.4209 - val_accuracy: 0.8346\n",
            "Epoch 48/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3688 - accuracy: 0.8604 - val_loss: 0.4270 - val_accuracy: 0.8327\n",
            "Epoch 49/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3670 - accuracy: 0.8560 - val_loss: 0.4289 - val_accuracy: 0.8385\n",
            "Epoch 50/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3681 - accuracy: 0.8575 - val_loss: 0.4312 - val_accuracy: 0.8444\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f94f018aeb0>"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.fit(x_train3, y_train3, epochs = 50, validation_split = 0.2, workers = -1, use_multiprocessing = True, verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfkzOQZk_px7",
        "outputId": "460bcd92-7e19-4520-ae75-6e82ad391f5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "66/66 [==============================] - 1s 6ms/step - loss: 0.3559 - accuracy: 0.8619 - val_loss: 0.4024 - val_accuracy: 0.8467\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3553 - accuracy: 0.8667 - val_loss: 0.4128 - val_accuracy: 0.8333\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3549 - accuracy: 0.8696 - val_loss: 0.4211 - val_accuracy: 0.8487\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3556 - accuracy: 0.8629 - val_loss: 0.4273 - val_accuracy: 0.8276\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3567 - accuracy: 0.8600 - val_loss: 0.4136 - val_accuracy: 0.8410\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3550 - accuracy: 0.8610 - val_loss: 0.4048 - val_accuracy: 0.8467\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3543 - accuracy: 0.8648 - val_loss: 0.3999 - val_accuracy: 0.8429\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3540 - accuracy: 0.8643 - val_loss: 0.4018 - val_accuracy: 0.8525\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3525 - accuracy: 0.8677 - val_loss: 0.4021 - val_accuracy: 0.8467\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3529 - accuracy: 0.8624 - val_loss: 0.4242 - val_accuracy: 0.8238\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3536 - accuracy: 0.8667 - val_loss: 0.4097 - val_accuracy: 0.8391\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3509 - accuracy: 0.8658 - val_loss: 0.4867 - val_accuracy: 0.7835\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3539 - accuracy: 0.8629 - val_loss: 0.4018 - val_accuracy: 0.8582\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3536 - accuracy: 0.8648 - val_loss: 0.4051 - val_accuracy: 0.8506\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3518 - accuracy: 0.8667 - val_loss: 0.4130 - val_accuracy: 0.8429\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3538 - accuracy: 0.8624 - val_loss: 0.4080 - val_accuracy: 0.8429\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3544 - accuracy: 0.8658 - val_loss: 0.4091 - val_accuracy: 0.8448\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3510 - accuracy: 0.8667 - val_loss: 0.4007 - val_accuracy: 0.8467\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3517 - accuracy: 0.8643 - val_loss: 0.4365 - val_accuracy: 0.8352\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3525 - accuracy: 0.8696 - val_loss: 0.4027 - val_accuracy: 0.8544\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3516 - accuracy: 0.8667 - val_loss: 0.4007 - val_accuracy: 0.8544\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3516 - accuracy: 0.8667 - val_loss: 0.4096 - val_accuracy: 0.8525\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3509 - accuracy: 0.8672 - val_loss: 0.4233 - val_accuracy: 0.8429\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3533 - accuracy: 0.8730 - val_loss: 0.4057 - val_accuracy: 0.8525\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3517 - accuracy: 0.8653 - val_loss: 0.4051 - val_accuracy: 0.8467\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3504 - accuracy: 0.8677 - val_loss: 0.4066 - val_accuracy: 0.8467\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3518 - accuracy: 0.8605 - val_loss: 0.4105 - val_accuracy: 0.8506\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3513 - accuracy: 0.8691 - val_loss: 0.4104 - val_accuracy: 0.8429\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3503 - accuracy: 0.8634 - val_loss: 0.4066 - val_accuracy: 0.8487\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.8696 - val_loss: 0.4111 - val_accuracy: 0.8410\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3505 - accuracy: 0.8663 - val_loss: 0.4481 - val_accuracy: 0.8180\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3506 - accuracy: 0.8629 - val_loss: 0.4037 - val_accuracy: 0.8410\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3488 - accuracy: 0.8634 - val_loss: 0.4061 - val_accuracy: 0.8467\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3494 - accuracy: 0.8653 - val_loss: 0.4087 - val_accuracy: 0.8391\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3508 - accuracy: 0.8667 - val_loss: 0.4644 - val_accuracy: 0.8257\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3512 - accuracy: 0.8663 - val_loss: 0.4180 - val_accuracy: 0.8333\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3506 - accuracy: 0.8643 - val_loss: 0.4112 - val_accuracy: 0.8391\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3503 - accuracy: 0.8629 - val_loss: 0.4045 - val_accuracy: 0.8429\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3500 - accuracy: 0.8615 - val_loss: 0.4015 - val_accuracy: 0.8467\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3513 - accuracy: 0.8672 - val_loss: 0.4029 - val_accuracy: 0.8506\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8691 - val_loss: 0.4149 - val_accuracy: 0.8372\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.8663 - val_loss: 0.4159 - val_accuracy: 0.8506\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3514 - accuracy: 0.8667 - val_loss: 0.4031 - val_accuracy: 0.8506\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3491 - accuracy: 0.8739 - val_loss: 0.4184 - val_accuracy: 0.8352\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3504 - accuracy: 0.8663 - val_loss: 0.4393 - val_accuracy: 0.8180\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3507 - accuracy: 0.8672 - val_loss: 0.4143 - val_accuracy: 0.8525\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3483 - accuracy: 0.8710 - val_loss: 0.4097 - val_accuracy: 0.8333\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3509 - accuracy: 0.8643 - val_loss: 0.4203 - val_accuracy: 0.8372\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3518 - accuracy: 0.8667 - val_loss: 0.4100 - val_accuracy: 0.8391\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3513 - accuracy: 0.8648 - val_loss: 0.4078 - val_accuracy: 0.8487\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9565719460>"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "local_loss_acc =[model1.evaluate(x_test_scaled, y_test), model2.evaluate(x_test_scaled, y_test), model3.evaluate(x_test_scaled, y_test)]\n",
        "print(local_loss_acc)\n",
        "print('SGD FROM NOW ON')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAKV8b15JUPL",
        "outputId": "0cc04251-25c3-4438-f26f-7f6e871dbc96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.8004\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6006 - accuracy: 0.7221\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5902 - accuracy: 0.7436\n",
            "[[0.44108617305755615, 0.8003913760185242], [0.6005954742431641, 0.7221134901046753], [0.5902456641197205, 0.7436399459838867]]\n",
            "SGD FROM NOW ON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p1_local = np.round(model1.predict(x_test_scaled))\n",
        "p2_local = np.round(model2.predict(x_test_scaled))\n",
        "p3_local = np.round(model3.predict(x_test_scaled))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-D__MRxMyloN",
        "outputId": "5f5d6e08-0f33-44ae-cbde-92f2deffc53b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 3ms/step\n",
            "32/32 [==============================] - 0s 3ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "local_cm = [confusion_matrix(y_test,p1_local),confusion_matrix(y_test,p2_local),confusion_matrix(y_test,p3_local)]\n",
        "local_cr = [classification_report(y_test,p1_local),classification_report(y_test,p2_local),classification_report(y_test,p3_local)]\n",
        "\n"
      ],
      "metadata": {
        "id": "ZNMg7XKvxvMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(local_cm[0])\n",
        "print(local_cm[1])\n",
        "print(local_cm[2])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaEpabK_40i1",
        "outputId": "34aceb1b-80b5-411a-9224-0599de667fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[791 177]\n",
            " [ 27  27]]\n",
            "[[698 270]\n",
            " [ 14  40]]\n",
            "[[726 242]\n",
            " [ 20  34]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(local_cr[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2u84UTn95J4J",
        "outputId": "7fe3b614-2eb7-46f6-e90b-b36869b1ffc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.82      0.89       968\n",
            "           1       0.13      0.50      0.21        54\n",
            "\n",
            "    accuracy                           0.80      1022\n",
            "   macro avg       0.55      0.66      0.55      1022\n",
            "weighted avg       0.92      0.80      0.85      1022\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(local_cr[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipfGVIr_5Na3",
        "outputId": "dd049a44-f7e2-4a4b-a15e-60af52e0690c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.72      0.83       968\n",
            "           1       0.13      0.74      0.22        54\n",
            "\n",
            "    accuracy                           0.72      1022\n",
            "   macro avg       0.55      0.73      0.53      1022\n",
            "weighted avg       0.94      0.72      0.80      1022\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(local_cr[2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okCzPNdD5O9B",
        "outputId": "e324b89b-265d-498e-d2d9-7908ca0ff6bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.75      0.85       968\n",
            "           1       0.12      0.63      0.21        54\n",
            "\n",
            "    accuracy                           0.74      1022\n",
            "   macro avg       0.55      0.69      0.53      1022\n",
            "weighted avg       0.93      0.74      0.81      1022\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Functions"
      ],
      "metadata": {
        "id": "BnVTdJuS_lDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_opt_weights(model):\n",
        "  symbolic_weights = getattr(model.optimizer, 'weights')\n",
        "  opt_weights = keras.backend.batch_get_value(symbolic_weights)\n",
        "\n",
        "  return opt_weights"
      ],
      "metadata": {
        "id": "gqnldLnASlVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def average_opt_weights(weight1, weight2, weight3):\n",
        "  new_weights = []\n",
        "  new_weights.append(weight1[0])\n",
        "  i = 1\n",
        "  for w1,w2,w3 in zip(weight1[1:], weight2[1:], weight3[1:]):\n",
        "    sub_weights = np.empty(shape = (w1.shape[0], 0))\n",
        "    sub_weights = np.append(sub_weights, (w1[0] + w2[0] + w3[0]) / 3)\n",
        "    for x,y,z in zip(w1[1:],w2[1:],w3[1:]):\n",
        "      sub_weights = np.vstack((sub_weights, (x + y + z) / 3))\n",
        "    if i%2 == 0:\n",
        "      sub_weights = np.reshape(sub_weights, newshape = (sub_weights.shape[0], ))\n",
        "    i += 1\n",
        "    new_weights.append(sub_weights)\n",
        "  return new_weights"
      ],
      "metadata": {
        "id": "sPHyd23fae3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def new_opt_weights_model(weight_values, model):\n",
        "  model.optimizer.set_weights(weight_values)\n",
        "  return model"
      ],
      "metadata": {
        "id": "zg0uv56Ea4cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Iterative"
      ],
      "metadata": {
        "id": "yWRkOBSkU8uA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global_loss_acc = []\n",
        "global_cm = []\n",
        "global_cr = []"
      ],
      "metadata": {
        "id": "Ko_cLUgxiGMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_process(model1, model2, model3, x_train1, y_train1, x_train2, y_train2, x_train3, y_train3):\n",
        "  weight1 = extract_opt_weights(model1)\n",
        "  weight2 = extract_opt_weights(model2)\n",
        "  weight3 = extract_opt_weights(model3)\n",
        "  print('Weights extracted succesfully')\n",
        "\n",
        "  new_weights = average_opt_weights(weight1, weight2, weight3)\n",
        "  print('Weights averaged successfully')\n",
        "\n",
        "  model1 = new_opt_weights_model(new_weights, model1)\n",
        "  model2 = new_opt_weights_model(new_weights, model2)\n",
        "  model3 = new_opt_weights_model(new_weights, model3)\n",
        "  print('New weights assigned successfully')\n",
        "\n",
        "  print('Training Model 1')\n",
        "  history1 = model1.fit(x_train1, y_train1, epochs = 50, validation_split = 0.2, workers = -1, use_multiprocessing = False, verbose = 1)\n",
        "  # print('Model 1 Accuracy')\n",
        "  # plt.plot(history1.history['accuracy'])\n",
        "  # plt.plot(history1.history['val_accuracy'])\n",
        "  # plt.title('model accuracy')\n",
        "  # plt.ylabel('accuracy')\n",
        "  # plt.xlabel('epoch')\n",
        "  # plt.legend(['train', 'test'], loc='upper left')\n",
        "  # plt.show()\n",
        "  # # summarize history for loss\n",
        "  # print('Model 1 Loss')\n",
        "  # plt.plot(history1.history['loss'])\n",
        "  # plt.plot(history1.history['val_loss'])\n",
        "  # plt.title('model loss')\n",
        "  # plt.ylabel('loss')\n",
        "  # plt.xlabel('epoch')\n",
        "  # plt.legend(['train', 'test'], loc='upper left')\n",
        "  # plt.show()\n",
        "\n",
        "  print('Training Model 2')\n",
        "  history2 = model2.fit(x_train2, y_train2, epochs = 50, validation_split = 0.2, workers = -1, use_multiprocessing = False, verbose = 1)\n",
        "  # print('Model 2 Accuracy')\n",
        "  # plt.plot(history2.history['accuracy'])\n",
        "  # plt.plot(history2.history['val_accuracy'])\n",
        "  # plt.title('model accuracy')\n",
        "  # plt.ylabel('accuracy')\n",
        "  # plt.xlabel('epoch')\n",
        "  # plt.legend(['train', 'test'], loc='upper left')\n",
        "  # plt.show()\n",
        "  # summarize history for loss\n",
        "  # print('Model 2 Loss')\n",
        "  # plt.plot(history2.history['loss'])\n",
        "  # plt.plot(history2.history['val_loss'])\n",
        "  # plt.title('model loss')\n",
        "  # plt.ylabel('loss')\n",
        "  # plt.xlabel('epoch')\n",
        "  # plt.legend(['train', 'test'], loc='upper left')\n",
        "  # plt.show()\n",
        "\n",
        "  print('Training Model 3')\n",
        "  history3 = model3.fit(x_train3, y_train3, epochs = 50, validation_split = 0.2, workers = -1, use_multiprocessing = False, verbose = 1)\n",
        "  # print('Model 3 Accuracy')\n",
        "  # plt.plot(history3.history['accuracy'])\n",
        "  # plt.plot(history3.history['val_accuracy'])\n",
        "  # plt.title('model accuracy')\n",
        "  # plt.ylabel('accuracy')\n",
        "  # plt.xlabel('epoch')\n",
        "  # plt.legend(['train', 'test'], loc='upper left')\n",
        "  # plt.show()\n",
        "\n",
        "  # summarize history for loss\n",
        "  # print('Model 3 Loss')\n",
        "  # plt.plot(history3.history['loss'])\n",
        "  # plt.plot(history3.history['val_loss'])\n",
        "  # plt.title('model loss')\n",
        "  # plt.ylabel('loss')\n",
        "  # plt.xlabel('epoch')\n",
        "  # plt.legend(['train', 'test'], loc='upper left')\n",
        "  # plt.show()\n",
        "\n",
        "  global_loss_acc.append(model1.evaluate(x_test_scaled, y_test))\n",
        "  global_loss_acc.append(model2.evaluate(x_test_scaled, y_test))\n",
        "  global_loss_acc.append(model3.evaluate(x_test_scaled, y_test))\n",
        "\n",
        "  return model1, model2, model3"
      ],
      "metadata": {
        "id": "dcgJGDgeMG6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 10):\n",
        "  print('\\nIteration:', i+1)\n",
        "  model1, model2, model3 = run_process(model1, model2, model3, x_train1, y_train1, x_train2, y_train2, x_train3, y_train3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xljnolL_MSBw",
        "outputId": "ff551b1c-4271-45cd-d63c-2b2829f9fba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration: 1\n",
            "Weights extracted succesfully\n",
            "Weights averaged successfully\n",
            "New weights assigned successfully\n",
            "Training Model 1\n",
            "Epoch 1/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8495 - val_loss: 0.3934 - val_accuracy: 0.8525\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3747 - accuracy: 0.8528 - val_loss: 0.3921 - val_accuracy: 0.8602\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3753 - accuracy: 0.8567 - val_loss: 0.3938 - val_accuracy: 0.8410\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3738 - accuracy: 0.8504 - val_loss: 0.4701 - val_accuracy: 0.7893\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3769 - accuracy: 0.8533 - val_loss: 0.3872 - val_accuracy: 0.8448\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3744 - accuracy: 0.8562 - val_loss: 0.3978 - val_accuracy: 0.8487\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3732 - accuracy: 0.8543 - val_loss: 0.3912 - val_accuracy: 0.8487\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3744 - accuracy: 0.8576 - val_loss: 0.4001 - val_accuracy: 0.8506\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3749 - accuracy: 0.8576 - val_loss: 0.3894 - val_accuracy: 0.8602\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3750 - accuracy: 0.8567 - val_loss: 0.3866 - val_accuracy: 0.8563\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3750 - accuracy: 0.8562 - val_loss: 0.4125 - val_accuracy: 0.8410\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.8557 - val_loss: 0.3911 - val_accuracy: 0.8602\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3732 - accuracy: 0.8600 - val_loss: 0.4074 - val_accuracy: 0.8352\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3738 - accuracy: 0.8523 - val_loss: 0.4069 - val_accuracy: 0.8467\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3728 - accuracy: 0.8576 - val_loss: 0.3885 - val_accuracy: 0.8602\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3724 - accuracy: 0.8605 - val_loss: 0.3903 - val_accuracy: 0.8659\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3725 - accuracy: 0.8586 - val_loss: 0.3880 - val_accuracy: 0.8544\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.8528 - val_loss: 0.3932 - val_accuracy: 0.8602\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3725 - accuracy: 0.8571 - val_loss: 0.4000 - val_accuracy: 0.8525\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3743 - accuracy: 0.8543 - val_loss: 0.3868 - val_accuracy: 0.8659\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3725 - accuracy: 0.8595 - val_loss: 0.3938 - val_accuracy: 0.8525\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3730 - accuracy: 0.8543 - val_loss: 0.4171 - val_accuracy: 0.8295\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3751 - accuracy: 0.8557 - val_loss: 0.3936 - val_accuracy: 0.8506\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3743 - accuracy: 0.8547 - val_loss: 0.3875 - val_accuracy: 0.8640\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3747 - accuracy: 0.8586 - val_loss: 0.4129 - val_accuracy: 0.8352\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3753 - accuracy: 0.8514 - val_loss: 0.3956 - val_accuracy: 0.8544\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3739 - accuracy: 0.8586 - val_loss: 0.4070 - val_accuracy: 0.8563\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3748 - accuracy: 0.8528 - val_loss: 0.3951 - val_accuracy: 0.8487\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3739 - accuracy: 0.8571 - val_loss: 0.3903 - val_accuracy: 0.8467\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3721 - accuracy: 0.8557 - val_loss: 0.3929 - val_accuracy: 0.8429\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3729 - accuracy: 0.8576 - val_loss: 0.3892 - val_accuracy: 0.8678\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3735 - accuracy: 0.8543 - val_loss: 0.4023 - val_accuracy: 0.8487\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3741 - accuracy: 0.8562 - val_loss: 0.3950 - val_accuracy: 0.8372\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3733 - accuracy: 0.8552 - val_loss: 0.3991 - val_accuracy: 0.8506\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3744 - accuracy: 0.8533 - val_loss: 0.3889 - val_accuracy: 0.8659\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3728 - accuracy: 0.8605 - val_loss: 0.3957 - val_accuracy: 0.8506\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3746 - accuracy: 0.8562 - val_loss: 0.3901 - val_accuracy: 0.8563\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3738 - accuracy: 0.8533 - val_loss: 0.3908 - val_accuracy: 0.8640\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3725 - accuracy: 0.8567 - val_loss: 0.3858 - val_accuracy: 0.8659\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3721 - accuracy: 0.8533 - val_loss: 0.3899 - val_accuracy: 0.8467\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.8504 - val_loss: 0.3933 - val_accuracy: 0.8448\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3735 - accuracy: 0.8562 - val_loss: 0.3969 - val_accuracy: 0.8391\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3741 - accuracy: 0.8581 - val_loss: 0.3976 - val_accuracy: 0.8506\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8581 - val_loss: 0.3930 - val_accuracy: 0.8563\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3720 - accuracy: 0.8581 - val_loss: 0.3979 - val_accuracy: 0.8621\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3732 - accuracy: 0.8586 - val_loss: 0.3927 - val_accuracy: 0.8467\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3726 - accuracy: 0.8600 - val_loss: 0.4016 - val_accuracy: 0.8563\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3740 - accuracy: 0.8571 - val_loss: 0.4020 - val_accuracy: 0.8314\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3734 - accuracy: 0.8552 - val_loss: 0.4072 - val_accuracy: 0.8372\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3741 - accuracy: 0.8576 - val_loss: 0.4011 - val_accuracy: 0.8333\n",
            "Training Model 2\n",
            "Epoch 1/50\n",
            "65/65 [==============================] - 1s 10ms/step - loss: 0.3707 - accuracy: 0.8531 - val_loss: 0.4189 - val_accuracy: 0.8385\n",
            "Epoch 2/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3666 - accuracy: 0.8599 - val_loss: 0.4324 - val_accuracy: 0.8210\n",
            "Epoch 3/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3671 - accuracy: 0.8570 - val_loss: 0.4322 - val_accuracy: 0.8191\n",
            "Epoch 4/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3672 - accuracy: 0.8565 - val_loss: 0.4276 - val_accuracy: 0.8152\n",
            "Epoch 5/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3682 - accuracy: 0.8546 - val_loss: 0.4180 - val_accuracy: 0.8424\n",
            "Epoch 6/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3661 - accuracy: 0.8589 - val_loss: 0.4265 - val_accuracy: 0.8366\n",
            "Epoch 7/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3664 - accuracy: 0.8619 - val_loss: 0.4201 - val_accuracy: 0.8405\n",
            "Epoch 8/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3666 - accuracy: 0.8594 - val_loss: 0.4140 - val_accuracy: 0.8268\n",
            "Epoch 9/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3679 - accuracy: 0.8560 - val_loss: 0.4306 - val_accuracy: 0.8327\n",
            "Epoch 10/50\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.3666 - accuracy: 0.8589 - val_loss: 0.4255 - val_accuracy: 0.8366\n",
            "Epoch 11/50\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 0.3667 - accuracy: 0.8624 - val_loss: 0.4284 - val_accuracy: 0.8268\n",
            "Epoch 12/50\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.3669 - accuracy: 0.8614 - val_loss: 0.4217 - val_accuracy: 0.8288\n",
            "Epoch 13/50\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.3655 - accuracy: 0.8599 - val_loss: 0.4168 - val_accuracy: 0.8346\n",
            "Epoch 14/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3644 - accuracy: 0.8594 - val_loss: 0.4358 - val_accuracy: 0.8249\n",
            "Epoch 15/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3654 - accuracy: 0.8609 - val_loss: 0.4199 - val_accuracy: 0.8230\n",
            "Epoch 16/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3657 - accuracy: 0.8594 - val_loss: 0.4230 - val_accuracy: 0.8307\n",
            "Epoch 17/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3631 - accuracy: 0.8614 - val_loss: 0.4199 - val_accuracy: 0.8482\n",
            "Epoch 18/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3643 - accuracy: 0.8648 - val_loss: 0.4195 - val_accuracy: 0.8444\n",
            "Epoch 19/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8541 - val_loss: 0.4226 - val_accuracy: 0.8405\n",
            "Epoch 20/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3634 - accuracy: 0.8614 - val_loss: 0.4235 - val_accuracy: 0.8346\n",
            "Epoch 21/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3649 - accuracy: 0.8604 - val_loss: 0.4269 - val_accuracy: 0.8366\n",
            "Epoch 22/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3661 - accuracy: 0.8653 - val_loss: 0.4238 - val_accuracy: 0.8424\n",
            "Epoch 23/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3633 - accuracy: 0.8594 - val_loss: 0.4289 - val_accuracy: 0.8366\n",
            "Epoch 24/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3633 - accuracy: 0.8619 - val_loss: 0.4346 - val_accuracy: 0.8152\n",
            "Epoch 25/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3652 - accuracy: 0.8589 - val_loss: 0.4327 - val_accuracy: 0.8405\n",
            "Epoch 26/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3652 - accuracy: 0.8594 - val_loss: 0.4239 - val_accuracy: 0.8249\n",
            "Epoch 27/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3638 - accuracy: 0.8580 - val_loss: 0.4277 - val_accuracy: 0.8249\n",
            "Epoch 28/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3631 - accuracy: 0.8604 - val_loss: 0.4361 - val_accuracy: 0.8171\n",
            "Epoch 29/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3639 - accuracy: 0.8677 - val_loss: 0.4369 - val_accuracy: 0.8210\n",
            "Epoch 30/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3639 - accuracy: 0.8643 - val_loss: 0.4382 - val_accuracy: 0.8385\n",
            "Epoch 31/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3640 - accuracy: 0.8580 - val_loss: 0.4172 - val_accuracy: 0.8424\n",
            "Epoch 32/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3639 - accuracy: 0.8604 - val_loss: 0.4187 - val_accuracy: 0.8463\n",
            "Epoch 33/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3626 - accuracy: 0.8633 - val_loss: 0.4295 - val_accuracy: 0.8385\n",
            "Epoch 34/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3643 - accuracy: 0.8594 - val_loss: 0.4251 - val_accuracy: 0.8405\n",
            "Epoch 35/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3627 - accuracy: 0.8585 - val_loss: 0.4319 - val_accuracy: 0.8132\n",
            "Epoch 36/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3642 - accuracy: 0.8585 - val_loss: 0.4219 - val_accuracy: 0.8444\n",
            "Epoch 37/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3636 - accuracy: 0.8589 - val_loss: 0.4316 - val_accuracy: 0.8346\n",
            "Epoch 38/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3627 - accuracy: 0.8614 - val_loss: 0.4290 - val_accuracy: 0.8346\n",
            "Epoch 39/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3622 - accuracy: 0.8614 - val_loss: 0.4167 - val_accuracy: 0.8444\n",
            "Epoch 40/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3639 - accuracy: 0.8604 - val_loss: 0.4317 - val_accuracy: 0.8307\n",
            "Epoch 41/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3624 - accuracy: 0.8643 - val_loss: 0.4232 - val_accuracy: 0.8385\n",
            "Epoch 42/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3620 - accuracy: 0.8638 - val_loss: 0.4345 - val_accuracy: 0.8132\n",
            "Epoch 43/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3640 - accuracy: 0.8662 - val_loss: 0.4252 - val_accuracy: 0.8288\n",
            "Epoch 44/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3649 - accuracy: 0.8575 - val_loss: 0.4209 - val_accuracy: 0.8405\n",
            "Epoch 45/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3645 - accuracy: 0.8589 - val_loss: 0.4402 - val_accuracy: 0.8191\n",
            "Epoch 46/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3628 - accuracy: 0.8624 - val_loss: 0.4383 - val_accuracy: 0.8171\n",
            "Epoch 47/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3624 - accuracy: 0.8658 - val_loss: 0.4258 - val_accuracy: 0.8385\n",
            "Epoch 48/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3630 - accuracy: 0.8648 - val_loss: 0.4337 - val_accuracy: 0.8405\n",
            "Epoch 49/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3618 - accuracy: 0.8638 - val_loss: 0.4331 - val_accuracy: 0.8288\n",
            "Epoch 50/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3621 - accuracy: 0.8604 - val_loss: 0.4352 - val_accuracy: 0.8424\n",
            "Training Model 3\n",
            "Epoch 1/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3505 - accuracy: 0.8658 - val_loss: 0.3997 - val_accuracy: 0.8487\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.8658 - val_loss: 0.4128 - val_accuracy: 0.8410\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3489 - accuracy: 0.8682 - val_loss: 0.4154 - val_accuracy: 0.8429\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3490 - accuracy: 0.8696 - val_loss: 0.4216 - val_accuracy: 0.8314\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3495 - accuracy: 0.8653 - val_loss: 0.4137 - val_accuracy: 0.8410\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3495 - accuracy: 0.8667 - val_loss: 0.4062 - val_accuracy: 0.8506\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3479 - accuracy: 0.8710 - val_loss: 0.4003 - val_accuracy: 0.8506\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3480 - accuracy: 0.8667 - val_loss: 0.3988 - val_accuracy: 0.8563\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3475 - accuracy: 0.8691 - val_loss: 0.4005 - val_accuracy: 0.8506\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3474 - accuracy: 0.8653 - val_loss: 0.4218 - val_accuracy: 0.8276\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3478 - accuracy: 0.8686 - val_loss: 0.4060 - val_accuracy: 0.8410\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8686 - val_loss: 0.4808 - val_accuracy: 0.8008\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3490 - accuracy: 0.8634 - val_loss: 0.4015 - val_accuracy: 0.8448\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3487 - accuracy: 0.8686 - val_loss: 0.4038 - val_accuracy: 0.8563\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3472 - accuracy: 0.8696 - val_loss: 0.4155 - val_accuracy: 0.8506\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3491 - accuracy: 0.8691 - val_loss: 0.4068 - val_accuracy: 0.8429\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3494 - accuracy: 0.8643 - val_loss: 0.4070 - val_accuracy: 0.8448\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3460 - accuracy: 0.8691 - val_loss: 0.3987 - val_accuracy: 0.8525\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3466 - accuracy: 0.8653 - val_loss: 0.4339 - val_accuracy: 0.8391\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3484 - accuracy: 0.8658 - val_loss: 0.4002 - val_accuracy: 0.8544\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3473 - accuracy: 0.8701 - val_loss: 0.4031 - val_accuracy: 0.8525\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3473 - accuracy: 0.8734 - val_loss: 0.4109 - val_accuracy: 0.8487\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3454 - accuracy: 0.8696 - val_loss: 0.4142 - val_accuracy: 0.8448\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3483 - accuracy: 0.8763 - val_loss: 0.4017 - val_accuracy: 0.8448\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3472 - accuracy: 0.8706 - val_loss: 0.4051 - val_accuracy: 0.8372\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3458 - accuracy: 0.8744 - val_loss: 0.4179 - val_accuracy: 0.8314\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3490 - accuracy: 0.8658 - val_loss: 0.4050 - val_accuracy: 0.8467\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3476 - accuracy: 0.8710 - val_loss: 0.4061 - val_accuracy: 0.8467\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3459 - accuracy: 0.8739 - val_loss: 0.4033 - val_accuracy: 0.8525\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3453 - accuracy: 0.8715 - val_loss: 0.4117 - val_accuracy: 0.8448\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8739 - val_loss: 0.4609 - val_accuracy: 0.8065\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3472 - accuracy: 0.8696 - val_loss: 0.4031 - val_accuracy: 0.8391\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3443 - accuracy: 0.8730 - val_loss: 0.4054 - val_accuracy: 0.8487\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3452 - accuracy: 0.8730 - val_loss: 0.4079 - val_accuracy: 0.8391\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.8710 - val_loss: 0.4810 - val_accuracy: 0.8218\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3477 - accuracy: 0.8686 - val_loss: 0.4153 - val_accuracy: 0.8391\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3464 - accuracy: 0.8725 - val_loss: 0.4150 - val_accuracy: 0.8352\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8677 - val_loss: 0.4038 - val_accuracy: 0.8372\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3460 - accuracy: 0.8648 - val_loss: 0.4031 - val_accuracy: 0.8391\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3473 - accuracy: 0.8734 - val_loss: 0.4030 - val_accuracy: 0.8448\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 0.8720 - val_loss: 0.4119 - val_accuracy: 0.8372\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8691 - val_loss: 0.4123 - val_accuracy: 0.8429\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3467 - accuracy: 0.8682 - val_loss: 0.4025 - val_accuracy: 0.8467\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3449 - accuracy: 0.8768 - val_loss: 0.4159 - val_accuracy: 0.8410\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3470 - accuracy: 0.8672 - val_loss: 0.4491 - val_accuracy: 0.8199\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3481 - accuracy: 0.8667 - val_loss: 0.4125 - val_accuracy: 0.8487\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3448 - accuracy: 0.8739 - val_loss: 0.4132 - val_accuracy: 0.8372\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3478 - accuracy: 0.8720 - val_loss: 0.4111 - val_accuracy: 0.8563\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3481 - accuracy: 0.8710 - val_loss: 0.4093 - val_accuracy: 0.8448\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3485 - accuracy: 0.8696 - val_loss: 0.4062 - val_accuracy: 0.8487\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7945\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6055 - accuracy: 0.7231\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6008 - accuracy: 0.7407\n",
            "\n",
            "Iteration: 2\n",
            "Weights extracted succesfully\n",
            "Weights averaged successfully\n",
            "New weights assigned successfully\n",
            "Training Model 1\n",
            "Epoch 1/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.8547 - val_loss: 0.3920 - val_accuracy: 0.8544\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3728 - accuracy: 0.8547 - val_loss: 0.3927 - val_accuracy: 0.8582\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3733 - accuracy: 0.8610 - val_loss: 0.3954 - val_accuracy: 0.8429\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3716 - accuracy: 0.8562 - val_loss: 0.4830 - val_accuracy: 0.7835\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3761 - accuracy: 0.8562 - val_loss: 0.3869 - val_accuracy: 0.8487\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3725 - accuracy: 0.8557 - val_loss: 0.3956 - val_accuracy: 0.8582\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3715 - accuracy: 0.8595 - val_loss: 0.3929 - val_accuracy: 0.8544\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3723 - accuracy: 0.8595 - val_loss: 0.3977 - val_accuracy: 0.8602\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3732 - accuracy: 0.8600 - val_loss: 0.3894 - val_accuracy: 0.8659\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3730 - accuracy: 0.8586 - val_loss: 0.3835 - val_accuracy: 0.8582\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3735 - accuracy: 0.8571 - val_loss: 0.3978 - val_accuracy: 0.8525\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3729 - accuracy: 0.8547 - val_loss: 0.3889 - val_accuracy: 0.8640\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3715 - accuracy: 0.8605 - val_loss: 0.4067 - val_accuracy: 0.8352\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3728 - accuracy: 0.8552 - val_loss: 0.4024 - val_accuracy: 0.8525\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3713 - accuracy: 0.8581 - val_loss: 0.3877 - val_accuracy: 0.8659\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3703 - accuracy: 0.8615 - val_loss: 0.3899 - val_accuracy: 0.8621\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3702 - accuracy: 0.8615 - val_loss: 0.3844 - val_accuracy: 0.8582\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3728 - accuracy: 0.8562 - val_loss: 0.3938 - val_accuracy: 0.8640\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3705 - accuracy: 0.8595 - val_loss: 0.3973 - val_accuracy: 0.8563\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3721 - accuracy: 0.8567 - val_loss: 0.3864 - val_accuracy: 0.8640\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3705 - accuracy: 0.8619 - val_loss: 0.3905 - val_accuracy: 0.8621\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3705 - accuracy: 0.8557 - val_loss: 0.4109 - val_accuracy: 0.8352\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3726 - accuracy: 0.8624 - val_loss: 0.3915 - val_accuracy: 0.8506\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3723 - accuracy: 0.8562 - val_loss: 0.3867 - val_accuracy: 0.8640\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3721 - accuracy: 0.8591 - val_loss: 0.4129 - val_accuracy: 0.8352\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3738 - accuracy: 0.8543 - val_loss: 0.3954 - val_accuracy: 0.8487\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3715 - accuracy: 0.8615 - val_loss: 0.4059 - val_accuracy: 0.8506\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3727 - accuracy: 0.8562 - val_loss: 0.3941 - val_accuracy: 0.8544\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3713 - accuracy: 0.8567 - val_loss: 0.3895 - val_accuracy: 0.8525\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3700 - accuracy: 0.8581 - val_loss: 0.3936 - val_accuracy: 0.8391\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3707 - accuracy: 0.8586 - val_loss: 0.3905 - val_accuracy: 0.8697\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3710 - accuracy: 0.8571 - val_loss: 0.4014 - val_accuracy: 0.8506\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3723 - accuracy: 0.8586 - val_loss: 0.3961 - val_accuracy: 0.8448\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3710 - accuracy: 0.8571 - val_loss: 0.3982 - val_accuracy: 0.8563\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3719 - accuracy: 0.8528 - val_loss: 0.3919 - val_accuracy: 0.8659\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8586 - val_loss: 0.3954 - val_accuracy: 0.8582\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8605 - val_loss: 0.3924 - val_accuracy: 0.8582\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3725 - accuracy: 0.8519 - val_loss: 0.3908 - val_accuracy: 0.8659\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3706 - accuracy: 0.8581 - val_loss: 0.3879 - val_accuracy: 0.8716\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3700 - accuracy: 0.8610 - val_loss: 0.3912 - val_accuracy: 0.8563\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3718 - accuracy: 0.8557 - val_loss: 0.3946 - val_accuracy: 0.8429\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3712 - accuracy: 0.8538 - val_loss: 0.3968 - val_accuracy: 0.8448\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3728 - accuracy: 0.8557 - val_loss: 0.3974 - val_accuracy: 0.8544\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3716 - accuracy: 0.8552 - val_loss: 0.3956 - val_accuracy: 0.8506\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3704 - accuracy: 0.8610 - val_loss: 0.3977 - val_accuracy: 0.8640\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3707 - accuracy: 0.8619 - val_loss: 0.3927 - val_accuracy: 0.8525\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3701 - accuracy: 0.8634 - val_loss: 0.3997 - val_accuracy: 0.8640\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3719 - accuracy: 0.8538 - val_loss: 0.3945 - val_accuracy: 0.8467\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3712 - accuracy: 0.8552 - val_loss: 0.4013 - val_accuracy: 0.8410\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3716 - accuracy: 0.8547 - val_loss: 0.4042 - val_accuracy: 0.8391\n",
            "Training Model 2\n",
            "Epoch 1/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3651 - accuracy: 0.8555 - val_loss: 0.4201 - val_accuracy: 0.8346\n",
            "Epoch 2/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3618 - accuracy: 0.8580 - val_loss: 0.4355 - val_accuracy: 0.8230\n",
            "Epoch 3/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3624 - accuracy: 0.8594 - val_loss: 0.4291 - val_accuracy: 0.8191\n",
            "Epoch 4/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3631 - accuracy: 0.8570 - val_loss: 0.4344 - val_accuracy: 0.8113\n",
            "Epoch 5/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3637 - accuracy: 0.8604 - val_loss: 0.4195 - val_accuracy: 0.8385\n",
            "Epoch 6/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3621 - accuracy: 0.8565 - val_loss: 0.4262 - val_accuracy: 0.8366\n",
            "Epoch 7/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3620 - accuracy: 0.8628 - val_loss: 0.4217 - val_accuracy: 0.8385\n",
            "Epoch 8/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3622 - accuracy: 0.8628 - val_loss: 0.4136 - val_accuracy: 0.8385\n",
            "Epoch 9/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3630 - accuracy: 0.8604 - val_loss: 0.4353 - val_accuracy: 0.8210\n",
            "Epoch 10/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3632 - accuracy: 0.8604 - val_loss: 0.4252 - val_accuracy: 0.8288\n",
            "Epoch 11/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3626 - accuracy: 0.8551 - val_loss: 0.4271 - val_accuracy: 0.8307\n",
            "Epoch 12/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3632 - accuracy: 0.8604 - val_loss: 0.4224 - val_accuracy: 0.8327\n",
            "Epoch 13/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3616 - accuracy: 0.8585 - val_loss: 0.4188 - val_accuracy: 0.8346\n",
            "Epoch 14/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3613 - accuracy: 0.8585 - val_loss: 0.4338 - val_accuracy: 0.8268\n",
            "Epoch 15/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3620 - accuracy: 0.8609 - val_loss: 0.4229 - val_accuracy: 0.8346\n",
            "Epoch 16/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3623 - accuracy: 0.8614 - val_loss: 0.4287 - val_accuracy: 0.8230\n",
            "Epoch 17/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3604 - accuracy: 0.8565 - val_loss: 0.4199 - val_accuracy: 0.8346\n",
            "Epoch 18/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3611 - accuracy: 0.8658 - val_loss: 0.4201 - val_accuracy: 0.8288\n",
            "Epoch 19/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3624 - accuracy: 0.8580 - val_loss: 0.4205 - val_accuracy: 0.8405\n",
            "Epoch 20/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3602 - accuracy: 0.8643 - val_loss: 0.4245 - val_accuracy: 0.8307\n",
            "Epoch 21/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3615 - accuracy: 0.8638 - val_loss: 0.4269 - val_accuracy: 0.8405\n",
            "Epoch 22/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3636 - accuracy: 0.8609 - val_loss: 0.4237 - val_accuracy: 0.8327\n",
            "Epoch 23/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3607 - accuracy: 0.8614 - val_loss: 0.4307 - val_accuracy: 0.8366\n",
            "Epoch 24/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3608 - accuracy: 0.8614 - val_loss: 0.4332 - val_accuracy: 0.8171\n",
            "Epoch 25/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3624 - accuracy: 0.8594 - val_loss: 0.4314 - val_accuracy: 0.8424\n",
            "Epoch 26/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3624 - accuracy: 0.8580 - val_loss: 0.4229 - val_accuracy: 0.8230\n",
            "Epoch 27/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3609 - accuracy: 0.8589 - val_loss: 0.4270 - val_accuracy: 0.8268\n",
            "Epoch 28/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3609 - accuracy: 0.8589 - val_loss: 0.4315 - val_accuracy: 0.8152\n",
            "Epoch 29/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3610 - accuracy: 0.8633 - val_loss: 0.4332 - val_accuracy: 0.8074\n",
            "Epoch 30/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3610 - accuracy: 0.8585 - val_loss: 0.4347 - val_accuracy: 0.8385\n",
            "Epoch 31/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3615 - accuracy: 0.8575 - val_loss: 0.4155 - val_accuracy: 0.8346\n",
            "Epoch 32/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3607 - accuracy: 0.8594 - val_loss: 0.4175 - val_accuracy: 0.8424\n",
            "Epoch 33/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3601 - accuracy: 0.8609 - val_loss: 0.4281 - val_accuracy: 0.8424\n",
            "Epoch 34/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3607 - accuracy: 0.8619 - val_loss: 0.4249 - val_accuracy: 0.8444\n",
            "Epoch 35/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3602 - accuracy: 0.8599 - val_loss: 0.4413 - val_accuracy: 0.8074\n",
            "Epoch 36/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3618 - accuracy: 0.8580 - val_loss: 0.4203 - val_accuracy: 0.8385\n",
            "Epoch 37/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3609 - accuracy: 0.8565 - val_loss: 0.4303 - val_accuracy: 0.8366\n",
            "Epoch 38/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3599 - accuracy: 0.8585 - val_loss: 0.4268 - val_accuracy: 0.8288\n",
            "Epoch 39/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3598 - accuracy: 0.8643 - val_loss: 0.4171 - val_accuracy: 0.8366\n",
            "Epoch 40/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3611 - accuracy: 0.8624 - val_loss: 0.4375 - val_accuracy: 0.8152\n",
            "Epoch 41/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3595 - accuracy: 0.8648 - val_loss: 0.4198 - val_accuracy: 0.8268\n",
            "Epoch 42/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3593 - accuracy: 0.8609 - val_loss: 0.4324 - val_accuracy: 0.8093\n",
            "Epoch 43/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3606 - accuracy: 0.8633 - val_loss: 0.4261 - val_accuracy: 0.8288\n",
            "Epoch 44/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3618 - accuracy: 0.8585 - val_loss: 0.4182 - val_accuracy: 0.8346\n",
            "Epoch 45/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3617 - accuracy: 0.8604 - val_loss: 0.4368 - val_accuracy: 0.8152\n",
            "Epoch 46/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3594 - accuracy: 0.8638 - val_loss: 0.4328 - val_accuracy: 0.8093\n",
            "Epoch 47/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3594 - accuracy: 0.8619 - val_loss: 0.4246 - val_accuracy: 0.8385\n",
            "Epoch 48/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3607 - accuracy: 0.8619 - val_loss: 0.4290 - val_accuracy: 0.8405\n",
            "Epoch 49/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3588 - accuracy: 0.8638 - val_loss: 0.4315 - val_accuracy: 0.8346\n",
            "Epoch 50/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3593 - accuracy: 0.8628 - val_loss: 0.4310 - val_accuracy: 0.8424\n",
            "Training Model 3\n",
            "Epoch 1/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3468 - accuracy: 0.8701 - val_loss: 0.3987 - val_accuracy: 0.8487\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3465 - accuracy: 0.8691 - val_loss: 0.4108 - val_accuracy: 0.8487\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8734 - val_loss: 0.4153 - val_accuracy: 0.8487\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3466 - accuracy: 0.8701 - val_loss: 0.4201 - val_accuracy: 0.8448\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3470 - accuracy: 0.8672 - val_loss: 0.4094 - val_accuracy: 0.8525\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3470 - accuracy: 0.8672 - val_loss: 0.4008 - val_accuracy: 0.8525\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3448 - accuracy: 0.8734 - val_loss: 0.4003 - val_accuracy: 0.8506\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3460 - accuracy: 0.8725 - val_loss: 0.3965 - val_accuracy: 0.8525\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3449 - accuracy: 0.8744 - val_loss: 0.3980 - val_accuracy: 0.8487\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3442 - accuracy: 0.8706 - val_loss: 0.4242 - val_accuracy: 0.8295\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3460 - accuracy: 0.8720 - val_loss: 0.4012 - val_accuracy: 0.8448\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3437 - accuracy: 0.8720 - val_loss: 0.4907 - val_accuracy: 0.7950\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3474 - accuracy: 0.8624 - val_loss: 0.4042 - val_accuracy: 0.8506\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3469 - accuracy: 0.8691 - val_loss: 0.3993 - val_accuracy: 0.8582\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3450 - accuracy: 0.8744 - val_loss: 0.4073 - val_accuracy: 0.8640\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3471 - accuracy: 0.8682 - val_loss: 0.4005 - val_accuracy: 0.8410\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3471 - accuracy: 0.8677 - val_loss: 0.4022 - val_accuracy: 0.8602\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3438 - accuracy: 0.8734 - val_loss: 0.3965 - val_accuracy: 0.8506\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3447 - accuracy: 0.8696 - val_loss: 0.4311 - val_accuracy: 0.8429\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3464 - accuracy: 0.8672 - val_loss: 0.3979 - val_accuracy: 0.8621\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3458 - accuracy: 0.8710 - val_loss: 0.3995 - val_accuracy: 0.8487\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3454 - accuracy: 0.8749 - val_loss: 0.4091 - val_accuracy: 0.8506\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3437 - accuracy: 0.8734 - val_loss: 0.4117 - val_accuracy: 0.8487\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8758 - val_loss: 0.3972 - val_accuracy: 0.8506\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3456 - accuracy: 0.8658 - val_loss: 0.4051 - val_accuracy: 0.8410\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3438 - accuracy: 0.8734 - val_loss: 0.4197 - val_accuracy: 0.8314\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3478 - accuracy: 0.8686 - val_loss: 0.4037 - val_accuracy: 0.8544\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3459 - accuracy: 0.8691 - val_loss: 0.4047 - val_accuracy: 0.8544\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8744 - val_loss: 0.4025 - val_accuracy: 0.8525\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3439 - accuracy: 0.8710 - val_loss: 0.4113 - val_accuracy: 0.8467\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.8739 - val_loss: 0.4647 - val_accuracy: 0.8199\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 0.8734 - val_loss: 0.4028 - val_accuracy: 0.8448\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3424 - accuracy: 0.8773 - val_loss: 0.4047 - val_accuracy: 0.8467\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.8754 - val_loss: 0.4082 - val_accuracy: 0.8429\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3450 - accuracy: 0.8758 - val_loss: 0.4811 - val_accuracy: 0.8218\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3472 - accuracy: 0.8696 - val_loss: 0.4083 - val_accuracy: 0.8429\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.8725 - val_loss: 0.4143 - val_accuracy: 0.8410\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3451 - accuracy: 0.8691 - val_loss: 0.4035 - val_accuracy: 0.8410\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3442 - accuracy: 0.8715 - val_loss: 0.4038 - val_accuracy: 0.8391\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3465 - accuracy: 0.8706 - val_loss: 0.4024 - val_accuracy: 0.8506\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3437 - accuracy: 0.8778 - val_loss: 0.4126 - val_accuracy: 0.8448\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3446 - accuracy: 0.8696 - val_loss: 0.4092 - val_accuracy: 0.8487\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3458 - accuracy: 0.8696 - val_loss: 0.3995 - val_accuracy: 0.8582\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3435 - accuracy: 0.8744 - val_loss: 0.4152 - val_accuracy: 0.8448\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3460 - accuracy: 0.8696 - val_loss: 0.4485 - val_accuracy: 0.8238\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3467 - accuracy: 0.8696 - val_loss: 0.4114 - val_accuracy: 0.8582\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3435 - accuracy: 0.8730 - val_loss: 0.4182 - val_accuracy: 0.8352\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3476 - accuracy: 0.8715 - val_loss: 0.4091 - val_accuracy: 0.8621\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.8730 - val_loss: 0.4118 - val_accuracy: 0.8487\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3468 - accuracy: 0.8749 - val_loss: 0.4078 - val_accuracy: 0.8467\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7896\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.7182\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6046 - accuracy: 0.7436\n",
            "\n",
            "Iteration: 3\n",
            "Weights extracted succesfully\n",
            "Weights averaged successfully\n",
            "New weights assigned successfully\n",
            "Training Model 1\n",
            "Epoch 1/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3716 - accuracy: 0.8552 - val_loss: 0.3918 - val_accuracy: 0.8582\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3714 - accuracy: 0.8586 - val_loss: 0.3951 - val_accuracy: 0.8659\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3712 - accuracy: 0.8586 - val_loss: 0.3928 - val_accuracy: 0.8544\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3695 - accuracy: 0.8586 - val_loss: 0.4867 - val_accuracy: 0.7816\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.8547 - val_loss: 0.3862 - val_accuracy: 0.8487\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3701 - accuracy: 0.8586 - val_loss: 0.3960 - val_accuracy: 0.8582\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3694 - accuracy: 0.8576 - val_loss: 0.3968 - val_accuracy: 0.8525\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3700 - accuracy: 0.8571 - val_loss: 0.4005 - val_accuracy: 0.8602\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3715 - accuracy: 0.8576 - val_loss: 0.3917 - val_accuracy: 0.8602\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3706 - accuracy: 0.8571 - val_loss: 0.3867 - val_accuracy: 0.8621\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3714 - accuracy: 0.8595 - val_loss: 0.3976 - val_accuracy: 0.8467\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3717 - accuracy: 0.8552 - val_loss: 0.3892 - val_accuracy: 0.8621\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3698 - accuracy: 0.8595 - val_loss: 0.4083 - val_accuracy: 0.8295\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3711 - accuracy: 0.8562 - val_loss: 0.4015 - val_accuracy: 0.8544\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3694 - accuracy: 0.8543 - val_loss: 0.3909 - val_accuracy: 0.8640\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3685 - accuracy: 0.8629 - val_loss: 0.3917 - val_accuracy: 0.8621\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3683 - accuracy: 0.8624 - val_loss: 0.3853 - val_accuracy: 0.8640\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3715 - accuracy: 0.8552 - val_loss: 0.3948 - val_accuracy: 0.8525\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3692 - accuracy: 0.8591 - val_loss: 0.3978 - val_accuracy: 0.8602\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3706 - accuracy: 0.8576 - val_loss: 0.3883 - val_accuracy: 0.8659\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3695 - accuracy: 0.8624 - val_loss: 0.3927 - val_accuracy: 0.8640\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3692 - accuracy: 0.8547 - val_loss: 0.4119 - val_accuracy: 0.8333\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3715 - accuracy: 0.8624 - val_loss: 0.3946 - val_accuracy: 0.8544\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3710 - accuracy: 0.8567 - val_loss: 0.3891 - val_accuracy: 0.8659\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3705 - accuracy: 0.8610 - val_loss: 0.4229 - val_accuracy: 0.8257\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3735 - accuracy: 0.8533 - val_loss: 0.3969 - val_accuracy: 0.8467\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3702 - accuracy: 0.8629 - val_loss: 0.4074 - val_accuracy: 0.8525\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3707 - accuracy: 0.8557 - val_loss: 0.3948 - val_accuracy: 0.8525\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3696 - accuracy: 0.8567 - val_loss: 0.3901 - val_accuracy: 0.8602\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3689 - accuracy: 0.8576 - val_loss: 0.3970 - val_accuracy: 0.8487\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3698 - accuracy: 0.8605 - val_loss: 0.3932 - val_accuracy: 0.8621\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3703 - accuracy: 0.8562 - val_loss: 0.4023 - val_accuracy: 0.8448\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3713 - accuracy: 0.8595 - val_loss: 0.3936 - val_accuracy: 0.8602\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3703 - accuracy: 0.8567 - val_loss: 0.3988 - val_accuracy: 0.8544\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3707 - accuracy: 0.8509 - val_loss: 0.3931 - val_accuracy: 0.8602\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3685 - accuracy: 0.8591 - val_loss: 0.3965 - val_accuracy: 0.8582\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3708 - accuracy: 0.8610 - val_loss: 0.3935 - val_accuracy: 0.8621\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3713 - accuracy: 0.8543 - val_loss: 0.3937 - val_accuracy: 0.8621\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3699 - accuracy: 0.8571 - val_loss: 0.3883 - val_accuracy: 0.8697\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3691 - accuracy: 0.8591 - val_loss: 0.3926 - val_accuracy: 0.8544\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3708 - accuracy: 0.8571 - val_loss: 0.3945 - val_accuracy: 0.8429\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3707 - accuracy: 0.8571 - val_loss: 0.3934 - val_accuracy: 0.8563\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.8571 - val_loss: 0.4002 - val_accuracy: 0.8506\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3699 - accuracy: 0.8619 - val_loss: 0.3955 - val_accuracy: 0.8544\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3697 - accuracy: 0.8610 - val_loss: 0.3979 - val_accuracy: 0.8640\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3697 - accuracy: 0.8629 - val_loss: 0.3934 - val_accuracy: 0.8544\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3683 - accuracy: 0.8634 - val_loss: 0.3973 - val_accuracy: 0.8678\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3705 - accuracy: 0.8562 - val_loss: 0.3971 - val_accuracy: 0.8410\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8538 - val_loss: 0.4002 - val_accuracy: 0.8391\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3707 - accuracy: 0.8576 - val_loss: 0.4008 - val_accuracy: 0.8429\n",
            "Training Model 2\n",
            "Epoch 1/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3626 - accuracy: 0.8560 - val_loss: 0.4151 - val_accuracy: 0.8327\n",
            "Epoch 2/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3589 - accuracy: 0.8599 - val_loss: 0.4318 - val_accuracy: 0.8210\n",
            "Epoch 3/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3599 - accuracy: 0.8589 - val_loss: 0.4249 - val_accuracy: 0.8230\n",
            "Epoch 4/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3602 - accuracy: 0.8565 - val_loss: 0.4300 - val_accuracy: 0.8093\n",
            "Epoch 5/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3609 - accuracy: 0.8570 - val_loss: 0.4159 - val_accuracy: 0.8366\n",
            "Epoch 6/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3595 - accuracy: 0.8609 - val_loss: 0.4227 - val_accuracy: 0.8385\n",
            "Epoch 7/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3596 - accuracy: 0.8609 - val_loss: 0.4183 - val_accuracy: 0.8405\n",
            "Epoch 8/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3591 - accuracy: 0.8628 - val_loss: 0.4116 - val_accuracy: 0.8346\n",
            "Epoch 9/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3603 - accuracy: 0.8594 - val_loss: 0.4289 - val_accuracy: 0.8288\n",
            "Epoch 10/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3608 - accuracy: 0.8609 - val_loss: 0.4235 - val_accuracy: 0.8385\n",
            "Epoch 11/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3599 - accuracy: 0.8604 - val_loss: 0.4276 - val_accuracy: 0.8366\n",
            "Epoch 12/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3604 - accuracy: 0.8619 - val_loss: 0.4193 - val_accuracy: 0.8327\n",
            "Epoch 13/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3592 - accuracy: 0.8580 - val_loss: 0.4144 - val_accuracy: 0.8327\n",
            "Epoch 14/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3586 - accuracy: 0.8633 - val_loss: 0.4306 - val_accuracy: 0.8307\n",
            "Epoch 15/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3596 - accuracy: 0.8624 - val_loss: 0.4198 - val_accuracy: 0.8327\n",
            "Epoch 16/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3597 - accuracy: 0.8599 - val_loss: 0.4282 - val_accuracy: 0.8210\n",
            "Epoch 17/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3581 - accuracy: 0.8575 - val_loss: 0.4181 - val_accuracy: 0.8385\n",
            "Epoch 18/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3588 - accuracy: 0.8628 - val_loss: 0.4183 - val_accuracy: 0.8405\n",
            "Epoch 19/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3603 - accuracy: 0.8619 - val_loss: 0.4197 - val_accuracy: 0.8424\n",
            "Epoch 20/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3582 - accuracy: 0.8653 - val_loss: 0.4220 - val_accuracy: 0.8346\n",
            "Epoch 21/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3586 - accuracy: 0.8604 - val_loss: 0.4253 - val_accuracy: 0.8366\n",
            "Epoch 22/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3613 - accuracy: 0.8628 - val_loss: 0.4203 - val_accuracy: 0.8366\n",
            "Epoch 23/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3583 - accuracy: 0.8580 - val_loss: 0.4283 - val_accuracy: 0.8385\n",
            "Epoch 24/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3584 - accuracy: 0.8614 - val_loss: 0.4303 - val_accuracy: 0.8230\n",
            "Epoch 25/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3597 - accuracy: 0.8604 - val_loss: 0.4298 - val_accuracy: 0.8444\n",
            "Epoch 26/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3605 - accuracy: 0.8585 - val_loss: 0.4202 - val_accuracy: 0.8210\n",
            "Epoch 27/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3588 - accuracy: 0.8585 - val_loss: 0.4263 - val_accuracy: 0.8288\n",
            "Epoch 28/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3589 - accuracy: 0.8575 - val_loss: 0.4311 - val_accuracy: 0.8093\n",
            "Epoch 29/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3586 - accuracy: 0.8648 - val_loss: 0.4294 - val_accuracy: 0.8074\n",
            "Epoch 30/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3591 - accuracy: 0.8628 - val_loss: 0.4346 - val_accuracy: 0.8327\n",
            "Epoch 31/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3590 - accuracy: 0.8599 - val_loss: 0.4126 - val_accuracy: 0.8327\n",
            "Epoch 32/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3580 - accuracy: 0.8628 - val_loss: 0.4161 - val_accuracy: 0.8502\n",
            "Epoch 33/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3585 - accuracy: 0.8624 - val_loss: 0.4270 - val_accuracy: 0.8424\n",
            "Epoch 34/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3586 - accuracy: 0.8604 - val_loss: 0.4236 - val_accuracy: 0.8424\n",
            "Epoch 35/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3586 - accuracy: 0.8570 - val_loss: 0.4360 - val_accuracy: 0.8054\n",
            "Epoch 36/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3596 - accuracy: 0.8619 - val_loss: 0.4178 - val_accuracy: 0.8405\n",
            "Epoch 37/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3593 - accuracy: 0.8594 - val_loss: 0.4312 - val_accuracy: 0.8249\n",
            "Epoch 38/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3584 - accuracy: 0.8585 - val_loss: 0.4240 - val_accuracy: 0.8268\n",
            "Epoch 39/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3576 - accuracy: 0.8614 - val_loss: 0.4144 - val_accuracy: 0.8444\n",
            "Epoch 40/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3588 - accuracy: 0.8628 - val_loss: 0.4336 - val_accuracy: 0.8230\n",
            "Epoch 41/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3576 - accuracy: 0.8653 - val_loss: 0.4163 - val_accuracy: 0.8444\n",
            "Epoch 42/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3578 - accuracy: 0.8614 - val_loss: 0.4284 - val_accuracy: 0.8113\n",
            "Epoch 43/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3586 - accuracy: 0.8614 - val_loss: 0.4250 - val_accuracy: 0.8288\n",
            "Epoch 44/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3600 - accuracy: 0.8585 - val_loss: 0.4161 - val_accuracy: 0.8424\n",
            "Epoch 45/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3598 - accuracy: 0.8604 - val_loss: 0.4286 - val_accuracy: 0.8249\n",
            "Epoch 46/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3570 - accuracy: 0.8633 - val_loss: 0.4296 - val_accuracy: 0.8093\n",
            "Epoch 47/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3575 - accuracy: 0.8589 - val_loss: 0.4228 - val_accuracy: 0.8463\n",
            "Epoch 48/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3584 - accuracy: 0.8633 - val_loss: 0.4270 - val_accuracy: 0.8405\n",
            "Epoch 49/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3570 - accuracy: 0.8619 - val_loss: 0.4308 - val_accuracy: 0.8327\n",
            "Epoch 50/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3575 - accuracy: 0.8604 - val_loss: 0.4314 - val_accuracy: 0.8482\n",
            "Training Model 3\n",
            "Epoch 1/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3455 - accuracy: 0.8725 - val_loss: 0.3994 - val_accuracy: 0.8487\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8696 - val_loss: 0.4095 - val_accuracy: 0.8525\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3450 - accuracy: 0.8701 - val_loss: 0.4122 - val_accuracy: 0.8563\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.8739 - val_loss: 0.4189 - val_accuracy: 0.8467\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3454 - accuracy: 0.8653 - val_loss: 0.4095 - val_accuracy: 0.8544\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3461 - accuracy: 0.8710 - val_loss: 0.4001 - val_accuracy: 0.8525\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3433 - accuracy: 0.8758 - val_loss: 0.4006 - val_accuracy: 0.8487\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3448 - accuracy: 0.8730 - val_loss: 0.3956 - val_accuracy: 0.8563\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3438 - accuracy: 0.8754 - val_loss: 0.3987 - val_accuracy: 0.8487\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3434 - accuracy: 0.8677 - val_loss: 0.4270 - val_accuracy: 0.8410\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3455 - accuracy: 0.8696 - val_loss: 0.4024 - val_accuracy: 0.8429\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3430 - accuracy: 0.8706 - val_loss: 0.4982 - val_accuracy: 0.7969\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3472 - accuracy: 0.8663 - val_loss: 0.4056 - val_accuracy: 0.8429\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3464 - accuracy: 0.8706 - val_loss: 0.3993 - val_accuracy: 0.8621\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3440 - accuracy: 0.8749 - val_loss: 0.4072 - val_accuracy: 0.8582\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3462 - accuracy: 0.8672 - val_loss: 0.4009 - val_accuracy: 0.8372\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3460 - accuracy: 0.8701 - val_loss: 0.4020 - val_accuracy: 0.8544\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.8720 - val_loss: 0.3972 - val_accuracy: 0.8563\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3438 - accuracy: 0.8710 - val_loss: 0.4352 - val_accuracy: 0.8410\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3456 - accuracy: 0.8691 - val_loss: 0.3989 - val_accuracy: 0.8582\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3451 - accuracy: 0.8691 - val_loss: 0.3993 - val_accuracy: 0.8467\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3445 - accuracy: 0.8730 - val_loss: 0.4095 - val_accuracy: 0.8563\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3427 - accuracy: 0.8725 - val_loss: 0.4134 - val_accuracy: 0.8487\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.8749 - val_loss: 0.3977 - val_accuracy: 0.8506\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3443 - accuracy: 0.8672 - val_loss: 0.4061 - val_accuracy: 0.8467\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3433 - accuracy: 0.8739 - val_loss: 0.4227 - val_accuracy: 0.8276\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3469 - accuracy: 0.8686 - val_loss: 0.4010 - val_accuracy: 0.8563\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3450 - accuracy: 0.8686 - val_loss: 0.4046 - val_accuracy: 0.8506\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.8763 - val_loss: 0.4023 - val_accuracy: 0.8563\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.8706 - val_loss: 0.4118 - val_accuracy: 0.8448\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3443 - accuracy: 0.8730 - val_loss: 0.4664 - val_accuracy: 0.8161\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3452 - accuracy: 0.8744 - val_loss: 0.4028 - val_accuracy: 0.8467\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3419 - accuracy: 0.8754 - val_loss: 0.4044 - val_accuracy: 0.8448\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8763 - val_loss: 0.4085 - val_accuracy: 0.8391\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3444 - accuracy: 0.8739 - val_loss: 0.4774 - val_accuracy: 0.8238\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3463 - accuracy: 0.8701 - val_loss: 0.4063 - val_accuracy: 0.8563\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3432 - accuracy: 0.8710 - val_loss: 0.4141 - val_accuracy: 0.8410\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3444 - accuracy: 0.8701 - val_loss: 0.4040 - val_accuracy: 0.8391\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3439 - accuracy: 0.8696 - val_loss: 0.4055 - val_accuracy: 0.8372\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 0.8715 - val_loss: 0.4031 - val_accuracy: 0.8525\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3430 - accuracy: 0.8763 - val_loss: 0.4129 - val_accuracy: 0.8448\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3442 - accuracy: 0.8686 - val_loss: 0.4092 - val_accuracy: 0.8487\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3452 - accuracy: 0.8701 - val_loss: 0.3998 - val_accuracy: 0.8563\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3430 - accuracy: 0.8744 - val_loss: 0.4167 - val_accuracy: 0.8429\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3459 - accuracy: 0.8696 - val_loss: 0.4487 - val_accuracy: 0.8276\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3461 - accuracy: 0.8672 - val_loss: 0.4116 - val_accuracy: 0.8582\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3432 - accuracy: 0.8701 - val_loss: 0.4179 - val_accuracy: 0.8372\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3468 - accuracy: 0.8696 - val_loss: 0.4095 - val_accuracy: 0.8621\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3455 - accuracy: 0.8730 - val_loss: 0.4115 - val_accuracy: 0.8506\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3465 - accuracy: 0.8734 - val_loss: 0.4075 - val_accuracy: 0.8429\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.4513 - accuracy: 0.7808\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6056 - accuracy: 0.7231\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6069 - accuracy: 0.7436\n",
            "\n",
            "Iteration: 4\n",
            "Weights extracted succesfully\n",
            "Weights averaged successfully\n",
            "New weights assigned successfully\n",
            "Training Model 1\n",
            "Epoch 1/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3704 - accuracy: 0.8595 - val_loss: 0.3929 - val_accuracy: 0.8602\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3703 - accuracy: 0.8619 - val_loss: 0.3976 - val_accuracy: 0.8621\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3698 - accuracy: 0.8591 - val_loss: 0.3933 - val_accuracy: 0.8602\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3683 - accuracy: 0.8591 - val_loss: 0.4970 - val_accuracy: 0.7739\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3743 - accuracy: 0.8552 - val_loss: 0.3858 - val_accuracy: 0.8506\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3698 - accuracy: 0.8595 - val_loss: 0.3955 - val_accuracy: 0.8582\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3685 - accuracy: 0.8567 - val_loss: 0.3967 - val_accuracy: 0.8487\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3693 - accuracy: 0.8581 - val_loss: 0.4011 - val_accuracy: 0.8563\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3702 - accuracy: 0.8571 - val_loss: 0.3929 - val_accuracy: 0.8621\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3694 - accuracy: 0.8552 - val_loss: 0.3860 - val_accuracy: 0.8582\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3705 - accuracy: 0.8624 - val_loss: 0.3970 - val_accuracy: 0.8448\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3697 - accuracy: 0.8581 - val_loss: 0.3904 - val_accuracy: 0.8640\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3681 - accuracy: 0.8610 - val_loss: 0.4100 - val_accuracy: 0.8295\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3699 - accuracy: 0.8581 - val_loss: 0.4006 - val_accuracy: 0.8621\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3685 - accuracy: 0.8533 - val_loss: 0.3904 - val_accuracy: 0.8621\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3679 - accuracy: 0.8629 - val_loss: 0.3912 - val_accuracy: 0.8563\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3672 - accuracy: 0.8624 - val_loss: 0.3839 - val_accuracy: 0.8621\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3701 - accuracy: 0.8581 - val_loss: 0.3941 - val_accuracy: 0.8544\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3678 - accuracy: 0.8605 - val_loss: 0.3981 - val_accuracy: 0.8640\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3697 - accuracy: 0.8576 - val_loss: 0.3884 - val_accuracy: 0.8640\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3682 - accuracy: 0.8615 - val_loss: 0.3915 - val_accuracy: 0.8697\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3685 - accuracy: 0.8538 - val_loss: 0.4043 - val_accuracy: 0.8257\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3700 - accuracy: 0.8619 - val_loss: 0.3937 - val_accuracy: 0.8563\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3701 - accuracy: 0.8557 - val_loss: 0.3881 - val_accuracy: 0.8678\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3690 - accuracy: 0.8586 - val_loss: 0.4239 - val_accuracy: 0.8218\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3725 - accuracy: 0.8538 - val_loss: 0.3954 - val_accuracy: 0.8448\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3684 - accuracy: 0.8624 - val_loss: 0.4075 - val_accuracy: 0.8506\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3692 - accuracy: 0.8543 - val_loss: 0.3919 - val_accuracy: 0.8582\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3686 - accuracy: 0.8571 - val_loss: 0.3883 - val_accuracy: 0.8659\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3675 - accuracy: 0.8629 - val_loss: 0.3947 - val_accuracy: 0.8506\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3686 - accuracy: 0.8610 - val_loss: 0.3936 - val_accuracy: 0.8640\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3688 - accuracy: 0.8610 - val_loss: 0.4006 - val_accuracy: 0.8487\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3696 - accuracy: 0.8581 - val_loss: 0.3939 - val_accuracy: 0.8544\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3690 - accuracy: 0.8567 - val_loss: 0.3972 - val_accuracy: 0.8582\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3698 - accuracy: 0.8519 - val_loss: 0.3920 - val_accuracy: 0.8678\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3676 - accuracy: 0.8610 - val_loss: 0.3957 - val_accuracy: 0.8621\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3699 - accuracy: 0.8586 - val_loss: 0.3915 - val_accuracy: 0.8602\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3701 - accuracy: 0.8557 - val_loss: 0.3918 - val_accuracy: 0.8602\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3687 - accuracy: 0.8547 - val_loss: 0.3864 - val_accuracy: 0.8602\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3677 - accuracy: 0.8591 - val_loss: 0.3881 - val_accuracy: 0.8563\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3692 - accuracy: 0.8591 - val_loss: 0.3913 - val_accuracy: 0.8506\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3693 - accuracy: 0.8571 - val_loss: 0.3918 - val_accuracy: 0.8563\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3703 - accuracy: 0.8533 - val_loss: 0.4001 - val_accuracy: 0.8525\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3690 - accuracy: 0.8595 - val_loss: 0.3947 - val_accuracy: 0.8602\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3684 - accuracy: 0.8576 - val_loss: 0.3935 - val_accuracy: 0.8582\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3675 - accuracy: 0.8624 - val_loss: 0.3918 - val_accuracy: 0.8582\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3666 - accuracy: 0.8619 - val_loss: 0.3953 - val_accuracy: 0.8602\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3691 - accuracy: 0.8586 - val_loss: 0.3963 - val_accuracy: 0.8429\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3687 - accuracy: 0.8547 - val_loss: 0.3989 - val_accuracy: 0.8448\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3691 - accuracy: 0.8600 - val_loss: 0.4004 - val_accuracy: 0.8429\n",
            "Training Model 2\n",
            "Epoch 1/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3608 - accuracy: 0.8594 - val_loss: 0.4157 - val_accuracy: 0.8385\n",
            "Epoch 2/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3571 - accuracy: 0.8614 - val_loss: 0.4279 - val_accuracy: 0.8230\n",
            "Epoch 3/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3577 - accuracy: 0.8628 - val_loss: 0.4257 - val_accuracy: 0.8210\n",
            "Epoch 4/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3584 - accuracy: 0.8585 - val_loss: 0.4296 - val_accuracy: 0.8035\n",
            "Epoch 5/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3590 - accuracy: 0.8565 - val_loss: 0.4155 - val_accuracy: 0.8482\n",
            "Epoch 6/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3579 - accuracy: 0.8619 - val_loss: 0.4234 - val_accuracy: 0.8463\n",
            "Epoch 7/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3581 - accuracy: 0.8628 - val_loss: 0.4153 - val_accuracy: 0.8385\n",
            "Epoch 8/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3575 - accuracy: 0.8648 - val_loss: 0.4093 - val_accuracy: 0.8385\n",
            "Epoch 9/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3586 - accuracy: 0.8599 - val_loss: 0.4273 - val_accuracy: 0.8405\n",
            "Epoch 10/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3589 - accuracy: 0.8609 - val_loss: 0.4236 - val_accuracy: 0.8385\n",
            "Epoch 11/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3590 - accuracy: 0.8599 - val_loss: 0.4286 - val_accuracy: 0.8366\n",
            "Epoch 12/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3590 - accuracy: 0.8672 - val_loss: 0.4185 - val_accuracy: 0.8405\n",
            "Epoch 13/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3577 - accuracy: 0.8619 - val_loss: 0.4137 - val_accuracy: 0.8444\n",
            "Epoch 14/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3569 - accuracy: 0.8638 - val_loss: 0.4313 - val_accuracy: 0.8327\n",
            "Epoch 15/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3577 - accuracy: 0.8638 - val_loss: 0.4226 - val_accuracy: 0.8346\n",
            "Epoch 16/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3586 - accuracy: 0.8594 - val_loss: 0.4313 - val_accuracy: 0.8268\n",
            "Epoch 17/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3572 - accuracy: 0.8575 - val_loss: 0.4175 - val_accuracy: 0.8405\n",
            "Epoch 18/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3573 - accuracy: 0.8648 - val_loss: 0.4198 - val_accuracy: 0.8463\n",
            "Epoch 19/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3594 - accuracy: 0.8614 - val_loss: 0.4204 - val_accuracy: 0.8444\n",
            "Epoch 20/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3573 - accuracy: 0.8658 - val_loss: 0.4215 - val_accuracy: 0.8482\n",
            "Epoch 21/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3577 - accuracy: 0.8648 - val_loss: 0.4266 - val_accuracy: 0.8405\n",
            "Epoch 22/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3597 - accuracy: 0.8648 - val_loss: 0.4236 - val_accuracy: 0.8366\n",
            "Epoch 23/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3570 - accuracy: 0.8638 - val_loss: 0.4307 - val_accuracy: 0.8385\n",
            "Epoch 24/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3574 - accuracy: 0.8653 - val_loss: 0.4323 - val_accuracy: 0.8288\n",
            "Epoch 25/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3582 - accuracy: 0.8589 - val_loss: 0.4280 - val_accuracy: 0.8424\n",
            "Epoch 26/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3591 - accuracy: 0.8565 - val_loss: 0.4226 - val_accuracy: 0.8191\n",
            "Epoch 27/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3578 - accuracy: 0.8643 - val_loss: 0.4273 - val_accuracy: 0.8405\n",
            "Epoch 28/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3575 - accuracy: 0.8614 - val_loss: 0.4342 - val_accuracy: 0.8191\n",
            "Epoch 29/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3573 - accuracy: 0.8653 - val_loss: 0.4300 - val_accuracy: 0.8113\n",
            "Epoch 30/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3574 - accuracy: 0.8609 - val_loss: 0.4339 - val_accuracy: 0.8327\n",
            "Epoch 31/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3578 - accuracy: 0.8624 - val_loss: 0.4131 - val_accuracy: 0.8346\n",
            "Epoch 32/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3569 - accuracy: 0.8658 - val_loss: 0.4164 - val_accuracy: 0.8482\n",
            "Epoch 33/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3572 - accuracy: 0.8609 - val_loss: 0.4294 - val_accuracy: 0.8424\n",
            "Epoch 34/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3575 - accuracy: 0.8633 - val_loss: 0.4232 - val_accuracy: 0.8405\n",
            "Epoch 35/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3572 - accuracy: 0.8585 - val_loss: 0.4382 - val_accuracy: 0.8152\n",
            "Epoch 36/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3587 - accuracy: 0.8643 - val_loss: 0.4175 - val_accuracy: 0.8405\n",
            "Epoch 37/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3580 - accuracy: 0.8604 - val_loss: 0.4385 - val_accuracy: 0.8152\n",
            "Epoch 38/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3577 - accuracy: 0.8589 - val_loss: 0.4254 - val_accuracy: 0.8288\n",
            "Epoch 39/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3570 - accuracy: 0.8619 - val_loss: 0.4154 - val_accuracy: 0.8444\n",
            "Epoch 40/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3581 - accuracy: 0.8633 - val_loss: 0.4343 - val_accuracy: 0.8288\n",
            "Epoch 41/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3568 - accuracy: 0.8667 - val_loss: 0.4179 - val_accuracy: 0.8444\n",
            "Epoch 42/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3569 - accuracy: 0.8609 - val_loss: 0.4280 - val_accuracy: 0.8152\n",
            "Epoch 43/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3583 - accuracy: 0.8628 - val_loss: 0.4272 - val_accuracy: 0.8307\n",
            "Epoch 44/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3595 - accuracy: 0.8599 - val_loss: 0.4177 - val_accuracy: 0.8385\n",
            "Epoch 45/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3588 - accuracy: 0.8609 - val_loss: 0.4308 - val_accuracy: 0.8346\n",
            "Epoch 46/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3566 - accuracy: 0.8638 - val_loss: 0.4292 - val_accuracy: 0.8093\n",
            "Epoch 47/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3569 - accuracy: 0.8628 - val_loss: 0.4243 - val_accuracy: 0.8502\n",
            "Epoch 48/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3579 - accuracy: 0.8633 - val_loss: 0.4264 - val_accuracy: 0.8366\n",
            "Epoch 49/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3566 - accuracy: 0.8628 - val_loss: 0.4345 - val_accuracy: 0.8385\n",
            "Epoch 50/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3571 - accuracy: 0.8614 - val_loss: 0.4320 - val_accuracy: 0.8463\n",
            "Training Model 3\n",
            "Epoch 1/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3449 - accuracy: 0.8739 - val_loss: 0.3984 - val_accuracy: 0.8467\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3458 - accuracy: 0.8706 - val_loss: 0.4096 - val_accuracy: 0.8487\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3443 - accuracy: 0.8725 - val_loss: 0.4126 - val_accuracy: 0.8525\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3441 - accuracy: 0.8739 - val_loss: 0.4180 - val_accuracy: 0.8467\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3451 - accuracy: 0.8634 - val_loss: 0.4089 - val_accuracy: 0.8544\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3458 - accuracy: 0.8706 - val_loss: 0.4001 - val_accuracy: 0.8525\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3433 - accuracy: 0.8754 - val_loss: 0.4005 - val_accuracy: 0.8506\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3444 - accuracy: 0.8734 - val_loss: 0.3962 - val_accuracy: 0.8582\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3434 - accuracy: 0.8763 - val_loss: 0.3996 - val_accuracy: 0.8487\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3430 - accuracy: 0.8658 - val_loss: 0.4262 - val_accuracy: 0.8352\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3447 - accuracy: 0.8710 - val_loss: 0.4030 - val_accuracy: 0.8448\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3426 - accuracy: 0.8715 - val_loss: 0.5015 - val_accuracy: 0.7893\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3470 - accuracy: 0.8667 - val_loss: 0.4064 - val_accuracy: 0.8525\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3459 - accuracy: 0.8720 - val_loss: 0.3996 - val_accuracy: 0.8602\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3435 - accuracy: 0.8763 - val_loss: 0.4066 - val_accuracy: 0.8582\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3462 - accuracy: 0.8686 - val_loss: 0.4001 - val_accuracy: 0.8410\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3455 - accuracy: 0.8701 - val_loss: 0.4021 - val_accuracy: 0.8544\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8739 - val_loss: 0.3971 - val_accuracy: 0.8582\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3434 - accuracy: 0.8701 - val_loss: 0.4354 - val_accuracy: 0.8429\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3453 - accuracy: 0.8686 - val_loss: 0.3987 - val_accuracy: 0.8582\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3449 - accuracy: 0.8696 - val_loss: 0.3981 - val_accuracy: 0.8506\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3438 - accuracy: 0.8730 - val_loss: 0.4096 - val_accuracy: 0.8544\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.8706 - val_loss: 0.4140 - val_accuracy: 0.8467\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3457 - accuracy: 0.8739 - val_loss: 0.3980 - val_accuracy: 0.8487\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3439 - accuracy: 0.8696 - val_loss: 0.4075 - val_accuracy: 0.8448\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3427 - accuracy: 0.8730 - val_loss: 0.4235 - val_accuracy: 0.8276\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3466 - accuracy: 0.8667 - val_loss: 0.4001 - val_accuracy: 0.8544\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3445 - accuracy: 0.8691 - val_loss: 0.4043 - val_accuracy: 0.8506\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3419 - accuracy: 0.8763 - val_loss: 0.4015 - val_accuracy: 0.8582\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3429 - accuracy: 0.8725 - val_loss: 0.4114 - val_accuracy: 0.8429\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3440 - accuracy: 0.8720 - val_loss: 0.4596 - val_accuracy: 0.8180\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3448 - accuracy: 0.8749 - val_loss: 0.4025 - val_accuracy: 0.8467\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.8758 - val_loss: 0.4038 - val_accuracy: 0.8467\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3427 - accuracy: 0.8773 - val_loss: 0.4080 - val_accuracy: 0.8410\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3439 - accuracy: 0.8730 - val_loss: 0.4970 - val_accuracy: 0.8103\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3466 - accuracy: 0.8701 - val_loss: 0.4058 - val_accuracy: 0.8563\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3428 - accuracy: 0.8734 - val_loss: 0.4133 - val_accuracy: 0.8429\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3440 - accuracy: 0.8706 - val_loss: 0.4038 - val_accuracy: 0.8391\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3436 - accuracy: 0.8672 - val_loss: 0.4051 - val_accuracy: 0.8391\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3452 - accuracy: 0.8730 - val_loss: 0.4025 - val_accuracy: 0.8506\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3427 - accuracy: 0.8758 - val_loss: 0.4128 - val_accuracy: 0.8448\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3437 - accuracy: 0.8706 - val_loss: 0.4091 - val_accuracy: 0.8487\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3449 - accuracy: 0.8701 - val_loss: 0.3994 - val_accuracy: 0.8582\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3425 - accuracy: 0.8739 - val_loss: 0.4161 - val_accuracy: 0.8448\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3451 - accuracy: 0.8710 - val_loss: 0.4473 - val_accuracy: 0.8276\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3454 - accuracy: 0.8682 - val_loss: 0.4114 - val_accuracy: 0.8563\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3426 - accuracy: 0.8706 - val_loss: 0.4151 - val_accuracy: 0.8391\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8720 - val_loss: 0.4094 - val_accuracy: 0.8582\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3453 - accuracy: 0.8725 - val_loss: 0.4111 - val_accuracy: 0.8506\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3462 - accuracy: 0.8734 - val_loss: 0.4070 - val_accuracy: 0.8429\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7867\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6041 - accuracy: 0.7290\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6061 - accuracy: 0.7436\n",
            "\n",
            "Iteration: 5\n",
            "Weights extracted succesfully\n",
            "Weights averaged successfully\n",
            "New weights assigned successfully\n",
            "Training Model 1\n",
            "Epoch 1/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3692 - accuracy: 0.8547 - val_loss: 0.3897 - val_accuracy: 0.8563\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3694 - accuracy: 0.8610 - val_loss: 0.3971 - val_accuracy: 0.8621\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3689 - accuracy: 0.8591 - val_loss: 0.3924 - val_accuracy: 0.8602\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3675 - accuracy: 0.8586 - val_loss: 0.5020 - val_accuracy: 0.7682\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3733 - accuracy: 0.8543 - val_loss: 0.3836 - val_accuracy: 0.8563\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3684 - accuracy: 0.8591 - val_loss: 0.3926 - val_accuracy: 0.8563\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3666 - accuracy: 0.8562 - val_loss: 0.3966 - val_accuracy: 0.8544\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3677 - accuracy: 0.8586 - val_loss: 0.3980 - val_accuracy: 0.8602\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3686 - accuracy: 0.8581 - val_loss: 0.3885 - val_accuracy: 0.8659\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8591 - val_loss: 0.3834 - val_accuracy: 0.8582\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3693 - accuracy: 0.8600 - val_loss: 0.3903 - val_accuracy: 0.8487\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8605 - val_loss: 0.3886 - val_accuracy: 0.8582\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3668 - accuracy: 0.8624 - val_loss: 0.4084 - val_accuracy: 0.8238\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3687 - accuracy: 0.8533 - val_loss: 0.3949 - val_accuracy: 0.8697\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3665 - accuracy: 0.8528 - val_loss: 0.3911 - val_accuracy: 0.8602\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3664 - accuracy: 0.8639 - val_loss: 0.3910 - val_accuracy: 0.8506\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3654 - accuracy: 0.8629 - val_loss: 0.3832 - val_accuracy: 0.8602\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8562 - val_loss: 0.3932 - val_accuracy: 0.8582\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3667 - accuracy: 0.8586 - val_loss: 0.3926 - val_accuracy: 0.8659\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8533 - val_loss: 0.3897 - val_accuracy: 0.8640\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3659 - accuracy: 0.8581 - val_loss: 0.3910 - val_accuracy: 0.8640\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3668 - accuracy: 0.8567 - val_loss: 0.4031 - val_accuracy: 0.8448\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3683 - accuracy: 0.8595 - val_loss: 0.3930 - val_accuracy: 0.8448\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3682 - accuracy: 0.8576 - val_loss: 0.3886 - val_accuracy: 0.8640\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3682 - accuracy: 0.8576 - val_loss: 0.4241 - val_accuracy: 0.8257\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3709 - accuracy: 0.8543 - val_loss: 0.3950 - val_accuracy: 0.8487\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3673 - accuracy: 0.8619 - val_loss: 0.4077 - val_accuracy: 0.8487\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3679 - accuracy: 0.8567 - val_loss: 0.3898 - val_accuracy: 0.8640\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3670 - accuracy: 0.8605 - val_loss: 0.3868 - val_accuracy: 0.8678\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3662 - accuracy: 0.8595 - val_loss: 0.3940 - val_accuracy: 0.8525\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3669 - accuracy: 0.8605 - val_loss: 0.3913 - val_accuracy: 0.8678\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3673 - accuracy: 0.8581 - val_loss: 0.3971 - val_accuracy: 0.8506\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3684 - accuracy: 0.8586 - val_loss: 0.3900 - val_accuracy: 0.8582\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3682 - accuracy: 0.8567 - val_loss: 0.3957 - val_accuracy: 0.8621\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3682 - accuracy: 0.8547 - val_loss: 0.3926 - val_accuracy: 0.8621\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3667 - accuracy: 0.8571 - val_loss: 0.3930 - val_accuracy: 0.8582\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3683 - accuracy: 0.8581 - val_loss: 0.3889 - val_accuracy: 0.8563\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3690 - accuracy: 0.8528 - val_loss: 0.3901 - val_accuracy: 0.8602\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3672 - accuracy: 0.8567 - val_loss: 0.3861 - val_accuracy: 0.8640\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3664 - accuracy: 0.8586 - val_loss: 0.3883 - val_accuracy: 0.8563\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3680 - accuracy: 0.8576 - val_loss: 0.3918 - val_accuracy: 0.8467\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3676 - accuracy: 0.8605 - val_loss: 0.3917 - val_accuracy: 0.8525\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3692 - accuracy: 0.8552 - val_loss: 0.4004 - val_accuracy: 0.8487\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3675 - accuracy: 0.8567 - val_loss: 0.3945 - val_accuracy: 0.8506\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3674 - accuracy: 0.8605 - val_loss: 0.3937 - val_accuracy: 0.8544\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3665 - accuracy: 0.8591 - val_loss: 0.3939 - val_accuracy: 0.8544\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3657 - accuracy: 0.8586 - val_loss: 0.3948 - val_accuracy: 0.8602\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3682 - accuracy: 0.8591 - val_loss: 0.4153 - val_accuracy: 0.8238\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3685 - accuracy: 0.8557 - val_loss: 0.3994 - val_accuracy: 0.8467\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8595 - val_loss: 0.3983 - val_accuracy: 0.8448\n",
            "Training Model 2\n",
            "Epoch 1/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3600 - accuracy: 0.8599 - val_loss: 0.4154 - val_accuracy: 0.8366\n",
            "Epoch 2/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3566 - accuracy: 0.8648 - val_loss: 0.4278 - val_accuracy: 0.8307\n",
            "Epoch 3/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3573 - accuracy: 0.8628 - val_loss: 0.4262 - val_accuracy: 0.8268\n",
            "Epoch 4/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3582 - accuracy: 0.8589 - val_loss: 0.4335 - val_accuracy: 0.8054\n",
            "Epoch 5/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3587 - accuracy: 0.8560 - val_loss: 0.4159 - val_accuracy: 0.8463\n",
            "Epoch 6/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3573 - accuracy: 0.8643 - val_loss: 0.4243 - val_accuracy: 0.8424\n",
            "Epoch 7/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3575 - accuracy: 0.8648 - val_loss: 0.4158 - val_accuracy: 0.8385\n",
            "Epoch 8/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3568 - accuracy: 0.8653 - val_loss: 0.4099 - val_accuracy: 0.8385\n",
            "Epoch 9/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3585 - accuracy: 0.8609 - val_loss: 0.4312 - val_accuracy: 0.8268\n",
            "Epoch 10/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3586 - accuracy: 0.8628 - val_loss: 0.4251 - val_accuracy: 0.8346\n",
            "Epoch 11/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3585 - accuracy: 0.8570 - val_loss: 0.4315 - val_accuracy: 0.8346\n",
            "Epoch 12/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3587 - accuracy: 0.8687 - val_loss: 0.4202 - val_accuracy: 0.8385\n",
            "Epoch 13/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3573 - accuracy: 0.8614 - val_loss: 0.4154 - val_accuracy: 0.8424\n",
            "Epoch 14/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3562 - accuracy: 0.8638 - val_loss: 0.4322 - val_accuracy: 0.8346\n",
            "Epoch 15/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3577 - accuracy: 0.8658 - val_loss: 0.4238 - val_accuracy: 0.8307\n",
            "Epoch 16/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3579 - accuracy: 0.8619 - val_loss: 0.4310 - val_accuracy: 0.8327\n",
            "Epoch 17/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3567 - accuracy: 0.8585 - val_loss: 0.4183 - val_accuracy: 0.8385\n",
            "Epoch 18/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3568 - accuracy: 0.8658 - val_loss: 0.4207 - val_accuracy: 0.8463\n",
            "Epoch 19/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3589 - accuracy: 0.8619 - val_loss: 0.4208 - val_accuracy: 0.8444\n",
            "Epoch 20/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3569 - accuracy: 0.8677 - val_loss: 0.4213 - val_accuracy: 0.8463\n",
            "Epoch 21/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3574 - accuracy: 0.8633 - val_loss: 0.4264 - val_accuracy: 0.8366\n",
            "Epoch 22/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3593 - accuracy: 0.8658 - val_loss: 0.4246 - val_accuracy: 0.8346\n",
            "Epoch 23/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3565 - accuracy: 0.8643 - val_loss: 0.4319 - val_accuracy: 0.8346\n",
            "Epoch 24/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3571 - accuracy: 0.8648 - val_loss: 0.4320 - val_accuracy: 0.8249\n",
            "Epoch 25/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3576 - accuracy: 0.8599 - val_loss: 0.4285 - val_accuracy: 0.8424\n",
            "Epoch 26/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3587 - accuracy: 0.8580 - val_loss: 0.4214 - val_accuracy: 0.8230\n",
            "Epoch 27/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3571 - accuracy: 0.8662 - val_loss: 0.4280 - val_accuracy: 0.8424\n",
            "Epoch 28/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3571 - accuracy: 0.8633 - val_loss: 0.4347 - val_accuracy: 0.8210\n",
            "Epoch 29/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3568 - accuracy: 0.8648 - val_loss: 0.4324 - val_accuracy: 0.8074\n",
            "Epoch 30/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3569 - accuracy: 0.8633 - val_loss: 0.4348 - val_accuracy: 0.8346\n",
            "Epoch 31/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3576 - accuracy: 0.8599 - val_loss: 0.4128 - val_accuracy: 0.8385\n",
            "Epoch 32/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3562 - accuracy: 0.8677 - val_loss: 0.4158 - val_accuracy: 0.8482\n",
            "Epoch 33/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3564 - accuracy: 0.8609 - val_loss: 0.4301 - val_accuracy: 0.8424\n",
            "Epoch 34/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3571 - accuracy: 0.8662 - val_loss: 0.4227 - val_accuracy: 0.8385\n",
            "Epoch 35/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3568 - accuracy: 0.8575 - val_loss: 0.4369 - val_accuracy: 0.8191\n",
            "Epoch 36/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3584 - accuracy: 0.8658 - val_loss: 0.4174 - val_accuracy: 0.8444\n",
            "Epoch 37/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3576 - accuracy: 0.8619 - val_loss: 0.4394 - val_accuracy: 0.8113\n",
            "Epoch 38/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3572 - accuracy: 0.8614 - val_loss: 0.4261 - val_accuracy: 0.8307\n",
            "Epoch 39/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3564 - accuracy: 0.8633 - val_loss: 0.4153 - val_accuracy: 0.8424\n",
            "Epoch 40/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3576 - accuracy: 0.8638 - val_loss: 0.4346 - val_accuracy: 0.8268\n",
            "Epoch 41/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3561 - accuracy: 0.8672 - val_loss: 0.4176 - val_accuracy: 0.8482\n",
            "Epoch 42/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3566 - accuracy: 0.8628 - val_loss: 0.4291 - val_accuracy: 0.8093\n",
            "Epoch 43/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3575 - accuracy: 0.8624 - val_loss: 0.4272 - val_accuracy: 0.8346\n",
            "Epoch 44/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3591 - accuracy: 0.8604 - val_loss: 0.4165 - val_accuracy: 0.8424\n",
            "Epoch 45/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3580 - accuracy: 0.8624 - val_loss: 0.4300 - val_accuracy: 0.8366\n",
            "Epoch 46/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3564 - accuracy: 0.8648 - val_loss: 0.4292 - val_accuracy: 0.8132\n",
            "Epoch 47/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3564 - accuracy: 0.8624 - val_loss: 0.4244 - val_accuracy: 0.8482\n",
            "Epoch 48/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3574 - accuracy: 0.8643 - val_loss: 0.4270 - val_accuracy: 0.8346\n",
            "Epoch 49/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3565 - accuracy: 0.8638 - val_loss: 0.4351 - val_accuracy: 0.8385\n",
            "Epoch 50/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3568 - accuracy: 0.8624 - val_loss: 0.4318 - val_accuracy: 0.8463\n",
            "Training Model 3\n",
            "Epoch 1/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3445 - accuracy: 0.8739 - val_loss: 0.3980 - val_accuracy: 0.8487\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3454 - accuracy: 0.8710 - val_loss: 0.4094 - val_accuracy: 0.8506\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3439 - accuracy: 0.8720 - val_loss: 0.4123 - val_accuracy: 0.8525\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3436 - accuracy: 0.8749 - val_loss: 0.4180 - val_accuracy: 0.8487\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.8648 - val_loss: 0.4086 - val_accuracy: 0.8544\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3456 - accuracy: 0.8696 - val_loss: 0.3998 - val_accuracy: 0.8525\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3425 - accuracy: 0.8758 - val_loss: 0.4007 - val_accuracy: 0.8506\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.8744 - val_loss: 0.3952 - val_accuracy: 0.8602\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3434 - accuracy: 0.8749 - val_loss: 0.3995 - val_accuracy: 0.8487\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3426 - accuracy: 0.8658 - val_loss: 0.4263 - val_accuracy: 0.8372\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3442 - accuracy: 0.8710 - val_loss: 0.4029 - val_accuracy: 0.8429\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3422 - accuracy: 0.8710 - val_loss: 0.5020 - val_accuracy: 0.7893\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3467 - accuracy: 0.8667 - val_loss: 0.4070 - val_accuracy: 0.8506\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3457 - accuracy: 0.8710 - val_loss: 0.3991 - val_accuracy: 0.8602\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3431 - accuracy: 0.8739 - val_loss: 0.4062 - val_accuracy: 0.8544\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3458 - accuracy: 0.8701 - val_loss: 0.3994 - val_accuracy: 0.8410\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3450 - accuracy: 0.8696 - val_loss: 0.4015 - val_accuracy: 0.8544\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3427 - accuracy: 0.8725 - val_loss: 0.3966 - val_accuracy: 0.8582\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3429 - accuracy: 0.8710 - val_loss: 0.4345 - val_accuracy: 0.8448\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3450 - accuracy: 0.8696 - val_loss: 0.3985 - val_accuracy: 0.8582\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3447 - accuracy: 0.8691 - val_loss: 0.3980 - val_accuracy: 0.8544\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3435 - accuracy: 0.8725 - val_loss: 0.4097 - val_accuracy: 0.8525\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3418 - accuracy: 0.8720 - val_loss: 0.4143 - val_accuracy: 0.8429\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3454 - accuracy: 0.8749 - val_loss: 0.3975 - val_accuracy: 0.8525\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3436 - accuracy: 0.8686 - val_loss: 0.4065 - val_accuracy: 0.8448\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3424 - accuracy: 0.8730 - val_loss: 0.4240 - val_accuracy: 0.8276\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3463 - accuracy: 0.8686 - val_loss: 0.3999 - val_accuracy: 0.8525\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3444 - accuracy: 0.8691 - val_loss: 0.4042 - val_accuracy: 0.8525\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3415 - accuracy: 0.8763 - val_loss: 0.4011 - val_accuracy: 0.8563\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3424 - accuracy: 0.8710 - val_loss: 0.4116 - val_accuracy: 0.8448\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3435 - accuracy: 0.8725 - val_loss: 0.4591 - val_accuracy: 0.8218\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3444 - accuracy: 0.8749 - val_loss: 0.4018 - val_accuracy: 0.8448\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3411 - accuracy: 0.8758 - val_loss: 0.4037 - val_accuracy: 0.8467\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3425 - accuracy: 0.8773 - val_loss: 0.4082 - val_accuracy: 0.8410\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.8725 - val_loss: 0.5101 - val_accuracy: 0.7912\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3466 - accuracy: 0.8696 - val_loss: 0.4070 - val_accuracy: 0.8506\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3426 - accuracy: 0.8715 - val_loss: 0.4130 - val_accuracy: 0.8410\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3437 - accuracy: 0.8701 - val_loss: 0.4036 - val_accuracy: 0.8391\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.8686 - val_loss: 0.4053 - val_accuracy: 0.8372\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3449 - accuracy: 0.8720 - val_loss: 0.4029 - val_accuracy: 0.8525\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3426 - accuracy: 0.8758 - val_loss: 0.4115 - val_accuracy: 0.8467\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3433 - accuracy: 0.8686 - val_loss: 0.4083 - val_accuracy: 0.8467\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3447 - accuracy: 0.8706 - val_loss: 0.3984 - val_accuracy: 0.8582\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.8758 - val_loss: 0.4157 - val_accuracy: 0.8429\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3449 - accuracy: 0.8696 - val_loss: 0.4512 - val_accuracy: 0.8257\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3453 - accuracy: 0.8672 - val_loss: 0.4110 - val_accuracy: 0.8563\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3422 - accuracy: 0.8701 - val_loss: 0.4174 - val_accuracy: 0.8391\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8691 - val_loss: 0.4086 - val_accuracy: 0.8602\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3448 - accuracy: 0.8725 - val_loss: 0.4115 - val_accuracy: 0.8506\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3458 - accuracy: 0.8739 - val_loss: 0.4071 - val_accuracy: 0.8448\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7886\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5985 - accuracy: 0.7329\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6073 - accuracy: 0.7466\n",
            "\n",
            "Iteration: 6\n",
            "Weights extracted succesfully\n",
            "Weights averaged successfully\n",
            "New weights assigned successfully\n",
            "Training Model 1\n",
            "Epoch 1/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3683 - accuracy: 0.8571 - val_loss: 0.3871 - val_accuracy: 0.8659\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3680 - accuracy: 0.8634 - val_loss: 0.3978 - val_accuracy: 0.8621\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3674 - accuracy: 0.8610 - val_loss: 0.3916 - val_accuracy: 0.8563\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3669 - accuracy: 0.8600 - val_loss: 0.5088 - val_accuracy: 0.7663\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3726 - accuracy: 0.8567 - val_loss: 0.3822 - val_accuracy: 0.8544\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3673 - accuracy: 0.8576 - val_loss: 0.3918 - val_accuracy: 0.8563\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3658 - accuracy: 0.8586 - val_loss: 0.3947 - val_accuracy: 0.8544\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3670 - accuracy: 0.8605 - val_loss: 0.3975 - val_accuracy: 0.8640\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8576 - val_loss: 0.3882 - val_accuracy: 0.8659\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3671 - accuracy: 0.8581 - val_loss: 0.3828 - val_accuracy: 0.8621\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3685 - accuracy: 0.8605 - val_loss: 0.3904 - val_accuracy: 0.8525\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3673 - accuracy: 0.8595 - val_loss: 0.3871 - val_accuracy: 0.8640\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3657 - accuracy: 0.8629 - val_loss: 0.4075 - val_accuracy: 0.8238\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3679 - accuracy: 0.8562 - val_loss: 0.3943 - val_accuracy: 0.8678\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3659 - accuracy: 0.8547 - val_loss: 0.3903 - val_accuracy: 0.8563\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3659 - accuracy: 0.8648 - val_loss: 0.3919 - val_accuracy: 0.8467\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3651 - accuracy: 0.8639 - val_loss: 0.3826 - val_accuracy: 0.8621\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3671 - accuracy: 0.8600 - val_loss: 0.3926 - val_accuracy: 0.8582\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3665 - accuracy: 0.8591 - val_loss: 0.3913 - val_accuracy: 0.8697\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3676 - accuracy: 0.8576 - val_loss: 0.3889 - val_accuracy: 0.8602\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3658 - accuracy: 0.8600 - val_loss: 0.3894 - val_accuracy: 0.8621\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3660 - accuracy: 0.8567 - val_loss: 0.4032 - val_accuracy: 0.8429\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3677 - accuracy: 0.8595 - val_loss: 0.3924 - val_accuracy: 0.8429\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3677 - accuracy: 0.8557 - val_loss: 0.3879 - val_accuracy: 0.8678\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3677 - accuracy: 0.8605 - val_loss: 0.4256 - val_accuracy: 0.8218\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3701 - accuracy: 0.8552 - val_loss: 0.3960 - val_accuracy: 0.8487\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3670 - accuracy: 0.8610 - val_loss: 0.4069 - val_accuracy: 0.8487\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3672 - accuracy: 0.8557 - val_loss: 0.3900 - val_accuracy: 0.8659\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3659 - accuracy: 0.8595 - val_loss: 0.3855 - val_accuracy: 0.8640\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3657 - accuracy: 0.8600 - val_loss: 0.3934 - val_accuracy: 0.8448\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3665 - accuracy: 0.8605 - val_loss: 0.3900 - val_accuracy: 0.8716\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3668 - accuracy: 0.8586 - val_loss: 0.3964 - val_accuracy: 0.8467\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3681 - accuracy: 0.8581 - val_loss: 0.3889 - val_accuracy: 0.8582\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3676 - accuracy: 0.8567 - val_loss: 0.3945 - val_accuracy: 0.8640\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8557 - val_loss: 0.3923 - val_accuracy: 0.8621\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3661 - accuracy: 0.8562 - val_loss: 0.3916 - val_accuracy: 0.8582\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3675 - accuracy: 0.8581 - val_loss: 0.3877 - val_accuracy: 0.8678\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3682 - accuracy: 0.8576 - val_loss: 0.3888 - val_accuracy: 0.8582\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3665 - accuracy: 0.8576 - val_loss: 0.3846 - val_accuracy: 0.8659\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3655 - accuracy: 0.8605 - val_loss: 0.3883 - val_accuracy: 0.8525\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3671 - accuracy: 0.8586 - val_loss: 0.3918 - val_accuracy: 0.8487\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3669 - accuracy: 0.8605 - val_loss: 0.3917 - val_accuracy: 0.8525\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3689 - accuracy: 0.8557 - val_loss: 0.4011 - val_accuracy: 0.8467\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3670 - accuracy: 0.8581 - val_loss: 0.3944 - val_accuracy: 0.8544\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3666 - accuracy: 0.8605 - val_loss: 0.3920 - val_accuracy: 0.8602\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3659 - accuracy: 0.8600 - val_loss: 0.3932 - val_accuracy: 0.8544\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3651 - accuracy: 0.8576 - val_loss: 0.3935 - val_accuracy: 0.8640\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3677 - accuracy: 0.8595 - val_loss: 0.3970 - val_accuracy: 0.8391\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3666 - accuracy: 0.8552 - val_loss: 0.4001 - val_accuracy: 0.8429\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3671 - accuracy: 0.8591 - val_loss: 0.3960 - val_accuracy: 0.8448\n",
            "Training Model 2\n",
            "Epoch 1/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3589 - accuracy: 0.8589 - val_loss: 0.4147 - val_accuracy: 0.8424\n",
            "Epoch 2/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3556 - accuracy: 0.8643 - val_loss: 0.4270 - val_accuracy: 0.8288\n",
            "Epoch 3/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3565 - accuracy: 0.8672 - val_loss: 0.4260 - val_accuracy: 0.8249\n",
            "Epoch 4/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3575 - accuracy: 0.8619 - val_loss: 0.4324 - val_accuracy: 0.8113\n",
            "Epoch 5/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3581 - accuracy: 0.8575 - val_loss: 0.4140 - val_accuracy: 0.8482\n",
            "Epoch 6/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3568 - accuracy: 0.8633 - val_loss: 0.4253 - val_accuracy: 0.8385\n",
            "Epoch 7/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3565 - accuracy: 0.8648 - val_loss: 0.4153 - val_accuracy: 0.8346\n",
            "Epoch 8/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3554 - accuracy: 0.8638 - val_loss: 0.4095 - val_accuracy: 0.8405\n",
            "Epoch 9/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3576 - accuracy: 0.8633 - val_loss: 0.4304 - val_accuracy: 0.8366\n",
            "Epoch 10/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3579 - accuracy: 0.8667 - val_loss: 0.4257 - val_accuracy: 0.8327\n",
            "Epoch 11/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3573 - accuracy: 0.8580 - val_loss: 0.4340 - val_accuracy: 0.8327\n",
            "Epoch 12/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3580 - accuracy: 0.8687 - val_loss: 0.4194 - val_accuracy: 0.8385\n",
            "Epoch 13/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3565 - accuracy: 0.8633 - val_loss: 0.4150 - val_accuracy: 0.8385\n",
            "Epoch 14/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3552 - accuracy: 0.8633 - val_loss: 0.4329 - val_accuracy: 0.8346\n",
            "Epoch 15/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3563 - accuracy: 0.8682 - val_loss: 0.4225 - val_accuracy: 0.8346\n",
            "Epoch 16/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3570 - accuracy: 0.8628 - val_loss: 0.4314 - val_accuracy: 0.8249\n",
            "Epoch 17/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3561 - accuracy: 0.8638 - val_loss: 0.4203 - val_accuracy: 0.8366\n",
            "Epoch 18/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3559 - accuracy: 0.8648 - val_loss: 0.4212 - val_accuracy: 0.8444\n",
            "Epoch 19/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3577 - accuracy: 0.8628 - val_loss: 0.4200 - val_accuracy: 0.8385\n",
            "Epoch 20/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3559 - accuracy: 0.8662 - val_loss: 0.4259 - val_accuracy: 0.8346\n",
            "Epoch 21/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3562 - accuracy: 0.8653 - val_loss: 0.4270 - val_accuracy: 0.8405\n",
            "Epoch 22/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3584 - accuracy: 0.8658 - val_loss: 0.4241 - val_accuracy: 0.8346\n",
            "Epoch 23/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3555 - accuracy: 0.8628 - val_loss: 0.4320 - val_accuracy: 0.8307\n",
            "Epoch 24/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3555 - accuracy: 0.8648 - val_loss: 0.4316 - val_accuracy: 0.8268\n",
            "Epoch 25/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3570 - accuracy: 0.8619 - val_loss: 0.4312 - val_accuracy: 0.8444\n",
            "Epoch 26/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3568 - accuracy: 0.8589 - val_loss: 0.4219 - val_accuracy: 0.8230\n",
            "Epoch 27/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3554 - accuracy: 0.8619 - val_loss: 0.4298 - val_accuracy: 0.8385\n",
            "Epoch 28/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3558 - accuracy: 0.8653 - val_loss: 0.4370 - val_accuracy: 0.8171\n",
            "Epoch 29/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3556 - accuracy: 0.8672 - val_loss: 0.4241 - val_accuracy: 0.8210\n",
            "Epoch 30/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3553 - accuracy: 0.8667 - val_loss: 0.4342 - val_accuracy: 0.8424\n",
            "Epoch 31/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3562 - accuracy: 0.8653 - val_loss: 0.4123 - val_accuracy: 0.8346\n",
            "Epoch 32/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3549 - accuracy: 0.8701 - val_loss: 0.4156 - val_accuracy: 0.8463\n",
            "Epoch 33/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3554 - accuracy: 0.8633 - val_loss: 0.4310 - val_accuracy: 0.8307\n",
            "Epoch 34/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3559 - accuracy: 0.8648 - val_loss: 0.4222 - val_accuracy: 0.8346\n",
            "Epoch 35/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3553 - accuracy: 0.8619 - val_loss: 0.4251 - val_accuracy: 0.8210\n",
            "Epoch 36/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3562 - accuracy: 0.8653 - val_loss: 0.4166 - val_accuracy: 0.8405\n",
            "Epoch 37/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3558 - accuracy: 0.8619 - val_loss: 0.4362 - val_accuracy: 0.8249\n",
            "Epoch 38/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3560 - accuracy: 0.8619 - val_loss: 0.4239 - val_accuracy: 0.8307\n",
            "Epoch 39/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3550 - accuracy: 0.8619 - val_loss: 0.4151 - val_accuracy: 0.8444\n",
            "Epoch 40/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3560 - accuracy: 0.8633 - val_loss: 0.4332 - val_accuracy: 0.8249\n",
            "Epoch 41/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3552 - accuracy: 0.8662 - val_loss: 0.4200 - val_accuracy: 0.8385\n",
            "Epoch 42/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3553 - accuracy: 0.8638 - val_loss: 0.4273 - val_accuracy: 0.8210\n",
            "Epoch 43/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3562 - accuracy: 0.8619 - val_loss: 0.4287 - val_accuracy: 0.8307\n",
            "Epoch 44/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3574 - accuracy: 0.8589 - val_loss: 0.4184 - val_accuracy: 0.8463\n",
            "Epoch 45/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3563 - accuracy: 0.8633 - val_loss: 0.4324 - val_accuracy: 0.8366\n",
            "Epoch 46/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3550 - accuracy: 0.8677 - val_loss: 0.4309 - val_accuracy: 0.8152\n",
            "Epoch 47/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3547 - accuracy: 0.8672 - val_loss: 0.4265 - val_accuracy: 0.8482\n",
            "Epoch 48/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3560 - accuracy: 0.8658 - val_loss: 0.4308 - val_accuracy: 0.8346\n",
            "Epoch 49/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3545 - accuracy: 0.8628 - val_loss: 0.4370 - val_accuracy: 0.8327\n",
            "Epoch 50/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3547 - accuracy: 0.8653 - val_loss: 0.4333 - val_accuracy: 0.8424\n",
            "Training Model 3\n",
            "Epoch 1/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3443 - accuracy: 0.8734 - val_loss: 0.3978 - val_accuracy: 0.8448\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3453 - accuracy: 0.8710 - val_loss: 0.4091 - val_accuracy: 0.8487\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3437 - accuracy: 0.8725 - val_loss: 0.4131 - val_accuracy: 0.8544\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.8749 - val_loss: 0.4182 - val_accuracy: 0.8487\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3443 - accuracy: 0.8639 - val_loss: 0.4091 - val_accuracy: 0.8563\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3448 - accuracy: 0.8720 - val_loss: 0.3997 - val_accuracy: 0.8525\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3423 - accuracy: 0.8768 - val_loss: 0.4004 - val_accuracy: 0.8506\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3439 - accuracy: 0.8734 - val_loss: 0.3959 - val_accuracy: 0.8582\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3428 - accuracy: 0.8744 - val_loss: 0.3989 - val_accuracy: 0.8525\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3421 - accuracy: 0.8672 - val_loss: 0.4297 - val_accuracy: 0.8372\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3444 - accuracy: 0.8706 - val_loss: 0.4026 - val_accuracy: 0.8429\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3419 - accuracy: 0.8701 - val_loss: 0.5038 - val_accuracy: 0.7893\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3465 - accuracy: 0.8653 - val_loss: 0.4063 - val_accuracy: 0.8467\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3455 - accuracy: 0.8710 - val_loss: 0.3991 - val_accuracy: 0.8582\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3427 - accuracy: 0.8763 - val_loss: 0.4064 - val_accuracy: 0.8582\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3455 - accuracy: 0.8701 - val_loss: 0.4003 - val_accuracy: 0.8391\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3449 - accuracy: 0.8715 - val_loss: 0.4012 - val_accuracy: 0.8544\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3421 - accuracy: 0.8725 - val_loss: 0.3963 - val_accuracy: 0.8563\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3426 - accuracy: 0.8696 - val_loss: 0.4362 - val_accuracy: 0.8429\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3445 - accuracy: 0.8691 - val_loss: 0.3981 - val_accuracy: 0.8563\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3443 - accuracy: 0.8686 - val_loss: 0.3991 - val_accuracy: 0.8487\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3434 - accuracy: 0.8720 - val_loss: 0.4097 - val_accuracy: 0.8544\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3417 - accuracy: 0.8720 - val_loss: 0.4138 - val_accuracy: 0.8487\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3450 - accuracy: 0.8744 - val_loss: 0.3972 - val_accuracy: 0.8506\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3433 - accuracy: 0.8686 - val_loss: 0.4059 - val_accuracy: 0.8448\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3419 - accuracy: 0.8734 - val_loss: 0.4232 - val_accuracy: 0.8276\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3458 - accuracy: 0.8667 - val_loss: 0.3998 - val_accuracy: 0.8563\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3442 - accuracy: 0.8691 - val_loss: 0.4041 - val_accuracy: 0.8525\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3411 - accuracy: 0.8758 - val_loss: 0.4016 - val_accuracy: 0.8563\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3424 - accuracy: 0.8696 - val_loss: 0.4120 - val_accuracy: 0.8429\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3432 - accuracy: 0.8730 - val_loss: 0.4599 - val_accuracy: 0.8199\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3441 - accuracy: 0.8749 - val_loss: 0.4022 - val_accuracy: 0.8448\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3405 - accuracy: 0.8758 - val_loss: 0.4034 - val_accuracy: 0.8467\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3421 - accuracy: 0.8763 - val_loss: 0.4083 - val_accuracy: 0.8410\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3430 - accuracy: 0.8710 - val_loss: 0.5097 - val_accuracy: 0.7931\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3465 - accuracy: 0.8696 - val_loss: 0.4071 - val_accuracy: 0.8506\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3423 - accuracy: 0.8710 - val_loss: 0.4141 - val_accuracy: 0.8448\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3432 - accuracy: 0.8715 - val_loss: 0.4035 - val_accuracy: 0.8410\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3429 - accuracy: 0.8677 - val_loss: 0.4056 - val_accuracy: 0.8372\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3448 - accuracy: 0.8706 - val_loss: 0.4031 - val_accuracy: 0.8525\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3422 - accuracy: 0.8754 - val_loss: 0.4118 - val_accuracy: 0.8467\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3430 - accuracy: 0.8701 - val_loss: 0.4084 - val_accuracy: 0.8467\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3436 - accuracy: 0.8725 - val_loss: 0.3990 - val_accuracy: 0.8582\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3420 - accuracy: 0.8749 - val_loss: 0.4162 - val_accuracy: 0.8448\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3446 - accuracy: 0.8696 - val_loss: 0.4506 - val_accuracy: 0.8238\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3448 - accuracy: 0.8672 - val_loss: 0.4118 - val_accuracy: 0.8563\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3420 - accuracy: 0.8691 - val_loss: 0.4215 - val_accuracy: 0.8372\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3463 - accuracy: 0.8706 - val_loss: 0.4094 - val_accuracy: 0.8563\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3446 - accuracy: 0.8720 - val_loss: 0.4116 - val_accuracy: 0.8506\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3458 - accuracy: 0.8739 - val_loss: 0.4079 - val_accuracy: 0.8429\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7867\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5974 - accuracy: 0.7339\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6075 - accuracy: 0.7446\n",
            "\n",
            "Iteration: 7\n",
            "Weights extracted succesfully\n",
            "Weights averaged successfully\n",
            "New weights assigned successfully\n",
            "Training Model 1\n",
            "Epoch 1/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3678 - accuracy: 0.8557 - val_loss: 0.3874 - val_accuracy: 0.8621\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3677 - accuracy: 0.8629 - val_loss: 0.3963 - val_accuracy: 0.8659\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3665 - accuracy: 0.8595 - val_loss: 0.3894 - val_accuracy: 0.8582\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3664 - accuracy: 0.8600 - val_loss: 0.5096 - val_accuracy: 0.7720\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3720 - accuracy: 0.8571 - val_loss: 0.3819 - val_accuracy: 0.8525\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3667 - accuracy: 0.8595 - val_loss: 0.3915 - val_accuracy: 0.8602\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3651 - accuracy: 0.8581 - val_loss: 0.3938 - val_accuracy: 0.8563\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3662 - accuracy: 0.8591 - val_loss: 0.3968 - val_accuracy: 0.8659\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3675 - accuracy: 0.8581 - val_loss: 0.3867 - val_accuracy: 0.8697\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3663 - accuracy: 0.8562 - val_loss: 0.3821 - val_accuracy: 0.8621\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3682 - accuracy: 0.8624 - val_loss: 0.3884 - val_accuracy: 0.8487\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3667 - accuracy: 0.8600 - val_loss: 0.3860 - val_accuracy: 0.8621\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3651 - accuracy: 0.8634 - val_loss: 0.4072 - val_accuracy: 0.8218\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3673 - accuracy: 0.8547 - val_loss: 0.3930 - val_accuracy: 0.8640\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3652 - accuracy: 0.8543 - val_loss: 0.3896 - val_accuracy: 0.8582\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3654 - accuracy: 0.8639 - val_loss: 0.3904 - val_accuracy: 0.8487\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3643 - accuracy: 0.8615 - val_loss: 0.3819 - val_accuracy: 0.8640\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3665 - accuracy: 0.8605 - val_loss: 0.3914 - val_accuracy: 0.8563\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3659 - accuracy: 0.8586 - val_loss: 0.3913 - val_accuracy: 0.8678\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3670 - accuracy: 0.8576 - val_loss: 0.3883 - val_accuracy: 0.8602\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3648 - accuracy: 0.8586 - val_loss: 0.3906 - val_accuracy: 0.8621\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3655 - accuracy: 0.8562 - val_loss: 0.4037 - val_accuracy: 0.8429\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3673 - accuracy: 0.8595 - val_loss: 0.3915 - val_accuracy: 0.8391\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3670 - accuracy: 0.8557 - val_loss: 0.3865 - val_accuracy: 0.8659\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3670 - accuracy: 0.8595 - val_loss: 0.4234 - val_accuracy: 0.8257\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3698 - accuracy: 0.8533 - val_loss: 0.3938 - val_accuracy: 0.8506\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3659 - accuracy: 0.8591 - val_loss: 0.4062 - val_accuracy: 0.8487\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 0.3662 - accuracy: 0.8567 - val_loss: 0.3891 - val_accuracy: 0.8621\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3652 - accuracy: 0.8591 - val_loss: 0.3850 - val_accuracy: 0.8640\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3657 - accuracy: 0.8600 - val_loss: 0.3925 - val_accuracy: 0.8448\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3661 - accuracy: 0.8595 - val_loss: 0.3885 - val_accuracy: 0.8716\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3658 - accuracy: 0.8571 - val_loss: 0.3957 - val_accuracy: 0.8448\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3674 - accuracy: 0.8562 - val_loss: 0.3884 - val_accuracy: 0.8602\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3667 - accuracy: 0.8567 - val_loss: 0.3932 - val_accuracy: 0.8621\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3671 - accuracy: 0.8557 - val_loss: 0.3919 - val_accuracy: 0.8602\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3653 - accuracy: 0.8567 - val_loss: 0.3914 - val_accuracy: 0.8602\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3673 - accuracy: 0.8576 - val_loss: 0.3870 - val_accuracy: 0.8640\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3670 - accuracy: 0.8591 - val_loss: 0.3886 - val_accuracy: 0.8582\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3661 - accuracy: 0.8567 - val_loss: 0.3844 - val_accuracy: 0.8659\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3647 - accuracy: 0.8605 - val_loss: 0.3873 - val_accuracy: 0.8506\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3667 - accuracy: 0.8586 - val_loss: 0.3954 - val_accuracy: 0.8467\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3664 - accuracy: 0.8595 - val_loss: 0.3918 - val_accuracy: 0.8467\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3682 - accuracy: 0.8586 - val_loss: 0.4008 - val_accuracy: 0.8448\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3662 - accuracy: 0.8581 - val_loss: 0.3932 - val_accuracy: 0.8544\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3656 - accuracy: 0.8605 - val_loss: 0.3909 - val_accuracy: 0.8582\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3654 - accuracy: 0.8605 - val_loss: 0.3930 - val_accuracy: 0.8525\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3644 - accuracy: 0.8600 - val_loss: 0.3928 - val_accuracy: 0.8602\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3673 - accuracy: 0.8581 - val_loss: 0.3951 - val_accuracy: 0.8448\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3658 - accuracy: 0.8547 - val_loss: 0.3985 - val_accuracy: 0.8391\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3661 - accuracy: 0.8581 - val_loss: 0.3955 - val_accuracy: 0.8448\n",
            "Training Model 2\n",
            "Epoch 1/50\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.3571 - accuracy: 0.8594 - val_loss: 0.4149 - val_accuracy: 0.8444\n",
            "Epoch 2/50\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.3542 - accuracy: 0.8638 - val_loss: 0.4304 - val_accuracy: 0.8230\n",
            "Epoch 3/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3548 - accuracy: 0.8628 - val_loss: 0.4252 - val_accuracy: 0.8210\n",
            "Epoch 4/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3559 - accuracy: 0.8653 - val_loss: 0.4297 - val_accuracy: 0.8191\n",
            "Epoch 5/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3564 - accuracy: 0.8628 - val_loss: 0.4162 - val_accuracy: 0.8502\n",
            "Epoch 6/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3551 - accuracy: 0.8648 - val_loss: 0.4260 - val_accuracy: 0.8424\n",
            "Epoch 7/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3552 - accuracy: 0.8643 - val_loss: 0.4181 - val_accuracy: 0.8327\n",
            "Epoch 8/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3540 - accuracy: 0.8653 - val_loss: 0.4101 - val_accuracy: 0.8346\n",
            "Epoch 9/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3564 - accuracy: 0.8638 - val_loss: 0.4309 - val_accuracy: 0.8346\n",
            "Epoch 10/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3565 - accuracy: 0.8653 - val_loss: 0.4296 - val_accuracy: 0.8366\n",
            "Epoch 11/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3557 - accuracy: 0.8624 - val_loss: 0.4378 - val_accuracy: 0.8346\n",
            "Epoch 12/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3572 - accuracy: 0.8633 - val_loss: 0.4199 - val_accuracy: 0.8405\n",
            "Epoch 13/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3551 - accuracy: 0.8662 - val_loss: 0.4168 - val_accuracy: 0.8424\n",
            "Epoch 14/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3536 - accuracy: 0.8619 - val_loss: 0.4387 - val_accuracy: 0.8405\n",
            "Epoch 15/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3554 - accuracy: 0.8658 - val_loss: 0.4222 - val_accuracy: 0.8249\n",
            "Epoch 16/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3557 - accuracy: 0.8604 - val_loss: 0.4340 - val_accuracy: 0.8230\n",
            "Epoch 17/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3545 - accuracy: 0.8662 - val_loss: 0.4222 - val_accuracy: 0.8424\n",
            "Epoch 18/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3548 - accuracy: 0.8653 - val_loss: 0.4241 - val_accuracy: 0.8463\n",
            "Epoch 19/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3567 - accuracy: 0.8633 - val_loss: 0.4230 - val_accuracy: 0.8444\n",
            "Epoch 20/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3543 - accuracy: 0.8696 - val_loss: 0.4292 - val_accuracy: 0.8405\n",
            "Epoch 21/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3547 - accuracy: 0.8638 - val_loss: 0.4299 - val_accuracy: 0.8424\n",
            "Epoch 22/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3567 - accuracy: 0.8638 - val_loss: 0.4282 - val_accuracy: 0.8346\n",
            "Epoch 23/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3539 - accuracy: 0.8643 - val_loss: 0.4356 - val_accuracy: 0.8307\n",
            "Epoch 24/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3542 - accuracy: 0.8692 - val_loss: 0.4369 - val_accuracy: 0.8288\n",
            "Epoch 25/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3558 - accuracy: 0.8653 - val_loss: 0.4361 - val_accuracy: 0.8424\n",
            "Epoch 26/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3557 - accuracy: 0.8594 - val_loss: 0.4243 - val_accuracy: 0.8346\n",
            "Epoch 27/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3540 - accuracy: 0.8604 - val_loss: 0.4317 - val_accuracy: 0.8307\n",
            "Epoch 28/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3542 - accuracy: 0.8677 - val_loss: 0.4396 - val_accuracy: 0.8132\n",
            "Epoch 29/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3540 - accuracy: 0.8662 - val_loss: 0.4257 - val_accuracy: 0.8113\n",
            "Epoch 30/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3543 - accuracy: 0.8662 - val_loss: 0.4389 - val_accuracy: 0.8366\n",
            "Epoch 31/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3552 - accuracy: 0.8648 - val_loss: 0.4141 - val_accuracy: 0.8307\n",
            "Epoch 32/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3534 - accuracy: 0.8672 - val_loss: 0.4180 - val_accuracy: 0.8521\n",
            "Epoch 33/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3542 - accuracy: 0.8662 - val_loss: 0.4332 - val_accuracy: 0.8366\n",
            "Epoch 34/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3547 - accuracy: 0.8662 - val_loss: 0.4242 - val_accuracy: 0.8424\n",
            "Epoch 35/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3536 - accuracy: 0.8653 - val_loss: 0.4277 - val_accuracy: 0.8249\n",
            "Epoch 36/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3549 - accuracy: 0.8658 - val_loss: 0.4196 - val_accuracy: 0.8405\n",
            "Epoch 37/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3543 - accuracy: 0.8643 - val_loss: 0.4432 - val_accuracy: 0.8249\n",
            "Epoch 38/50\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.3558 - accuracy: 0.8633 - val_loss: 0.4262 - val_accuracy: 0.8327\n",
            "Epoch 39/50\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.3540 - accuracy: 0.8633 - val_loss: 0.4178 - val_accuracy: 0.8482\n",
            "Epoch 40/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3551 - accuracy: 0.8638 - val_loss: 0.4344 - val_accuracy: 0.8307\n",
            "Epoch 41/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3535 - accuracy: 0.8682 - val_loss: 0.4226 - val_accuracy: 0.8424\n",
            "Epoch 42/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3543 - accuracy: 0.8648 - val_loss: 0.4305 - val_accuracy: 0.8171\n",
            "Epoch 43/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3551 - accuracy: 0.8658 - val_loss: 0.4290 - val_accuracy: 0.8268\n",
            "Epoch 44/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3560 - accuracy: 0.8628 - val_loss: 0.4227 - val_accuracy: 0.8541\n",
            "Epoch 45/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.8653 - val_loss: 0.4342 - val_accuracy: 0.8346\n",
            "Epoch 46/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3536 - accuracy: 0.8638 - val_loss: 0.4320 - val_accuracy: 0.8093\n",
            "Epoch 47/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3537 - accuracy: 0.8662 - val_loss: 0.4303 - val_accuracy: 0.8541\n",
            "Epoch 48/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3549 - accuracy: 0.8687 - val_loss: 0.4341 - val_accuracy: 0.8327\n",
            "Epoch 49/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3537 - accuracy: 0.8628 - val_loss: 0.4413 - val_accuracy: 0.8385\n",
            "Epoch 50/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3537 - accuracy: 0.8682 - val_loss: 0.4377 - val_accuracy: 0.8521\n",
            "Training Model 3\n",
            "Epoch 1/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3439 - accuracy: 0.8725 - val_loss: 0.3985 - val_accuracy: 0.8487\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3449 - accuracy: 0.8706 - val_loss: 0.4098 - val_accuracy: 0.8467\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3434 - accuracy: 0.8734 - val_loss: 0.4123 - val_accuracy: 0.8544\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3429 - accuracy: 0.8749 - val_loss: 0.4181 - val_accuracy: 0.8487\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3441 - accuracy: 0.8658 - val_loss: 0.4091 - val_accuracy: 0.8563\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3448 - accuracy: 0.8701 - val_loss: 0.4000 - val_accuracy: 0.8563\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.8773 - val_loss: 0.4010 - val_accuracy: 0.8525\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3437 - accuracy: 0.8739 - val_loss: 0.3955 - val_accuracy: 0.8582\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3423 - accuracy: 0.8754 - val_loss: 0.3987 - val_accuracy: 0.8544\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3417 - accuracy: 0.8667 - val_loss: 0.4296 - val_accuracy: 0.8372\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3441 - accuracy: 0.8691 - val_loss: 0.4024 - val_accuracy: 0.8429\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3416 - accuracy: 0.8725 - val_loss: 0.5022 - val_accuracy: 0.7893\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3461 - accuracy: 0.8658 - val_loss: 0.4060 - val_accuracy: 0.8467\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3451 - accuracy: 0.8710 - val_loss: 0.3985 - val_accuracy: 0.8602\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3426 - accuracy: 0.8758 - val_loss: 0.4067 - val_accuracy: 0.8563\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3449 - accuracy: 0.8696 - val_loss: 0.4004 - val_accuracy: 0.8391\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3444 - accuracy: 0.8725 - val_loss: 0.4016 - val_accuracy: 0.8582\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3420 - accuracy: 0.8730 - val_loss: 0.3964 - val_accuracy: 0.8544\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3422 - accuracy: 0.8715 - val_loss: 0.4373 - val_accuracy: 0.8410\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3442 - accuracy: 0.8696 - val_loss: 0.3982 - val_accuracy: 0.8563\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3441 - accuracy: 0.8701 - val_loss: 0.3986 - val_accuracy: 0.8448\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3431 - accuracy: 0.8706 - val_loss: 0.4100 - val_accuracy: 0.8544\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3412 - accuracy: 0.8710 - val_loss: 0.4144 - val_accuracy: 0.8467\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3446 - accuracy: 0.8749 - val_loss: 0.3969 - val_accuracy: 0.8506\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3428 - accuracy: 0.8667 - val_loss: 0.4070 - val_accuracy: 0.8448\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3419 - accuracy: 0.8730 - val_loss: 0.4240 - val_accuracy: 0.8314\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3461 - accuracy: 0.8672 - val_loss: 0.3999 - val_accuracy: 0.8544\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 0.3436 - accuracy: 0.8696 - val_loss: 0.4044 - val_accuracy: 0.8506\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3409 - accuracy: 0.8768 - val_loss: 0.4014 - val_accuracy: 0.8563\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3422 - accuracy: 0.8691 - val_loss: 0.4114 - val_accuracy: 0.8429\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3426 - accuracy: 0.8730 - val_loss: 0.4592 - val_accuracy: 0.8218\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3435 - accuracy: 0.8734 - val_loss: 0.4015 - val_accuracy: 0.8448\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3402 - accuracy: 0.8758 - val_loss: 0.4034 - val_accuracy: 0.8487\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3417 - accuracy: 0.8773 - val_loss: 0.4080 - val_accuracy: 0.8429\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3431 - accuracy: 0.8739 - val_loss: 0.5119 - val_accuracy: 0.7912\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3461 - accuracy: 0.8696 - val_loss: 0.4068 - val_accuracy: 0.8467\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3421 - accuracy: 0.8706 - val_loss: 0.4131 - val_accuracy: 0.8429\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3428 - accuracy: 0.8715 - val_loss: 0.4036 - val_accuracy: 0.8391\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3426 - accuracy: 0.8701 - val_loss: 0.4053 - val_accuracy: 0.8372\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3443 - accuracy: 0.8706 - val_loss: 0.4027 - val_accuracy: 0.8525\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3417 - accuracy: 0.8749 - val_loss: 0.4112 - val_accuracy: 0.8487\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3427 - accuracy: 0.8696 - val_loss: 0.4072 - val_accuracy: 0.8525\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3435 - accuracy: 0.8720 - val_loss: 0.3982 - val_accuracy: 0.8563\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3417 - accuracy: 0.8744 - val_loss: 0.4162 - val_accuracy: 0.8467\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3446 - accuracy: 0.8691 - val_loss: 0.4512 - val_accuracy: 0.8218\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3446 - accuracy: 0.8672 - val_loss: 0.4113 - val_accuracy: 0.8563\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3419 - accuracy: 0.8696 - val_loss: 0.4215 - val_accuracy: 0.8372\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3463 - accuracy: 0.8715 - val_loss: 0.4087 - val_accuracy: 0.8602\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3442 - accuracy: 0.8744 - val_loss: 0.4117 - val_accuracy: 0.8506\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3454 - accuracy: 0.8720 - val_loss: 0.4071 - val_accuracy: 0.8391\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.4515 - accuracy: 0.7896\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6020 - accuracy: 0.7339\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6087 - accuracy: 0.7456\n",
            "\n",
            "Iteration: 8\n",
            "Weights extracted succesfully\n",
            "Weights averaged successfully\n",
            "New weights assigned successfully\n",
            "Training Model 1\n",
            "Epoch 1/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3670 - accuracy: 0.8547 - val_loss: 0.3858 - val_accuracy: 0.8640\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3668 - accuracy: 0.8624 - val_loss: 0.3949 - val_accuracy: 0.8582\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3658 - accuracy: 0.8581 - val_loss: 0.3875 - val_accuracy: 0.8582\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3656 - accuracy: 0.8595 - val_loss: 0.5156 - val_accuracy: 0.7720\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3714 - accuracy: 0.8576 - val_loss: 0.3803 - val_accuracy: 0.8525\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3657 - accuracy: 0.8600 - val_loss: 0.3893 - val_accuracy: 0.8602\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3643 - accuracy: 0.8595 - val_loss: 0.3914 - val_accuracy: 0.8563\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3652 - accuracy: 0.8615 - val_loss: 0.3954 - val_accuracy: 0.8678\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3666 - accuracy: 0.8586 - val_loss: 0.3843 - val_accuracy: 0.8716\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3654 - accuracy: 0.8571 - val_loss: 0.3800 - val_accuracy: 0.8621\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3672 - accuracy: 0.8619 - val_loss: 0.3883 - val_accuracy: 0.8544\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3659 - accuracy: 0.8619 - val_loss: 0.3844 - val_accuracy: 0.8697\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3640 - accuracy: 0.8643 - val_loss: 0.4071 - val_accuracy: 0.8257\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3663 - accuracy: 0.8562 - val_loss: 0.3920 - val_accuracy: 0.8678\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3647 - accuracy: 0.8547 - val_loss: 0.3878 - val_accuracy: 0.8582\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3646 - accuracy: 0.8653 - val_loss: 0.3881 - val_accuracy: 0.8467\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3637 - accuracy: 0.8639 - val_loss: 0.3799 - val_accuracy: 0.8602\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3658 - accuracy: 0.8615 - val_loss: 0.3898 - val_accuracy: 0.8582\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3650 - accuracy: 0.8586 - val_loss: 0.3891 - val_accuracy: 0.8697\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3660 - accuracy: 0.8581 - val_loss: 0.3864 - val_accuracy: 0.8602\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3640 - accuracy: 0.8605 - val_loss: 0.3878 - val_accuracy: 0.8697\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3645 - accuracy: 0.8571 - val_loss: 0.4027 - val_accuracy: 0.8372\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3665 - accuracy: 0.8605 - val_loss: 0.3899 - val_accuracy: 0.8429\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3662 - accuracy: 0.8581 - val_loss: 0.3847 - val_accuracy: 0.8678\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3665 - accuracy: 0.8605 - val_loss: 0.4224 - val_accuracy: 0.8257\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3687 - accuracy: 0.8543 - val_loss: 0.3917 - val_accuracy: 0.8487\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3651 - accuracy: 0.8586 - val_loss: 0.4030 - val_accuracy: 0.8506\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3652 - accuracy: 0.8562 - val_loss: 0.3863 - val_accuracy: 0.8602\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3647 - accuracy: 0.8629 - val_loss: 0.3821 - val_accuracy: 0.8602\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3649 - accuracy: 0.8605 - val_loss: 0.3888 - val_accuracy: 0.8506\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3653 - accuracy: 0.8624 - val_loss: 0.3856 - val_accuracy: 0.8716\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3651 - accuracy: 0.8571 - val_loss: 0.3947 - val_accuracy: 0.8429\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3663 - accuracy: 0.8576 - val_loss: 0.3869 - val_accuracy: 0.8602\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3661 - accuracy: 0.8567 - val_loss: 0.3910 - val_accuracy: 0.8640\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3662 - accuracy: 0.8581 - val_loss: 0.3901 - val_accuracy: 0.8659\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3647 - accuracy: 0.8581 - val_loss: 0.3894 - val_accuracy: 0.8602\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3668 - accuracy: 0.8600 - val_loss: 0.3861 - val_accuracy: 0.8640\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3666 - accuracy: 0.8567 - val_loss: 0.3873 - val_accuracy: 0.8582\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3652 - accuracy: 0.8547 - val_loss: 0.3829 - val_accuracy: 0.8602\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3647 - accuracy: 0.8586 - val_loss: 0.3853 - val_accuracy: 0.8563\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3657 - accuracy: 0.8576 - val_loss: 0.3928 - val_accuracy: 0.8467\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3655 - accuracy: 0.8600 - val_loss: 0.3897 - val_accuracy: 0.8506\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3674 - accuracy: 0.8571 - val_loss: 0.3989 - val_accuracy: 0.8391\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3655 - accuracy: 0.8586 - val_loss: 0.3931 - val_accuracy: 0.8563\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3656 - accuracy: 0.8624 - val_loss: 0.3896 - val_accuracy: 0.8602\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3648 - accuracy: 0.8610 - val_loss: 0.3918 - val_accuracy: 0.8525\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3639 - accuracy: 0.8605 - val_loss: 0.3911 - val_accuracy: 0.8640\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3662 - accuracy: 0.8605 - val_loss: 0.4028 - val_accuracy: 0.8333\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3660 - accuracy: 0.8562 - val_loss: 0.3968 - val_accuracy: 0.8410\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3654 - accuracy: 0.8567 - val_loss: 0.3951 - val_accuracy: 0.8429\n",
            "Training Model 2\n",
            "Epoch 1/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3565 - accuracy: 0.8609 - val_loss: 0.4177 - val_accuracy: 0.8444\n",
            "Epoch 2/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3530 - accuracy: 0.8687 - val_loss: 0.4320 - val_accuracy: 0.8152\n",
            "Epoch 3/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3543 - accuracy: 0.8633 - val_loss: 0.4272 - val_accuracy: 0.8249\n",
            "Epoch 4/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3550 - accuracy: 0.8677 - val_loss: 0.4307 - val_accuracy: 0.8191\n",
            "Epoch 5/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3557 - accuracy: 0.8643 - val_loss: 0.4177 - val_accuracy: 0.8502\n",
            "Epoch 6/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3542 - accuracy: 0.8643 - val_loss: 0.4290 - val_accuracy: 0.8444\n",
            "Epoch 7/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3542 - accuracy: 0.8638 - val_loss: 0.4191 - val_accuracy: 0.8405\n",
            "Epoch 8/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3531 - accuracy: 0.8648 - val_loss: 0.4108 - val_accuracy: 0.8346\n",
            "Epoch 9/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3556 - accuracy: 0.8648 - val_loss: 0.4331 - val_accuracy: 0.8307\n",
            "Epoch 10/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3557 - accuracy: 0.8672 - val_loss: 0.4336 - val_accuracy: 0.8385\n",
            "Epoch 11/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3549 - accuracy: 0.8609 - val_loss: 0.4425 - val_accuracy: 0.8346\n",
            "Epoch 12/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3566 - accuracy: 0.8662 - val_loss: 0.4210 - val_accuracy: 0.8366\n",
            "Epoch 13/50\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3542 - accuracy: 0.8653 - val_loss: 0.4177 - val_accuracy: 0.8424\n",
            "Epoch 14/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3529 - accuracy: 0.8648 - val_loss: 0.4402 - val_accuracy: 0.8424\n",
            "Epoch 15/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3547 - accuracy: 0.8648 - val_loss: 0.4244 - val_accuracy: 0.8249\n",
            "Epoch 16/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3552 - accuracy: 0.8648 - val_loss: 0.4339 - val_accuracy: 0.8268\n",
            "Epoch 17/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3536 - accuracy: 0.8692 - val_loss: 0.4224 - val_accuracy: 0.8405\n",
            "Epoch 18/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3540 - accuracy: 0.8687 - val_loss: 0.4248 - val_accuracy: 0.8502\n",
            "Epoch 19/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3560 - accuracy: 0.8653 - val_loss: 0.4225 - val_accuracy: 0.8482\n",
            "Epoch 20/50\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.3538 - accuracy: 0.8696 - val_loss: 0.4311 - val_accuracy: 0.8444\n",
            "Epoch 21/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3538 - accuracy: 0.8672 - val_loss: 0.4310 - val_accuracy: 0.8444\n",
            "Epoch 22/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3562 - accuracy: 0.8628 - val_loss: 0.4278 - val_accuracy: 0.8463\n",
            "Epoch 23/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3529 - accuracy: 0.8658 - val_loss: 0.4369 - val_accuracy: 0.8366\n",
            "Epoch 24/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3534 - accuracy: 0.8662 - val_loss: 0.4378 - val_accuracy: 0.8288\n",
            "Epoch 25/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3550 - accuracy: 0.8667 - val_loss: 0.4352 - val_accuracy: 0.8463\n",
            "Epoch 26/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3550 - accuracy: 0.8594 - val_loss: 0.4253 - val_accuracy: 0.8327\n",
            "Epoch 27/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3536 - accuracy: 0.8599 - val_loss: 0.4325 - val_accuracy: 0.8385\n",
            "Epoch 28/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3533 - accuracy: 0.8672 - val_loss: 0.4405 - val_accuracy: 0.8230\n",
            "Epoch 29/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3537 - accuracy: 0.8628 - val_loss: 0.4307 - val_accuracy: 0.8054\n",
            "Epoch 30/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3538 - accuracy: 0.8706 - val_loss: 0.4399 - val_accuracy: 0.8444\n",
            "Epoch 31/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3547 - accuracy: 0.8638 - val_loss: 0.4159 - val_accuracy: 0.8346\n",
            "Epoch 32/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3533 - accuracy: 0.8682 - val_loss: 0.4204 - val_accuracy: 0.8541\n",
            "Epoch 33/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3536 - accuracy: 0.8662 - val_loss: 0.4358 - val_accuracy: 0.8366\n",
            "Epoch 34/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3542 - accuracy: 0.8672 - val_loss: 0.4260 - val_accuracy: 0.8405\n",
            "Epoch 35/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3531 - accuracy: 0.8628 - val_loss: 0.4284 - val_accuracy: 0.8249\n",
            "Epoch 36/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3544 - accuracy: 0.8682 - val_loss: 0.4200 - val_accuracy: 0.8405\n",
            "Epoch 37/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3536 - accuracy: 0.8628 - val_loss: 0.4438 - val_accuracy: 0.8210\n",
            "Epoch 38/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3553 - accuracy: 0.8677 - val_loss: 0.4266 - val_accuracy: 0.8268\n",
            "Epoch 39/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3536 - accuracy: 0.8628 - val_loss: 0.4203 - val_accuracy: 0.8463\n",
            "Epoch 40/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3546 - accuracy: 0.8653 - val_loss: 0.4347 - val_accuracy: 0.8288\n",
            "Epoch 41/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3530 - accuracy: 0.8662 - val_loss: 0.4230 - val_accuracy: 0.8463\n",
            "Epoch 42/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3536 - accuracy: 0.8643 - val_loss: 0.4306 - val_accuracy: 0.8132\n",
            "Epoch 43/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3546 - accuracy: 0.8658 - val_loss: 0.4319 - val_accuracy: 0.8249\n",
            "Epoch 44/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3557 - accuracy: 0.8624 - val_loss: 0.4257 - val_accuracy: 0.8482\n",
            "Epoch 45/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3550 - accuracy: 0.8658 - val_loss: 0.4354 - val_accuracy: 0.8307\n",
            "Epoch 46/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3531 - accuracy: 0.8648 - val_loss: 0.4352 - val_accuracy: 0.8054\n",
            "Epoch 47/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3532 - accuracy: 0.8677 - val_loss: 0.4319 - val_accuracy: 0.8482\n",
            "Epoch 48/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3545 - accuracy: 0.8682 - val_loss: 0.4367 - val_accuracy: 0.8385\n",
            "Epoch 49/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3528 - accuracy: 0.8648 - val_loss: 0.4418 - val_accuracy: 0.8385\n",
            "Epoch 50/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3532 - accuracy: 0.8682 - val_loss: 0.4380 - val_accuracy: 0.8541\n",
            "Training Model 3\n",
            "Epoch 1/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3436 - accuracy: 0.8715 - val_loss: 0.3981 - val_accuracy: 0.8487\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3447 - accuracy: 0.8696 - val_loss: 0.4096 - val_accuracy: 0.8506\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3430 - accuracy: 0.8730 - val_loss: 0.4112 - val_accuracy: 0.8544\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3427 - accuracy: 0.8744 - val_loss: 0.4181 - val_accuracy: 0.8467\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3438 - accuracy: 0.8672 - val_loss: 0.4092 - val_accuracy: 0.8563\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3444 - accuracy: 0.8691 - val_loss: 0.3994 - val_accuracy: 0.8563\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3417 - accuracy: 0.8773 - val_loss: 0.4004 - val_accuracy: 0.8525\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3435 - accuracy: 0.8720 - val_loss: 0.3956 - val_accuracy: 0.8602\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3420 - accuracy: 0.8754 - val_loss: 0.3984 - val_accuracy: 0.8544\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3414 - accuracy: 0.8677 - val_loss: 0.4297 - val_accuracy: 0.8391\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3437 - accuracy: 0.8701 - val_loss: 0.4023 - val_accuracy: 0.8448\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3414 - accuracy: 0.8710 - val_loss: 0.5029 - val_accuracy: 0.7931\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3456 - accuracy: 0.8653 - val_loss: 0.4065 - val_accuracy: 0.8467\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3448 - accuracy: 0.8725 - val_loss: 0.3984 - val_accuracy: 0.8602\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3422 - accuracy: 0.8744 - val_loss: 0.4067 - val_accuracy: 0.8563\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3449 - accuracy: 0.8701 - val_loss: 0.4002 - val_accuracy: 0.8391\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3445 - accuracy: 0.8710 - val_loss: 0.4010 - val_accuracy: 0.8582\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3417 - accuracy: 0.8730 - val_loss: 0.3955 - val_accuracy: 0.8582\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3420 - accuracy: 0.8715 - val_loss: 0.4376 - val_accuracy: 0.8410\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3440 - accuracy: 0.8701 - val_loss: 0.3972 - val_accuracy: 0.8563\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3439 - accuracy: 0.8706 - val_loss: 0.3980 - val_accuracy: 0.8487\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3428 - accuracy: 0.8715 - val_loss: 0.4095 - val_accuracy: 0.8544\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3409 - accuracy: 0.8720 - val_loss: 0.4145 - val_accuracy: 0.8487\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3444 - accuracy: 0.8749 - val_loss: 0.3968 - val_accuracy: 0.8506\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3426 - accuracy: 0.8686 - val_loss: 0.4064 - val_accuracy: 0.8448\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3417 - accuracy: 0.8739 - val_loss: 0.4228 - val_accuracy: 0.8314\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3453 - accuracy: 0.8667 - val_loss: 0.3990 - val_accuracy: 0.8544\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3433 - accuracy: 0.8701 - val_loss: 0.4044 - val_accuracy: 0.8544\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3406 - accuracy: 0.8754 - val_loss: 0.4008 - val_accuracy: 0.8563\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3418 - accuracy: 0.8682 - val_loss: 0.4113 - val_accuracy: 0.8448\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3422 - accuracy: 0.8730 - val_loss: 0.4601 - val_accuracy: 0.8199\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3434 - accuracy: 0.8744 - val_loss: 0.4019 - val_accuracy: 0.8467\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3398 - accuracy: 0.8763 - val_loss: 0.4035 - val_accuracy: 0.8487\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3413 - accuracy: 0.8773 - val_loss: 0.4086 - val_accuracy: 0.8429\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3426 - accuracy: 0.8715 - val_loss: 0.5146 - val_accuracy: 0.7893\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3461 - accuracy: 0.8686 - val_loss: 0.4058 - val_accuracy: 0.8525\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3416 - accuracy: 0.8715 - val_loss: 0.4135 - val_accuracy: 0.8429\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3424 - accuracy: 0.8715 - val_loss: 0.4041 - val_accuracy: 0.8391\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3423 - accuracy: 0.8686 - val_loss: 0.4056 - val_accuracy: 0.8372\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3442 - accuracy: 0.8701 - val_loss: 0.4025 - val_accuracy: 0.8544\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3414 - accuracy: 0.8754 - val_loss: 0.4116 - val_accuracy: 0.8467\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3424 - accuracy: 0.8691 - val_loss: 0.4068 - val_accuracy: 0.8506\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3430 - accuracy: 0.8706 - val_loss: 0.4006 - val_accuracy: 0.8525\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3414 - accuracy: 0.8754 - val_loss: 0.4160 - val_accuracy: 0.8467\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3440 - accuracy: 0.8686 - val_loss: 0.4509 - val_accuracy: 0.8218\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3444 - accuracy: 0.8682 - val_loss: 0.4114 - val_accuracy: 0.8563\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3417 - accuracy: 0.8691 - val_loss: 0.4214 - val_accuracy: 0.8352\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3459 - accuracy: 0.8720 - val_loss: 0.4089 - val_accuracy: 0.8602\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3441 - accuracy: 0.8734 - val_loss: 0.4122 - val_accuracy: 0.8506\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3453 - accuracy: 0.8725 - val_loss: 0.4071 - val_accuracy: 0.8410\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.7867\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6009 - accuracy: 0.7339\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6097 - accuracy: 0.7436\n",
            "\n",
            "Iteration: 9\n",
            "Weights extracted succesfully\n",
            "Weights averaged successfully\n",
            "New weights assigned successfully\n",
            "Training Model 1\n",
            "Epoch 1/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3663 - accuracy: 0.8562 - val_loss: 0.3854 - val_accuracy: 0.8621\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3663 - accuracy: 0.8629 - val_loss: 0.3940 - val_accuracy: 0.8582\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3650 - accuracy: 0.8581 - val_loss: 0.3864 - val_accuracy: 0.8582\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 0.3650 - accuracy: 0.8605 - val_loss: 0.5188 - val_accuracy: 0.7720\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8557 - val_loss: 0.3793 - val_accuracy: 0.8563\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3650 - accuracy: 0.8600 - val_loss: 0.3879 - val_accuracy: 0.8640\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3640 - accuracy: 0.8595 - val_loss: 0.3905 - val_accuracy: 0.8544\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3641 - accuracy: 0.8595 - val_loss: 0.3952 - val_accuracy: 0.8678\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3658 - accuracy: 0.8591 - val_loss: 0.3833 - val_accuracy: 0.8697\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3648 - accuracy: 0.8581 - val_loss: 0.3790 - val_accuracy: 0.8602\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3666 - accuracy: 0.8605 - val_loss: 0.3872 - val_accuracy: 0.8506\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3654 - accuracy: 0.8619 - val_loss: 0.3835 - val_accuracy: 0.8697\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3635 - accuracy: 0.8643 - val_loss: 0.4065 - val_accuracy: 0.8276\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3659 - accuracy: 0.8567 - val_loss: 0.3915 - val_accuracy: 0.8678\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3640 - accuracy: 0.8567 - val_loss: 0.3866 - val_accuracy: 0.8602\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3640 - accuracy: 0.8643 - val_loss: 0.3869 - val_accuracy: 0.8487\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3629 - accuracy: 0.8648 - val_loss: 0.3796 - val_accuracy: 0.8582\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3650 - accuracy: 0.8600 - val_loss: 0.3889 - val_accuracy: 0.8582\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3646 - accuracy: 0.8600 - val_loss: 0.3881 - val_accuracy: 0.8697\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3653 - accuracy: 0.8586 - val_loss: 0.3854 - val_accuracy: 0.8621\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3635 - accuracy: 0.8600 - val_loss: 0.3876 - val_accuracy: 0.8659\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3640 - accuracy: 0.8571 - val_loss: 0.4012 - val_accuracy: 0.8391\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3660 - accuracy: 0.8624 - val_loss: 0.3894 - val_accuracy: 0.8487\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3656 - accuracy: 0.8571 - val_loss: 0.3836 - val_accuracy: 0.8659\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3660 - accuracy: 0.8615 - val_loss: 0.4307 - val_accuracy: 0.8199\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3683 - accuracy: 0.8562 - val_loss: 0.3903 - val_accuracy: 0.8487\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3646 - accuracy: 0.8581 - val_loss: 0.4025 - val_accuracy: 0.8487\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3647 - accuracy: 0.8576 - val_loss: 0.3855 - val_accuracy: 0.8563\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3643 - accuracy: 0.8615 - val_loss: 0.3817 - val_accuracy: 0.8602\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3643 - accuracy: 0.8591 - val_loss: 0.3876 - val_accuracy: 0.8525\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3648 - accuracy: 0.8610 - val_loss: 0.3848 - val_accuracy: 0.8716\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3645 - accuracy: 0.8567 - val_loss: 0.3945 - val_accuracy: 0.8448\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3660 - accuracy: 0.8576 - val_loss: 0.3860 - val_accuracy: 0.8582\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3654 - accuracy: 0.8562 - val_loss: 0.3908 - val_accuracy: 0.8621\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3660 - accuracy: 0.8562 - val_loss: 0.3884 - val_accuracy: 0.8659\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3642 - accuracy: 0.8571 - val_loss: 0.3891 - val_accuracy: 0.8602\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3663 - accuracy: 0.8605 - val_loss: 0.3849 - val_accuracy: 0.8621\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3662 - accuracy: 0.8562 - val_loss: 0.3856 - val_accuracy: 0.8602\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3647 - accuracy: 0.8562 - val_loss: 0.3813 - val_accuracy: 0.8659\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3639 - accuracy: 0.8595 - val_loss: 0.3845 - val_accuracy: 0.8506\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3654 - accuracy: 0.8576 - val_loss: 0.3920 - val_accuracy: 0.8487\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3652 - accuracy: 0.8595 - val_loss: 0.3889 - val_accuracy: 0.8506\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3669 - accuracy: 0.8571 - val_loss: 0.3984 - val_accuracy: 0.8410\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3651 - accuracy: 0.8591 - val_loss: 0.3923 - val_accuracy: 0.8563\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3646 - accuracy: 0.8619 - val_loss: 0.3889 - val_accuracy: 0.8602\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3642 - accuracy: 0.8605 - val_loss: 0.3908 - val_accuracy: 0.8544\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3635 - accuracy: 0.8610 - val_loss: 0.3901 - val_accuracy: 0.8602\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3661 - accuracy: 0.8595 - val_loss: 0.3944 - val_accuracy: 0.8410\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3650 - accuracy: 0.8567 - val_loss: 0.3958 - val_accuracy: 0.8448\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3648 - accuracy: 0.8571 - val_loss: 0.3944 - val_accuracy: 0.8410\n",
            "Training Model 2\n",
            "Epoch 1/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3558 - accuracy: 0.8599 - val_loss: 0.4170 - val_accuracy: 0.8463\n",
            "Epoch 2/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3524 - accuracy: 0.8662 - val_loss: 0.4313 - val_accuracy: 0.8191\n",
            "Epoch 3/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3538 - accuracy: 0.8633 - val_loss: 0.4268 - val_accuracy: 0.8288\n",
            "Epoch 4/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3541 - accuracy: 0.8638 - val_loss: 0.4338 - val_accuracy: 0.8210\n",
            "Epoch 5/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3551 - accuracy: 0.8653 - val_loss: 0.4190 - val_accuracy: 0.8482\n",
            "Epoch 6/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3538 - accuracy: 0.8662 - val_loss: 0.4305 - val_accuracy: 0.8424\n",
            "Epoch 7/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3537 - accuracy: 0.8628 - val_loss: 0.4199 - val_accuracy: 0.8424\n",
            "Epoch 8/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3524 - accuracy: 0.8658 - val_loss: 0.4124 - val_accuracy: 0.8366\n",
            "Epoch 9/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3548 - accuracy: 0.8633 - val_loss: 0.4357 - val_accuracy: 0.8307\n",
            "Epoch 10/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3553 - accuracy: 0.8672 - val_loss: 0.4344 - val_accuracy: 0.8444\n",
            "Epoch 11/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3546 - accuracy: 0.8609 - val_loss: 0.4458 - val_accuracy: 0.8385\n",
            "Epoch 12/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3559 - accuracy: 0.8662 - val_loss: 0.4239 - val_accuracy: 0.8366\n",
            "Epoch 13/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3537 - accuracy: 0.8653 - val_loss: 0.4199 - val_accuracy: 0.8444\n",
            "Epoch 14/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3525 - accuracy: 0.8643 - val_loss: 0.4426 - val_accuracy: 0.8444\n",
            "Epoch 15/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3540 - accuracy: 0.8643 - val_loss: 0.4271 - val_accuracy: 0.8230\n",
            "Epoch 16/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3547 - accuracy: 0.8643 - val_loss: 0.4361 - val_accuracy: 0.8268\n",
            "Epoch 17/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3531 - accuracy: 0.8706 - val_loss: 0.4243 - val_accuracy: 0.8385\n",
            "Epoch 18/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3535 - accuracy: 0.8672 - val_loss: 0.4265 - val_accuracy: 0.8521\n",
            "Epoch 19/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3553 - accuracy: 0.8658 - val_loss: 0.4257 - val_accuracy: 0.8482\n",
            "Epoch 20/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3537 - accuracy: 0.8682 - val_loss: 0.4343 - val_accuracy: 0.8405\n",
            "Epoch 21/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3533 - accuracy: 0.8653 - val_loss: 0.4339 - val_accuracy: 0.8482\n",
            "Epoch 22/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3560 - accuracy: 0.8638 - val_loss: 0.4290 - val_accuracy: 0.8405\n",
            "Epoch 23/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3528 - accuracy: 0.8667 - val_loss: 0.4377 - val_accuracy: 0.8444\n",
            "Epoch 24/50\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.3529 - accuracy: 0.8682 - val_loss: 0.4405 - val_accuracy: 0.8268\n",
            "Epoch 25/50\n",
            "65/65 [==============================] - 0s 8ms/step - loss: 0.3544 - accuracy: 0.8643 - val_loss: 0.4370 - val_accuracy: 0.8482\n",
            "Epoch 26/50\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 0.3546 - accuracy: 0.8648 - val_loss: 0.4263 - val_accuracy: 0.8307\n",
            "Epoch 27/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3534 - accuracy: 0.8638 - val_loss: 0.4338 - val_accuracy: 0.8405\n",
            "Epoch 28/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3527 - accuracy: 0.8682 - val_loss: 0.4421 - val_accuracy: 0.8152\n",
            "Epoch 29/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3532 - accuracy: 0.8672 - val_loss: 0.4324 - val_accuracy: 0.8074\n",
            "Epoch 30/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3532 - accuracy: 0.8696 - val_loss: 0.4432 - val_accuracy: 0.8405\n",
            "Epoch 31/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3543 - accuracy: 0.8677 - val_loss: 0.4155 - val_accuracy: 0.8307\n",
            "Epoch 32/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3525 - accuracy: 0.8692 - val_loss: 0.4213 - val_accuracy: 0.8580\n",
            "Epoch 33/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3532 - accuracy: 0.8643 - val_loss: 0.4367 - val_accuracy: 0.8366\n",
            "Epoch 34/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3533 - accuracy: 0.8662 - val_loss: 0.4270 - val_accuracy: 0.8424\n",
            "Epoch 35/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3523 - accuracy: 0.8633 - val_loss: 0.4283 - val_accuracy: 0.8230\n",
            "Epoch 36/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3536 - accuracy: 0.8682 - val_loss: 0.4204 - val_accuracy: 0.8424\n",
            "Epoch 37/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3530 - accuracy: 0.8643 - val_loss: 0.4430 - val_accuracy: 0.8210\n",
            "Epoch 38/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3546 - accuracy: 0.8653 - val_loss: 0.4272 - val_accuracy: 0.8268\n",
            "Epoch 39/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3526 - accuracy: 0.8638 - val_loss: 0.4218 - val_accuracy: 0.8482\n",
            "Epoch 40/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3541 - accuracy: 0.8662 - val_loss: 0.4339 - val_accuracy: 0.8288\n",
            "Epoch 41/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3524 - accuracy: 0.8672 - val_loss: 0.4239 - val_accuracy: 0.8463\n",
            "Epoch 42/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3529 - accuracy: 0.8658 - val_loss: 0.4320 - val_accuracy: 0.8132\n",
            "Epoch 43/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3542 - accuracy: 0.8658 - val_loss: 0.4320 - val_accuracy: 0.8268\n",
            "Epoch 44/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3548 - accuracy: 0.8628 - val_loss: 0.4272 - val_accuracy: 0.8482\n",
            "Epoch 45/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3543 - accuracy: 0.8667 - val_loss: 0.4349 - val_accuracy: 0.8288\n",
            "Epoch 46/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3522 - accuracy: 0.8667 - val_loss: 0.4361 - val_accuracy: 0.8093\n",
            "Epoch 47/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3526 - accuracy: 0.8687 - val_loss: 0.4343 - val_accuracy: 0.8521\n",
            "Epoch 48/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3536 - accuracy: 0.8667 - val_loss: 0.4380 - val_accuracy: 0.8366\n",
            "Epoch 49/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3524 - accuracy: 0.8648 - val_loss: 0.4438 - val_accuracy: 0.8405\n",
            "Epoch 50/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3523 - accuracy: 0.8682 - val_loss: 0.4416 - val_accuracy: 0.8541\n",
            "Training Model 3\n",
            "Epoch 1/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3434 - accuracy: 0.8720 - val_loss: 0.3983 - val_accuracy: 0.8467\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3444 - accuracy: 0.8701 - val_loss: 0.4088 - val_accuracy: 0.8506\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3428 - accuracy: 0.8725 - val_loss: 0.4110 - val_accuracy: 0.8563\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3429 - accuracy: 0.8725 - val_loss: 0.4184 - val_accuracy: 0.8467\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3434 - accuracy: 0.8653 - val_loss: 0.4090 - val_accuracy: 0.8582\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3440 - accuracy: 0.8686 - val_loss: 0.3996 - val_accuracy: 0.8563\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3413 - accuracy: 0.8778 - val_loss: 0.4005 - val_accuracy: 0.8525\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3431 - accuracy: 0.8734 - val_loss: 0.3958 - val_accuracy: 0.8582\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3416 - accuracy: 0.8744 - val_loss: 0.3976 - val_accuracy: 0.8525\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3411 - accuracy: 0.8667 - val_loss: 0.4305 - val_accuracy: 0.8314\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3434 - accuracy: 0.8686 - val_loss: 0.4020 - val_accuracy: 0.8448\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3409 - accuracy: 0.8710 - val_loss: 0.5059 - val_accuracy: 0.7874\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3455 - accuracy: 0.8653 - val_loss: 0.4072 - val_accuracy: 0.8487\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3446 - accuracy: 0.8706 - val_loss: 0.3983 - val_accuracy: 0.8602\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3419 - accuracy: 0.8749 - val_loss: 0.4060 - val_accuracy: 0.8563\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3445 - accuracy: 0.8691 - val_loss: 0.4001 - val_accuracy: 0.8391\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3445 - accuracy: 0.8725 - val_loss: 0.4006 - val_accuracy: 0.8582\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3413 - accuracy: 0.8739 - val_loss: 0.3961 - val_accuracy: 0.8544\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3415 - accuracy: 0.8706 - val_loss: 0.4379 - val_accuracy: 0.8410\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3436 - accuracy: 0.8701 - val_loss: 0.3984 - val_accuracy: 0.8544\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3438 - accuracy: 0.8691 - val_loss: 0.3984 - val_accuracy: 0.8467\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3426 - accuracy: 0.8710 - val_loss: 0.4092 - val_accuracy: 0.8544\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3406 - accuracy: 0.8710 - val_loss: 0.4143 - val_accuracy: 0.8467\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3441 - accuracy: 0.8734 - val_loss: 0.3964 - val_accuracy: 0.8506\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3422 - accuracy: 0.8663 - val_loss: 0.4063 - val_accuracy: 0.8467\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3415 - accuracy: 0.8725 - val_loss: 0.4249 - val_accuracy: 0.8295\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3453 - accuracy: 0.8667 - val_loss: 0.3991 - val_accuracy: 0.8563\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3429 - accuracy: 0.8691 - val_loss: 0.4042 - val_accuracy: 0.8525\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3406 - accuracy: 0.8763 - val_loss: 0.4008 - val_accuracy: 0.8563\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3416 - accuracy: 0.8701 - val_loss: 0.4099 - val_accuracy: 0.8410\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3421 - accuracy: 0.8730 - val_loss: 0.4834 - val_accuracy: 0.8142\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3437 - accuracy: 0.8730 - val_loss: 0.4020 - val_accuracy: 0.8506\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3394 - accuracy: 0.8763 - val_loss: 0.4032 - val_accuracy: 0.8487\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3411 - accuracy: 0.8773 - val_loss: 0.4078 - val_accuracy: 0.8429\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3423 - accuracy: 0.8734 - val_loss: 0.5085 - val_accuracy: 0.7874\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3453 - accuracy: 0.8701 - val_loss: 0.4068 - val_accuracy: 0.8506\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3412 - accuracy: 0.8706 - val_loss: 0.4134 - val_accuracy: 0.8448\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3423 - accuracy: 0.8710 - val_loss: 0.4034 - val_accuracy: 0.8410\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3418 - accuracy: 0.8686 - val_loss: 0.4055 - val_accuracy: 0.8391\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3440 - accuracy: 0.8725 - val_loss: 0.4022 - val_accuracy: 0.8525\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3413 - accuracy: 0.8754 - val_loss: 0.4111 - val_accuracy: 0.8467\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3423 - accuracy: 0.8686 - val_loss: 0.4066 - val_accuracy: 0.8525\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3428 - accuracy: 0.8696 - val_loss: 0.3979 - val_accuracy: 0.8563\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3411 - accuracy: 0.8734 - val_loss: 0.4156 - val_accuracy: 0.8467\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3436 - accuracy: 0.8701 - val_loss: 0.4537 - val_accuracy: 0.8199\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 0.3442 - accuracy: 0.8691 - val_loss: 0.4108 - val_accuracy: 0.8544\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3413 - accuracy: 0.8710 - val_loss: 0.4173 - val_accuracy: 0.8372\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3456 - accuracy: 0.8696 - val_loss: 0.4086 - val_accuracy: 0.8582\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3439 - accuracy: 0.8715 - val_loss: 0.4117 - val_accuracy: 0.8506\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3452 - accuracy: 0.8739 - val_loss: 0.4071 - val_accuracy: 0.8448\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.7857\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6025 - accuracy: 0.7299\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6096 - accuracy: 0.7436\n",
            "\n",
            "Iteration: 10\n",
            "Weights extracted succesfully\n",
            "Weights averaged successfully\n",
            "New weights assigned successfully\n",
            "Training Model 1\n",
            "Epoch 1/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3662 - accuracy: 0.8533 - val_loss: 0.3846 - val_accuracy: 0.8602\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3659 - accuracy: 0.8648 - val_loss: 0.3928 - val_accuracy: 0.8582\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3645 - accuracy: 0.8605 - val_loss: 0.3862 - val_accuracy: 0.8582\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3643 - accuracy: 0.8605 - val_loss: 0.5228 - val_accuracy: 0.7663\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3712 - accuracy: 0.8552 - val_loss: 0.3787 - val_accuracy: 0.8525\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3648 - accuracy: 0.8600 - val_loss: 0.3872 - val_accuracy: 0.8659\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3633 - accuracy: 0.8600 - val_loss: 0.3896 - val_accuracy: 0.8563\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3639 - accuracy: 0.8615 - val_loss: 0.3936 - val_accuracy: 0.8678\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3654 - accuracy: 0.8591 - val_loss: 0.3824 - val_accuracy: 0.8716\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3641 - accuracy: 0.8576 - val_loss: 0.3779 - val_accuracy: 0.8582\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3662 - accuracy: 0.8619 - val_loss: 0.3875 - val_accuracy: 0.8487\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3650 - accuracy: 0.8600 - val_loss: 0.3818 - val_accuracy: 0.8659\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3630 - accuracy: 0.8629 - val_loss: 0.4064 - val_accuracy: 0.8276\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3656 - accuracy: 0.8552 - val_loss: 0.3902 - val_accuracy: 0.8678\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3636 - accuracy: 0.8547 - val_loss: 0.3857 - val_accuracy: 0.8602\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3633 - accuracy: 0.8648 - val_loss: 0.3866 - val_accuracy: 0.8487\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3628 - accuracy: 0.8639 - val_loss: 0.3778 - val_accuracy: 0.8678\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3644 - accuracy: 0.8600 - val_loss: 0.3880 - val_accuracy: 0.8602\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3646 - accuracy: 0.8595 - val_loss: 0.3872 - val_accuracy: 0.8697\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3651 - accuracy: 0.8581 - val_loss: 0.3841 - val_accuracy: 0.8582\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3633 - accuracy: 0.8610 - val_loss: 0.3874 - val_accuracy: 0.8659\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3638 - accuracy: 0.8571 - val_loss: 0.4012 - val_accuracy: 0.8352\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3659 - accuracy: 0.8615 - val_loss: 0.3888 - val_accuracy: 0.8506\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3652 - accuracy: 0.8571 - val_loss: 0.3831 - val_accuracy: 0.8659\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3654 - accuracy: 0.8595 - val_loss: 0.4285 - val_accuracy: 0.8218\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3683 - accuracy: 0.8547 - val_loss: 0.3897 - val_accuracy: 0.8467\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3642 - accuracy: 0.8605 - val_loss: 0.4018 - val_accuracy: 0.8506\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 0.3642 - accuracy: 0.8595 - val_loss: 0.3843 - val_accuracy: 0.8602\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3636 - accuracy: 0.8619 - val_loss: 0.3805 - val_accuracy: 0.8640\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3638 - accuracy: 0.8586 - val_loss: 0.3875 - val_accuracy: 0.8487\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3643 - accuracy: 0.8639 - val_loss: 0.3839 - val_accuracy: 0.8716\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3640 - accuracy: 0.8571 - val_loss: 0.3928 - val_accuracy: 0.8429\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3656 - accuracy: 0.8576 - val_loss: 0.3842 - val_accuracy: 0.8659\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3648 - accuracy: 0.8576 - val_loss: 0.3894 - val_accuracy: 0.8621\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3655 - accuracy: 0.8543 - val_loss: 0.3879 - val_accuracy: 0.8659\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3641 - accuracy: 0.8591 - val_loss: 0.3883 - val_accuracy: 0.8621\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3659 - accuracy: 0.8586 - val_loss: 0.3839 - val_accuracy: 0.8621\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3657 - accuracy: 0.8571 - val_loss: 0.3852 - val_accuracy: 0.8563\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3644 - accuracy: 0.8552 - val_loss: 0.3806 - val_accuracy: 0.8640\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3632 - accuracy: 0.8581 - val_loss: 0.3842 - val_accuracy: 0.8544\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3652 - accuracy: 0.8562 - val_loss: 0.3926 - val_accuracy: 0.8506\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3649 - accuracy: 0.8610 - val_loss: 0.3877 - val_accuracy: 0.8525\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3664 - accuracy: 0.8562 - val_loss: 0.3991 - val_accuracy: 0.8410\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3648 - accuracy: 0.8586 - val_loss: 0.3914 - val_accuracy: 0.8544\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3644 - accuracy: 0.8619 - val_loss: 0.3879 - val_accuracy: 0.8602\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3639 - accuracy: 0.8600 - val_loss: 0.3904 - val_accuracy: 0.8525\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3632 - accuracy: 0.8591 - val_loss: 0.3891 - val_accuracy: 0.8621\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3659 - accuracy: 0.8586 - val_loss: 0.3922 - val_accuracy: 0.8410\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3646 - accuracy: 0.8562 - val_loss: 0.3956 - val_accuracy: 0.8429\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3643 - accuracy: 0.8562 - val_loss: 0.3944 - val_accuracy: 0.8410\n",
            "Training Model 2\n",
            "Epoch 1/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3549 - accuracy: 0.8594 - val_loss: 0.4195 - val_accuracy: 0.8366\n",
            "Epoch 2/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3520 - accuracy: 0.8658 - val_loss: 0.4313 - val_accuracy: 0.8132\n",
            "Epoch 3/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3532 - accuracy: 0.8633 - val_loss: 0.4278 - val_accuracy: 0.8210\n",
            "Epoch 4/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3538 - accuracy: 0.8638 - val_loss: 0.4311 - val_accuracy: 0.8210\n",
            "Epoch 5/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3542 - accuracy: 0.8662 - val_loss: 0.4199 - val_accuracy: 0.8502\n",
            "Epoch 6/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3530 - accuracy: 0.8658 - val_loss: 0.4307 - val_accuracy: 0.8405\n",
            "Epoch 7/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3533 - accuracy: 0.8604 - val_loss: 0.4212 - val_accuracy: 0.8385\n",
            "Epoch 8/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3519 - accuracy: 0.8643 - val_loss: 0.4134 - val_accuracy: 0.8327\n",
            "Epoch 9/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3543 - accuracy: 0.8604 - val_loss: 0.4366 - val_accuracy: 0.8288\n",
            "Epoch 10/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3551 - accuracy: 0.8682 - val_loss: 0.4360 - val_accuracy: 0.8424\n",
            "Epoch 11/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3543 - accuracy: 0.8585 - val_loss: 0.4486 - val_accuracy: 0.8327\n",
            "Epoch 12/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3553 - accuracy: 0.8672 - val_loss: 0.4252 - val_accuracy: 0.8366\n",
            "Epoch 13/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3529 - accuracy: 0.8677 - val_loss: 0.4193 - val_accuracy: 0.8482\n",
            "Epoch 14/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3517 - accuracy: 0.8643 - val_loss: 0.4437 - val_accuracy: 0.8385\n",
            "Epoch 15/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3536 - accuracy: 0.8667 - val_loss: 0.4268 - val_accuracy: 0.8268\n",
            "Epoch 16/50\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.3540 - accuracy: 0.8619 - val_loss: 0.4372 - val_accuracy: 0.8307\n",
            "Epoch 17/50\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.3524 - accuracy: 0.8696 - val_loss: 0.4251 - val_accuracy: 0.8366\n",
            "Epoch 18/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3527 - accuracy: 0.8667 - val_loss: 0.4286 - val_accuracy: 0.8521\n",
            "Epoch 19/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3549 - accuracy: 0.8624 - val_loss: 0.4256 - val_accuracy: 0.8482\n",
            "Epoch 20/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3530 - accuracy: 0.8677 - val_loss: 0.4361 - val_accuracy: 0.8405\n",
            "Epoch 21/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3527 - accuracy: 0.8677 - val_loss: 0.4350 - val_accuracy: 0.8463\n",
            "Epoch 22/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3556 - accuracy: 0.8662 - val_loss: 0.4295 - val_accuracy: 0.8482\n",
            "Epoch 23/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3526 - accuracy: 0.8672 - val_loss: 0.4378 - val_accuracy: 0.8424\n",
            "Epoch 24/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3520 - accuracy: 0.8701 - val_loss: 0.4396 - val_accuracy: 0.8230\n",
            "Epoch 25/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3538 - accuracy: 0.8604 - val_loss: 0.4365 - val_accuracy: 0.8580\n",
            "Epoch 26/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3543 - accuracy: 0.8599 - val_loss: 0.4279 - val_accuracy: 0.8288\n",
            "Epoch 27/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3528 - accuracy: 0.8604 - val_loss: 0.4346 - val_accuracy: 0.8444\n",
            "Epoch 28/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3520 - accuracy: 0.8648 - val_loss: 0.4414 - val_accuracy: 0.8249\n",
            "Epoch 29/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3527 - accuracy: 0.8672 - val_loss: 0.4333 - val_accuracy: 0.7996\n",
            "Epoch 30/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3527 - accuracy: 0.8682 - val_loss: 0.4438 - val_accuracy: 0.8482\n",
            "Epoch 31/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3540 - accuracy: 0.8653 - val_loss: 0.4161 - val_accuracy: 0.8327\n",
            "Epoch 32/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3523 - accuracy: 0.8672 - val_loss: 0.4224 - val_accuracy: 0.8502\n",
            "Epoch 33/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3527 - accuracy: 0.8648 - val_loss: 0.4359 - val_accuracy: 0.8444\n",
            "Epoch 34/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3528 - accuracy: 0.8653 - val_loss: 0.4266 - val_accuracy: 0.8521\n",
            "Epoch 35/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3517 - accuracy: 0.8624 - val_loss: 0.4293 - val_accuracy: 0.8249\n",
            "Epoch 36/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3530 - accuracy: 0.8677 - val_loss: 0.4210 - val_accuracy: 0.8366\n",
            "Epoch 37/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3523 - accuracy: 0.8624 - val_loss: 0.4431 - val_accuracy: 0.8171\n",
            "Epoch 38/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3542 - accuracy: 0.8633 - val_loss: 0.4294 - val_accuracy: 0.8230\n",
            "Epoch 39/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3520 - accuracy: 0.8648 - val_loss: 0.4220 - val_accuracy: 0.8463\n",
            "Epoch 40/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3538 - accuracy: 0.8662 - val_loss: 0.4346 - val_accuracy: 0.8268\n",
            "Epoch 41/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3517 - accuracy: 0.8696 - val_loss: 0.4237 - val_accuracy: 0.8424\n",
            "Epoch 42/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3522 - accuracy: 0.8638 - val_loss: 0.4323 - val_accuracy: 0.8132\n",
            "Epoch 43/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3535 - accuracy: 0.8648 - val_loss: 0.4320 - val_accuracy: 0.8268\n",
            "Epoch 44/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3540 - accuracy: 0.8633 - val_loss: 0.4271 - val_accuracy: 0.8502\n",
            "Epoch 45/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3539 - accuracy: 0.8662 - val_loss: 0.4351 - val_accuracy: 0.8307\n",
            "Epoch 46/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3517 - accuracy: 0.8653 - val_loss: 0.4360 - val_accuracy: 0.8035\n",
            "Epoch 47/50\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.3520 - accuracy: 0.8662 - val_loss: 0.4349 - val_accuracy: 0.8521\n",
            "Epoch 48/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3530 - accuracy: 0.8672 - val_loss: 0.4388 - val_accuracy: 0.8346\n",
            "Epoch 49/50\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 0.3519 - accuracy: 0.8648 - val_loss: 0.4459 - val_accuracy: 0.8366\n",
            "Epoch 50/50\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3520 - accuracy: 0.8653 - val_loss: 0.4411 - val_accuracy: 0.8521\n",
            "Training Model 3\n",
            "Epoch 1/50\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 0.3431 - accuracy: 0.8730 - val_loss: 0.3971 - val_accuracy: 0.8487\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3441 - accuracy: 0.8696 - val_loss: 0.4084 - val_accuracy: 0.8487\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3428 - accuracy: 0.8739 - val_loss: 0.4112 - val_accuracy: 0.8525\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3425 - accuracy: 0.8744 - val_loss: 0.4169 - val_accuracy: 0.8467\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3433 - accuracy: 0.8658 - val_loss: 0.4079 - val_accuracy: 0.8563\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3436 - accuracy: 0.8682 - val_loss: 0.4001 - val_accuracy: 0.8563\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3411 - accuracy: 0.8763 - val_loss: 0.4011 - val_accuracy: 0.8525\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3431 - accuracy: 0.8715 - val_loss: 0.3948 - val_accuracy: 0.8602\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3416 - accuracy: 0.8730 - val_loss: 0.3983 - val_accuracy: 0.8525\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3408 - accuracy: 0.8658 - val_loss: 0.4267 - val_accuracy: 0.8372\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3431 - accuracy: 0.8677 - val_loss: 0.4014 - val_accuracy: 0.8429\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3406 - accuracy: 0.8730 - val_loss: 0.5104 - val_accuracy: 0.7835\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3454 - accuracy: 0.8653 - val_loss: 0.4072 - val_accuracy: 0.8487\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3443 - accuracy: 0.8720 - val_loss: 0.3988 - val_accuracy: 0.8602\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3416 - accuracy: 0.8744 - val_loss: 0.4062 - val_accuracy: 0.8563\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3443 - accuracy: 0.8691 - val_loss: 0.3997 - val_accuracy: 0.8391\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3439 - accuracy: 0.8710 - val_loss: 0.4001 - val_accuracy: 0.8621\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3415 - accuracy: 0.8734 - val_loss: 0.3958 - val_accuracy: 0.8563\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3412 - accuracy: 0.8701 - val_loss: 0.4355 - val_accuracy: 0.8410\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3433 - accuracy: 0.8701 - val_loss: 0.3974 - val_accuracy: 0.8563\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3434 - accuracy: 0.8710 - val_loss: 0.3980 - val_accuracy: 0.8506\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3421 - accuracy: 0.8725 - val_loss: 0.4099 - val_accuracy: 0.8525\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3405 - accuracy: 0.8710 - val_loss: 0.4151 - val_accuracy: 0.8487\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3440 - accuracy: 0.8749 - val_loss: 0.3966 - val_accuracy: 0.8487\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3419 - accuracy: 0.8677 - val_loss: 0.4065 - val_accuracy: 0.8487\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3411 - accuracy: 0.8715 - val_loss: 0.4250 - val_accuracy: 0.8314\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3448 - accuracy: 0.8672 - val_loss: 0.3981 - val_accuracy: 0.8544\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3425 - accuracy: 0.8691 - val_loss: 0.4038 - val_accuracy: 0.8525\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3401 - accuracy: 0.8744 - val_loss: 0.4008 - val_accuracy: 0.8563\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3413 - accuracy: 0.8701 - val_loss: 0.4094 - val_accuracy: 0.8429\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3417 - accuracy: 0.8730 - val_loss: 0.4845 - val_accuracy: 0.8103\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3435 - accuracy: 0.8744 - val_loss: 0.4018 - val_accuracy: 0.8506\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3391 - accuracy: 0.8773 - val_loss: 0.4029 - val_accuracy: 0.8487\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3407 - accuracy: 0.8768 - val_loss: 0.4075 - val_accuracy: 0.8467\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3421 - accuracy: 0.8734 - val_loss: 0.5080 - val_accuracy: 0.7912\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3456 - accuracy: 0.8701 - val_loss: 0.4070 - val_accuracy: 0.8487\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3410 - accuracy: 0.8710 - val_loss: 0.4137 - val_accuracy: 0.8487\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.3423 - accuracy: 0.8686 - val_loss: 0.4034 - val_accuracy: 0.8410\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3415 - accuracy: 0.8686 - val_loss: 0.4056 - val_accuracy: 0.8391\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.3437 - accuracy: 0.8715 - val_loss: 0.4022 - val_accuracy: 0.8525\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3406 - accuracy: 0.8768 - val_loss: 0.4123 - val_accuracy: 0.8487\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3421 - accuracy: 0.8706 - val_loss: 0.4065 - val_accuracy: 0.8506\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3428 - accuracy: 0.8701 - val_loss: 0.4006 - val_accuracy: 0.8544\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3408 - accuracy: 0.8749 - val_loss: 0.4163 - val_accuracy: 0.8467\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3434 - accuracy: 0.8696 - val_loss: 0.4506 - val_accuracy: 0.8199\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3439 - accuracy: 0.8682 - val_loss: 0.4115 - val_accuracy: 0.8563\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3411 - accuracy: 0.8710 - val_loss: 0.4231 - val_accuracy: 0.8372\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3458 - accuracy: 0.8691 - val_loss: 0.4087 - val_accuracy: 0.8602\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3433 - accuracy: 0.8734 - val_loss: 0.4123 - val_accuracy: 0.8487\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.3451 - accuracy: 0.8715 - val_loss: 0.4063 - val_accuracy: 0.8467\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.7847\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6000 - accuracy: 0.7358\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6102 - accuracy: 0.7446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.evaluate(x_test_scaled, y_test), model2.evaluate(x_test_scaled, y_test), model3.evaluate(x_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RvtgfOzIR24",
        "outputId": "84b33fff-4f7c-4ebb-a723-b9d8e6a967c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7847\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.7358\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6102 - accuracy: 0.7446\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.4532375633716583, 0.7847357988357544],\n",
              " [0.5999822020530701, 0.7358121275901794],\n",
              " [0.6102432012557983, 0.7446184158325195])"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('global_loss_acc_sgd.npy',global_loss_acc)"
      ],
      "metadata": {
        "id": "52J0HiVK3aDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = np.round(model1.predict(x_test_scaled))\n",
        "p2 = np.round(model2.predict(x_test_scaled))\n",
        "p3 = np.round(model3.predict(x_test_scaled))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI3geQUqsimC",
        "outputId": "78d3311e-e3af-4dde-ab74-632c16cff8f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "32/32 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "global_cm = [confusion_matrix(y_test,p1),confusion_matrix(y_test,p2),confusion_matrix(y_test,p3)]\n",
        "global_cr = [classification_report(y_test,p1),classification_report(y_test,p2),classification_report(y_test,p3)]"
      ],
      "metadata": {
        "id": "aFV-udw10gbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(global_cr[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3ufHKCs22bX",
        "outputId": "ccd7093b-ea81-47d3-b48b-358ac0cf7260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.80      0.88       968\n",
            "           1       0.12      0.48      0.19        54\n",
            "\n",
            "    accuracy                           0.78      1022\n",
            "   macro avg       0.54      0.64      0.53      1022\n",
            "weighted avg       0.92      0.78      0.84      1022\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(global_cr[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y83hJZ5F3z18",
        "outputId": "73de5afd-d4cf-44ec-ad1f-cc0c0c874aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.74      0.84       968\n",
            "           1       0.11      0.57      0.19        54\n",
            "\n",
            "    accuracy                           0.74      1022\n",
            "   macro avg       0.54      0.66      0.51      1022\n",
            "weighted avg       0.92      0.74      0.81      1022\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(global_cr[2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukFErgoX34Sb",
        "outputId": "81981a1e-c8f6-415e-d705-95dd4fd77972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.75      0.85       968\n",
            "           1       0.12      0.57      0.19        54\n",
            "\n",
            "    accuracy                           0.74      1022\n",
            "   macro avg       0.54      0.66      0.52      1022\n",
            "weighted avg       0.92      0.74      0.81      1022\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(global_cm[0])\n",
        "print(global_cm[1])\n",
        "print(global_cm[2])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDAJAZEQ4Afu",
        "outputId": "42e4d3ca-ce08-4e82-aada-0c10840c22e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[776 192]\n",
            " [ 28  26]]\n",
            "[[721 247]\n",
            " [ 23  31]]\n",
            "[[730 238]\n",
            " [ 23  31]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h6z8-C_KDQcQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}